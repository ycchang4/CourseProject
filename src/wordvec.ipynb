{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9621a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "    def __init__(self):\n",
    "        p = []\n",
    "        with open(\"phrases.txt\") as f:\n",
    "            for line in f:\n",
    "                p.append(line.split())\n",
    "        self.p = dict(p)\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath('lee_background.cor')\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            s = utils.simple_preprocess(line)\n",
    "            i = 0\n",
    "            new_s = []\n",
    "            while i < len(s) - 1:\n",
    "                if (s[i+1] == self.p.get(s[i], False)):\n",
    "                    new_s.append(s[i] + \"_\" + s[i+1]) \n",
    "                    i+=2\n",
    "                else:\n",
    "                    new_s.append(s[i])\n",
    "                    i+=1\n",
    "            yield new_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf77d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f75cca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class moreCorpus:\n",
    "    def __iter__(self):\n",
    "        for line in open(\"phrased_bags.dat\"):\n",
    "            yield line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b95b3f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-04 14:37:41,404 : INFO : collecting all words and their counts\n",
      "2021-12-04 14:37:41,405 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-12-04 14:37:41,527 : INFO : collected 6953 word types from a corpus of 57835 raw words and 300 sentences\n",
      "2021-12-04 14:37:41,527 : INFO : Creating a fresh vocabulary\n",
      "2021-12-04 14:37:41,538 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1739 unique words (25.01078671077233%% of original 6953, drops 5214)', 'datetime': '2021-12-04T14:37:41.538342', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2021-12-04 14:37:41,539 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 49031 word corpus (84.77738393706234%% of original 57835, drops 8804)', 'datetime': '2021-12-04T14:37:41.539081', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2021-12-04 14:37:41,552 : INFO : deleting the raw counts dictionary of 6953 items\n",
      "2021-12-04 14:37:41,554 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2021-12-04 14:37:41,554 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 35662.53080575807 word corpus (72.7%% of prior 49031)', 'datetime': '2021-12-04T14:37:41.554858', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2021-12-04 14:37:41,576 : INFO : estimated required memory for 1739 words and 100 dimensions: 2260700 bytes\n",
      "2021-12-04 14:37:41,576 : INFO : resetting layer weights\n",
      "2021-12-04 14:37:41,578 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-12-04T14:37:41.578597', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2021-12-04 14:37:41,579 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1739 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2021-12-04T14:37:41.579317', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'train'}\n",
      "2021-12-04 14:37:41,707 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-04 14:37:41,712 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-04 14:37:41,713 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-04 14:37:41,713 : INFO : EPOCH - 1 : training on 57835 raw words (35656 effective words) took 0.1s, 268364 effective words/s\n",
      "2021-12-04 14:37:41,837 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-04 14:37:41,842 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-04 14:37:41,843 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-04 14:37:41,844 : INFO : EPOCH - 2 : training on 57835 raw words (35633 effective words) took 0.1s, 277189 effective words/s\n",
      "2021-12-04 14:37:41,966 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-04 14:37:41,972 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-04 14:37:41,973 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-04 14:37:41,974 : INFO : EPOCH - 3 : training on 57835 raw words (35630 effective words) took 0.1s, 276907 effective words/s\n",
      "2021-12-04 14:37:42,094 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-04 14:37:42,099 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-04 14:37:42,101 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-04 14:37:42,101 : INFO : EPOCH - 4 : training on 57835 raw words (35694 effective words) took 0.1s, 284761 effective words/s\n",
      "2021-12-04 14:37:42,235 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-04 14:37:42,240 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-04 14:37:42,241 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-04 14:37:42,242 : INFO : EPOCH - 5 : training on 57835 raw words (35632 effective words) took 0.1s, 257449 effective words/s\n",
      "2021-12-04 14:37:42,242 : INFO : Word2Vec lifecycle event {'msg': 'training on 289175 raw words (178245 effective words) took 0.7s, 268894 effective words/s', 'datetime': '2021-12-04T14:37:42.242683', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'train'}\n",
      "2021-12-04 14:37:42,243 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1739, vector_size=100, alpha=0.025)', 'datetime': '2021-12-04T14:37:42.243089', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9638d2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-04 14:37:48,234 : INFO : collecting all words and their counts\n",
      "2021-12-04 14:37:48,237 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-12-04 14:37:52,457 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "2021-12-04 14:37:52,458 : INFO : Updating model with new vocabulary\n",
      "2021-12-04 14:37:52,992 : INFO : Word2Vec lifecycle event {'msg': 'added 69587 new unique words (27.412213319467096%% of original 253854) and increased the count of 1703 pre-existing words (0.6708580522662633%% of original 253854)', 'datetime': '2021-12-04T14:37:52.992490', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2021-12-04 14:37:53,512 : INFO : deleting the raw counts dictionary of 253854 items\n",
      "2021-12-04 14:37:53,517 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2021-12-04 14:37:53,518 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 12506280.016269669 word corpus (74.8%% of prior 16718844)', 'datetime': '2021-12-04T14:37:53.518649', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2021-12-04 14:37:54,224 : INFO : estimated required memory for 71290 words and 100 dimensions: 92677000 bytes\n",
      "2021-12-04 14:37:54,225 : INFO : updating layer weights\n",
      "2021-12-04 14:37:54,289 : INFO : Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2021-12-04T14:37:54.289305', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2021-12-04 14:37:54,290 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2021-12-04 14:37:54,290 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 71326 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2021-12-04T14:37:54.290520', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'train'}\n",
      "2021-12-04 14:37:55,297 : INFO : EPOCH 1 - PROGRESS: at 8.58% examples, 1064137 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:37:56,300 : INFO : EPOCH 1 - PROGRESS: at 19.28% examples, 1197808 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:37:57,310 : INFO : EPOCH 1 - PROGRESS: at 30.04% examples, 1247170 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:37:58,312 : INFO : EPOCH 1 - PROGRESS: at 40.33% examples, 1258565 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:37:59,316 : INFO : EPOCH 1 - PROGRESS: at 49.79% examples, 1244007 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:00,317 : INFO : EPOCH 1 - PROGRESS: at 59.91% examples, 1248117 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:01,320 : INFO : EPOCH 1 - PROGRESS: at 69.49% examples, 1241004 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:02,320 : INFO : EPOCH 1 - PROGRESS: at 79.66% examples, 1243072 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:03,323 : INFO : EPOCH 1 - PROGRESS: at 88.36% examples, 1225240 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:04,328 : INFO : EPOCH 1 - PROGRESS: at 97.59% examples, 1216977 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:04,602 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-04 14:38:04,606 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-04 14:38:04,612 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-04 14:38:04,613 : INFO : EPOCH - 1 : training on 17005207 raw words (12507672 effective words) took 10.3s, 1212337 effective words/s\n",
      "2021-12-04 14:38:05,623 : INFO : EPOCH 2 - PROGRESS: at 9.41% examples, 1159504 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:06,623 : INFO : EPOCH 2 - PROGRESS: at 19.93% examples, 1235559 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:07,624 : INFO : EPOCH 2 - PROGRESS: at 29.81% examples, 1239992 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:08,627 : INFO : EPOCH 2 - PROGRESS: at 40.33% examples, 1260292 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:09,630 : INFO : EPOCH 2 - PROGRESS: at 50.85% examples, 1272012 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:10,632 : INFO : EPOCH 2 - PROGRESS: at 61.38% examples, 1279655 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:11,634 : INFO : EPOCH 2 - PROGRESS: at 71.96% examples, 1285946 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:12,639 : INFO : EPOCH 2 - PROGRESS: at 82.54% examples, 1287544 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:13,642 : INFO : EPOCH 2 - PROGRESS: at 92.77% examples, 1286053 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:14,288 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-04 14:38:14,292 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-04 14:38:14,293 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-04 14:38:14,293 : INFO : EPOCH - 2 : training on 17005207 raw words (12506046 effective words) took 9.7s, 1292314 effective words/s\n",
      "2021-12-04 14:38:15,297 : INFO : EPOCH 3 - PROGRESS: at 10.99% examples, 1363864 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:16,303 : INFO : EPOCH 3 - PROGRESS: at 21.93% examples, 1361407 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:17,303 : INFO : EPOCH 3 - PROGRESS: at 32.63% examples, 1358768 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:18,305 : INFO : EPOCH 3 - PROGRESS: at 42.50% examples, 1329320 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:19,309 : INFO : EPOCH 3 - PROGRESS: at 53.20% examples, 1331188 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:20,311 : INFO : EPOCH 3 - PROGRESS: at 64.14% examples, 1337641 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:21,312 : INFO : EPOCH 3 - PROGRESS: at 73.90% examples, 1321556 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:22,316 : INFO : EPOCH 3 - PROGRESS: at 84.71% examples, 1322305 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:23,318 : INFO : EPOCH 3 - PROGRESS: at 95.59% examples, 1325922 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:23,712 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-04 14:38:23,713 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-04 14:38:23,717 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-04 14:38:23,718 : INFO : EPOCH - 3 : training on 17005207 raw words (12508134 effective words) took 9.4s, 1327589 effective words/s\n",
      "2021-12-04 14:38:24,723 : INFO : EPOCH 4 - PROGRESS: at 10.93% examples, 1350845 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:25,725 : INFO : EPOCH 4 - PROGRESS: at 22.28% examples, 1383890 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:26,728 : INFO : EPOCH 4 - PROGRESS: at 32.75% examples, 1363204 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:27,728 : INFO : EPOCH 4 - PROGRESS: at 41.86% examples, 1308877 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:28,729 : INFO : EPOCH 4 - PROGRESS: at 52.20% examples, 1306588 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:29,729 : INFO : EPOCH 4 - PROGRESS: at 63.14% examples, 1317784 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:30,733 : INFO : EPOCH 4 - PROGRESS: at 73.78% examples, 1319827 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:31,736 : INFO : EPOCH 4 - PROGRESS: at 83.89% examples, 1310110 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:32,736 : INFO : EPOCH 4 - PROGRESS: at 94.42% examples, 1310178 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:33,249 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-04 14:38:33,251 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-04 14:38:33,254 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-04 14:38:33,254 : INFO : EPOCH - 4 : training on 17005207 raw words (12506953 effective words) took 9.5s, 1311788 effective words/s\n",
      "2021-12-04 14:38:34,259 : INFO : EPOCH 5 - PROGRESS: at 10.99% examples, 1358605 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:35,262 : INFO : EPOCH 5 - PROGRESS: at 22.22% examples, 1379716 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:36,268 : INFO : EPOCH 5 - PROGRESS: at 32.98% examples, 1370922 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:37,269 : INFO : EPOCH 5 - PROGRESS: at 43.97% examples, 1373225 words/s, in_qsize 6, out_qsize 0\n",
      "2021-12-04 14:38:38,272 : INFO : EPOCH 5 - PROGRESS: at 53.97% examples, 1349163 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:39,273 : INFO : EPOCH 5 - PROGRESS: at 64.96% examples, 1353753 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:40,279 : INFO : EPOCH 5 - PROGRESS: at 75.43% examples, 1345958 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:41,282 : INFO : EPOCH 5 - PROGRESS: at 84.89% examples, 1323624 words/s, in_qsize 6, out_qsize 0\n",
      "2021-12-04 14:38:42,283 : INFO : EPOCH 5 - PROGRESS: at 94.06% examples, 1303519 words/s, in_qsize 5, out_qsize 0\n",
      "2021-12-04 14:38:42,858 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-04 14:38:42,862 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-04 14:38:42,863 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-04 14:38:42,864 : INFO : EPOCH - 5 : training on 17005207 raw words (12505472 effective words) took 9.6s, 1301617 effective words/s\n",
      "2021-12-04 14:38:42,864 : INFO : Word2Vec lifecycle event {'msg': 'training on 85026035 raw words (62534277 effective words) took 48.6s, 1287422 effective words/s', 'datetime': '2021-12-04T14:38:42.864527', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'train'}\n",
      "2021-12-04 14:38:42,865 : INFO : collecting all words and their counts\n",
      "2021-12-04 14:38:42,866 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-12-04 14:38:42,916 : INFO : collected 12250 word types from a corpus of 216470 raw words and 160 sentences\n",
      "2021-12-04 14:38:42,917 : INFO : Updating model with new vocabulary\n",
      "2021-12-04 14:38:43,282 : INFO : Word2Vec lifecycle event {'msg': 'added 458 new unique words (3.7387755102040816%% of original 12250) and increased the count of 3677 pre-existing words (30.016326530612243%% of original 12250)', 'datetime': '2021-12-04T14:38:43.282859', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2021-12-04 14:38:43,313 : INFO : deleting the raw counts dictionary of 12250 items\n",
      "2021-12-04 14:38:43,313 : INFO : sample=0.001 downsamples 56 most-common words\n",
      "2021-12-04 14:38:43,314 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 180867.80429278902 word corpus (89.1%% of prior 202962)', 'datetime': '2021-12-04T14:38:43.314307', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2021-12-04 14:38:44,081 : INFO : estimated required memory for 4135 words and 100 dimensions: 5375500 bytes\n",
      "2021-12-04 14:38:44,081 : INFO : updating layer weights\n",
      "2021-12-04 14:38:44,148 : INFO : Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2021-12-04T14:38:44.148521', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2021-12-04 14:38:44,149 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2021-12-04 14:38:44,149 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 71784 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2021-12-04T14:38:44.149792', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'train'}\n",
      "2021-12-04 14:38:44,272 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-04 14:38:44,276 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-04 14:38:44,288 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-04 14:38:44,289 : INFO : EPOCH - 1 : training on 216470 raw words (176006 effective words) took 0.1s, 1284918 effective words/s\n",
      "2021-12-04 14:38:44,406 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-04 14:38:44,408 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-04 14:38:44,421 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-04 14:38:44,421 : INFO : EPOCH - 2 : training on 216470 raw words (175958 effective words) took 0.1s, 1343341 effective words/s\n",
      "2021-12-04 14:38:44,538 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-04 14:38:44,541 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-04 14:38:44,552 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-04 14:38:44,553 : INFO : EPOCH - 3 : training on 216470 raw words (176133 effective words) took 0.1s, 1362810 effective words/s\n",
      "2021-12-04 14:38:44,671 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-04 14:38:44,675 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-04 14:38:44,687 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-04 14:38:44,688 : INFO : EPOCH - 4 : training on 216470 raw words (176169 effective words) took 0.1s, 1317305 effective words/s\n",
      "2021-12-04 14:38:44,809 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-04 14:38:44,815 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-04 14:38:44,826 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-04 14:38:44,826 : INFO : EPOCH - 5 : training on 216470 raw words (176096 effective words) took 0.1s, 1291719 effective words/s\n",
      "2021-12-04 14:38:44,827 : INFO : Word2Vec lifecycle event {'msg': 'training on 1082350 raw words (880362 effective words) took 0.7s, 1300371 effective words/s', 'datetime': '2021-12-04T14:38:44.827257', 'gensim': '4.1.2', 'python': '3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]', 'platform': 'Darwin-20.2.0-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(880362, 1082350)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text8 = gensim.models.word2vec.Text8Corpus(\"text8\")\n",
    "model.build_vocab(text8, update=True)\n",
    "model.train(text8, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "more_sentences = moreCorpus()\n",
    "model.build_vocab(more_sentences, update=True)\n",
    "model.train(more_sentences, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aae9d97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5443577 , -1.8677766 ,  0.6969574 , -0.7649274 ,  0.4136052 ,\n",
       "        0.95004326,  1.4783763 , -0.44680443,  0.5444725 ,  1.1497146 ,\n",
       "       -2.756879  , -1.2932364 ,  1.0540298 ,  0.04450639, -2.3502295 ,\n",
       "        0.43234324,  1.4133047 ,  0.7529522 , -1.7938697 ,  0.7479326 ,\n",
       "        0.98470724,  0.41273305, -1.0099581 ,  0.45519257, -1.4839329 ,\n",
       "        2.0943274 , -0.46799213, -1.3057925 , -1.562512  , -0.23459376,\n",
       "        0.3445955 , -1.93649   , -1.0005608 , -0.15533416, -1.0690696 ,\n",
       "        3.6427383 , -0.9240831 , -1.2301477 , -1.866946  , -1.069647  ,\n",
       "       -0.55926585, -0.30832335,  0.8833607 , -1.8611103 ,  0.44886217,\n",
       "        0.75281125, -1.1127822 , -1.5394735 ,  0.18234703, -0.89218485,\n",
       "        2.6705978 , -0.98842096, -2.1195145 ,  2.9772646 , -2.3291984 ,\n",
       "        0.04284742,  1.5605425 ,  0.21591453, -1.2733151 ,  0.21606953,\n",
       "       -1.1090584 ,  1.7248476 , -1.8718649 , -1.1038254 , -0.37583908,\n",
       "        0.38263977, -2.3194928 , -1.5594994 ,  0.10595816,  0.27934527,\n",
       "       -0.95608413,  1.0677195 ,  0.17905085,  1.1597335 ,  0.500681  ,\n",
       "       -0.5535348 ,  1.0073141 ,  0.5033654 , -1.1940502 , -0.13467741,\n",
       "        0.93926084, -1.4526101 , -1.3276774 ,  1.897223  , -0.02063618,\n",
       "       -0.19784859, -3.0299554 ,  0.861227  ,  0.64120555, -0.52508616,\n",
       "       -1.4983721 , -0.23308782,  2.2873027 ,  1.2771415 ,  0.8340255 ,\n",
       "        4.38278   , -0.00491076, -1.1049277 , -2.0673525 ,  0.35171643],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('vector_space')\n",
    "model.wv['vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e40e7529",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'next_lecture' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d3bc3acd7638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vector_space\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"next_lecture\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36msimilarity\u001b[0;34m(self, w1, w2)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \"\"\"\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mn_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'next_lecture' not present\""
     ]
    }
   ],
   "source": [
    "model.wv.similarity(\"vector_space\", \"next_lecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "600b178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10a9bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hitx = []\n",
    "hity = []\n",
    "pos = 0\n",
    "neg = 0\n",
    "                \n",
    "with open(\"miss.dat\") as f:\n",
    "    for line in f:\n",
    "        for word in utils.simple_preprocess(line):\n",
    "            try:\n",
    "                hitx.append(model.wv[word])\n",
    "                hity.append(0.0)\n",
    "                neg += 1\n",
    "            except:\n",
    "                continue\n",
    "with open(\"hits.dat\") as f:\n",
    "    for line in f:\n",
    "        for word in utils.simple_preprocess(line):\n",
    "            try:\n",
    "                vec = model.wv[word]\n",
    "                hitx.append(vec)\n",
    "                hity.append(1.0)\n",
    "                pos += 1\n",
    "            except:\n",
    "                continue\n",
    "hitx = np.array(hitx)\n",
    "hity = np.array(hity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8139ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_bias = np.log([pos/neg])\n",
    "output_bias = tf.keras.initializers.Constant(initial_bias)\n",
    "nnet = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid',bias_initializer= output_bias)])\n",
    "nnet.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c6a3b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "13009/13009 [==============================] - 11s 820us/step - loss: 0.4337 - binary_accuracy: 0.8021\n",
      "Epoch 2/3\n",
      "13009/13009 [==============================] - 11s 822us/step - loss: 0.4121 - binary_accuracy: 0.8152\n",
      "Epoch 3/3\n",
      "13009/13009 [==============================] - 10s 795us/step - loss: 0.4044 - binary_accuracy: 0.8194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a5d3bccc40>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet.fit(\n",
    "  x=hitx,\n",
    "  y=hity,\n",
    "  shuffle=True,\n",
    "  epochs=3,\n",
    "  batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58c116cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79793197]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet.predict(np.array([model.wv['dcg']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ccbb144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastGetter:\n",
    "    def __init__(self, m, wv):\n",
    "        self.model = m\n",
    "        self.wv = wv\n",
    "        self.d = {}\n",
    "    def get(self, x):\n",
    "        r = self.d.get(x, 100)\n",
    "        if (r != 100):\n",
    "            return r\n",
    "        else:\n",
    "            r = self.model.predict(np.array([model.wv[x.strip()]]))\n",
    "            self.d[x] = r\n",
    "            return r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1bf3b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = FastGetter(nnet, model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13ffc9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 0.7\n",
    "\n",
    "with open(\"reducedretrieval.dat\", \"w\", encoding='utf-8') as out:\n",
    "    with open(\"textretrieval.txt\", encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            li = []\n",
    "            for sentence in line.split(\".\"):\n",
    "                accu = 0.0\n",
    "                cnt = 0\n",
    "                for word in utils.simple_preprocess(sentence):\n",
    "                    try:\n",
    "                        accu += fg.get(word)\n",
    "                        cnt+=1\n",
    "                    except:\n",
    "                        continue\n",
    "                try:\n",
    "                    accu /= cnt\n",
    "                    li.append((accu[0], sentence))\n",
    "#                     if (accu > tol):\n",
    "#                         print(sentence)\n",
    "#                     else:\n",
    "#                         print(\"passed\")\n",
    "                except:\n",
    "                    continue\n",
    "            li.sort(reverse=True)\n",
    "            li = [i for _, i in li]\n",
    "            out.write(\".\".join(li[:round(len(li)/2)]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56c45116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = [\"1\", \"2\",\"3\", \"4\"]\n",
    "\".\".join(li[:round(len(li)/2)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
