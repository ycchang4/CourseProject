WEBVTT Kind: captions; Language: en-US

NOTE
Created on 2021-02-26T23:59:32.1306336Z by ClassTranscribe

00:00:00.300 --> 00:00:02.530
This lecture is about the evaluation of

00:00:02.530 --> 00:00:03.680
taxable categorization.

00:00:11.740 --> 00:00:13.930
So we've talked about many different

00:00:13.930 --> 00:00:16.120
methods for taxi categorisation, but

00:00:16.120 --> 00:00:18.080
how do you which method works better?

00:00:18.970 --> 00:00:20.860
And for a particular application, how

00:00:20.860 --> 00:00:24.750
do you this is the best way of solving

00:00:24.750 --> 00:00:25.460
your problem.

00:00:25.460 --> 00:00:28.350
To understand these will have to.

00:00:29.020 --> 00:00:32.700
How to we have to know how to evaluate

00:00:32.700 --> 00:00:33.990
categorisation results?

00:00:34.760 --> 00:00:36.920
So first some general thoughts about

00:00:36.920 --> 00:00:39.630
the evaluation in general for

00:00:39.630 --> 00:00:41.630
evaluation of this kind of empirical

00:00:41.630 --> 00:00:45.560
tasks such as categorisation, we use

00:00:45.560 --> 00:00:49.300
methodology that was developed in 1960s

00:00:49.300 --> 00:00:51.540
by information retrieval researchers

00:00:51.540 --> 00:00:53.005
called Cranfield Evaluation

00:00:53.005 --> 00:00:53.572
Methodology.

00:00:53.572 --> 00:00:56.340
The basic idea is to help humans to

00:00:56.340 --> 00:00:58.340
create test collection.

00:00:58.930 --> 00:01:01.810
Where we already every document is

00:01:01.810 --> 00:01:04.120
tagged with the desired categories, or

00:01:04.120 --> 00:01:06.620
in the case of search for which query,

00:01:06.620 --> 00:01:08.390
which documents should have been

00:01:08.390 --> 00:01:10.310
retrieved and this is called ground

00:01:10.310 --> 00:01:10.740
truth.

00:01:11.960 --> 00:01:13.966
Now with this ground truth test

00:01:13.966 --> 00:01:16.890
collection, we can then reduce the

00:01:16.890 --> 00:01:19.415
collection to test many different

00:01:19.415 --> 00:01:21.344
systems and compare different systems.

00:01:21.344 --> 00:01:24.380
We can also turn off some component in

00:01:24.380 --> 00:01:25.960
system to see what's going to happen.

00:01:25.960 --> 00:01:27.710
Basically it provides.

00:01:29.190 --> 00:01:33.370
A way to do controlled experiments to

00:01:33.370 --> 00:01:34.830
compare different methods.

00:01:35.790 --> 00:01:37.680
So this methodology has been virtually

00:01:37.680 --> 00:01:41.890
used for all the tasks that involve

00:01:41.890 --> 00:01:43.870
empirically defined problems.

00:01:45.850 --> 00:01:48.460
So in our case, then we're going to

00:01:48.460 --> 00:01:50.820
compare our systems categorization

00:01:50.820 --> 00:01:54.040
results with the categorisation ground

00:01:54.040 --> 00:01:55.650
truth created by humans.

00:01:56.630 --> 00:01:58.900
And we're going to compare our systems

00:01:58.900 --> 00:02:02.370
decisions on which documents should get

00:02:02.370 --> 00:02:04.770
which category with what.

00:02:06.050 --> 00:02:07.660
Categories have been assigned to those

00:02:07.660 --> 00:02:10.250
documents by humans and we want to

00:02:10.250 --> 00:02:12.680
quantify the similarity of these

00:02:12.680 --> 00:02:13.440
decisions.

00:02:14.170 --> 00:02:16.770
Or equivalently, to measure the

00:02:16.770 --> 00:02:18.850
difference between the system output

00:02:18.850 --> 00:02:22.855
and desired ideal output generated by

00:02:22.855 --> 00:02:23.790
the humans?

00:02:24.900 --> 00:02:27.550
So obviously the higher similarity is,

00:02:27.550 --> 00:02:29.220
the better the results are.

00:02:29.900 --> 00:02:31.820
The similarity can be measured in

00:02:31.820 --> 00:02:32.850
different ways.

00:02:33.690 --> 00:02:34.990
And that would lead to different

00:02:34.990 --> 00:02:37.400
measures, and sometimes it's desirable

00:02:37.400 --> 00:02:39.520
also to measure the similarity from

00:02:39.520 --> 00:02:41.915
different perspectives just to have a

00:02:41.915 --> 00:02:44.150
better understanding of the results in

00:02:44.150 --> 00:02:44.640
detail.

00:02:44.640 --> 00:02:45.970
For example, it might be also

00:02:45.970 --> 00:02:48.510
interested in knowing which category

00:02:48.510 --> 00:02:51.250
performs better, which category is easy

00:02:51.250 --> 00:02:53.200
to categorize, etc.

00:02:54.630 --> 00:02:57.660
In general, different categorization

00:02:57.660 --> 00:03:01.230
mistakes, however, have different costs

00:03:01.230 --> 00:03:04.110
for a specific application, so some

00:03:04.110 --> 00:03:05.810
errors might be more serious than

00:03:05.810 --> 00:03:06.335
others.

00:03:06.335 --> 00:03:09.570
So ideally we would like to model such

00:03:09.570 --> 00:03:10.580
differences.

00:03:10.580 --> 00:03:13.170
But if you read many papers in texture

00:03:13.170 --> 00:03:14.640
catalyzation, you will see that they

00:03:14.640 --> 00:03:16.420
don't generally do that, and instead

00:03:16.420 --> 00:03:18.670
they will use a simplified measure.

00:03:19.380 --> 00:03:20.880
And that's the cause.

00:03:20.880 --> 00:03:23.630
It's often OK not to consider such a

00:03:23.630 --> 00:03:25.850
cost variation when we compare

00:03:25.850 --> 00:03:27.310
different methods.

00:03:27.310 --> 00:03:30.155
An we when we are interested in knowing

00:03:30.155 --> 00:03:32.775
the relative difference of these

00:03:32.775 --> 00:03:33.250
methods.

00:03:33.940 --> 00:03:36.950
So it's OK to introduce some bias as

00:03:36.950 --> 00:03:38.810
long as the bias is not correlated with

00:03:38.810 --> 00:03:39.870
a particular method.

00:03:40.680 --> 00:03:42.990
And then we should still expect the

00:03:42.990 --> 00:03:45.780
more effective method to perform better

00:03:45.780 --> 00:03:48.770
than a less effective one, even though

00:03:48.770 --> 00:03:50.650
the measure is not perfect.

00:03:53.010 --> 00:03:54.560
So the first measure that we will

00:03:54.560 --> 00:03:55.990
introduce is called classification

00:03:55.990 --> 00:03:57.530
accuracy, and this is basically to

00:03:57.530 --> 00:03:59.060
measure the percentage of corrective

00:03:59.060 --> 00:03:59.385
decisions.

00:03:59.385 --> 00:04:02.785
So here you show that here you see that

00:04:02.785 --> 00:04:05.316
there are K categories denoted by C1

00:04:05.316 --> 00:04:08.150
through CK and there are N documents in

00:04:08.150 --> 00:04:11.455
order by D1 through DN an for each pair

00:04:11.455 --> 00:04:13.230
of a category on the document that we

00:04:13.230 --> 00:04:15.160
can then look at the situation.

00:04:16.680 --> 00:04:20.380
And see if the system has said yes to

00:04:20.380 --> 00:04:20.960
despair.

00:04:20.960 --> 00:04:22.853
Basically has assigned this category to

00:04:22.853 --> 00:04:25.460
this document or no, so this is denoted

00:04:25.460 --> 00:04:26.900
by Y or N.

00:04:26.900 --> 00:04:28.783
That's the system to decision.

00:04:28.783 --> 00:04:30.650
And similarly we can look at the humans

00:04:30.650 --> 00:04:31.060
decision.

00:04:31.060 --> 00:04:34.084
Also, if the human has assigned a

00:04:34.084 --> 00:04:36.270
category to the document, there will be

00:04:36.270 --> 00:04:37.600
a plus sign here.

00:04:37.600 --> 00:04:40.480
That's just that just means a human

00:04:40.480 --> 00:04:42.680
would think this assignment is correct

00:04:42.680 --> 00:04:45.220
an if the incorrect, and then there's a

00:04:45.220 --> 00:04:45.900
minus.

00:04:45.900 --> 00:04:47.770
So we will see.

00:04:47.820 --> 00:04:51.440
All combinations of these ends yes and

00:04:51.440 --> 00:04:53.112
Nos with minus and plus.

00:04:53.112 --> 00:04:55.502
So there are four combinations in total

00:04:55.502 --> 00:04:58.865
and two of them are correct and when we

00:04:58.865 --> 00:05:02.840
have Y plus or minus and then there are

00:05:02.840 --> 00:05:04.150
also two kinds of errors.

00:05:04.150 --> 00:05:06.210
So the measure of classification

00:05:06.210 --> 00:05:08.190
accuracy is similar to count how many

00:05:08.190 --> 00:05:10.399
of these decisions are correct and

00:05:10.400 --> 00:05:12.590
normalize that by the total number of

00:05:12.590 --> 00:05:13.780
decisions we have made.

00:05:13.780 --> 00:05:16.625
So we know that the total number of

00:05:16.625 --> 00:05:17.439
decisions is.

00:05:18.010 --> 00:05:19.520
In multiplied by K.

00:05:20.190 --> 00:05:22.300
And the number of characters decisions

00:05:22.300 --> 00:05:24.890
obviously are basically of two kinds.

00:05:24.890 --> 00:05:27.500
One is why pluses and the other is N

00:05:27.500 --> 00:05:29.540
minus is and we just put together the

00:05:29.540 --> 00:05:30.150
account.

00:05:30.150 --> 00:05:32.810
Now this is a very convenient measure

00:05:32.810 --> 00:05:35.040
that will give us a one number to

00:05:35.040 --> 00:05:38.185
characterize performance of method and

00:05:38.185 --> 00:05:39.770
the higher the better of course.

00:05:40.370 --> 00:05:42.650
But the method I also had some

00:05:42.650 --> 00:05:43.580
problems.

00:05:43.580 --> 00:05:46.840
First it has treated all the decisions

00:05:46.840 --> 00:05:50.050
equally so, but in reality there's some

00:05:50.050 --> 00:05:51.923
decision errors are more serious than

00:05:51.923 --> 00:05:52.406
others.

00:05:52.406 --> 00:05:54.203
For example, it may be more important

00:05:54.203 --> 00:05:55.890
to get the decisions right on some

00:05:55.890 --> 00:05:58.705
documents than others, and or maybe

00:05:58.705 --> 00:06:00.300
more important to get the divisions

00:06:00.300 --> 00:06:02.345
right on some categories than others,

00:06:02.345 --> 00:06:05.340
and this would call for some detailed

00:06:05.340 --> 00:06:08.870
evaluation of this results to

00:06:08.870 --> 00:06:09.760
understand.

00:06:10.720 --> 00:06:12.640
The strengths and weaknesses of

00:06:12.640 --> 00:06:13.600
different methods.

00:06:14.880 --> 00:06:17.830
And to understand the performance of

00:06:17.830 --> 00:06:19.210
these methods in detail.

00:06:21.380 --> 00:06:24.430
In APA category or per document basis?

00:06:25.360 --> 00:06:28.460
One example that shows clearly the

00:06:28.460 --> 00:06:31.090
desicion errors are having different

00:06:31.090 --> 00:06:33.550
causes, spam filtering that could be

00:06:33.550 --> 00:06:35.050
retrieved as a two category

00:06:35.050 --> 00:06:36.190
categorization problem.

00:06:36.830 --> 00:06:40.540
Missing a legitimate email is all is 1

00:06:40.540 --> 00:06:41.980
type of error.

00:06:41.980 --> 00:06:45.150
But letting us ma'am to come into your

00:06:45.150 --> 00:06:46.977
folder is another type of error.

00:06:46.977 --> 00:06:49.320
The two types of errors are clearly

00:06:49.320 --> 00:06:52.019
very different because it's very

00:06:52.020 --> 00:06:54.225
important not to miss a legitimate

00:06:54.225 --> 00:06:54.697
email.

00:06:54.697 --> 00:06:57.320
It's OK to occasionally let us spam

00:06:57.320 --> 00:07:00.210
email to come into your inbox, so the

00:07:00.210 --> 00:07:03.409
error of the first missing a legitimate

00:07:03.409 --> 00:07:05.823
email is very high cost.

00:07:05.823 --> 00:07:07.620
It's very serious mistake.

00:07:08.420 --> 00:07:11.180
And classification error classification

00:07:11.180 --> 00:07:13.340
accuracy does not address this issue.

00:07:14.230 --> 00:07:15.590
There's also another problem with

00:07:15.590 --> 00:07:17.610
imbalanced tests at the Imagine there's

00:07:17.610 --> 00:07:17.945
a skew.

00:07:17.945 --> 00:07:20.360
The test set where most instances are

00:07:20.360 --> 00:07:21.330
in category one.

00:07:21.970 --> 00:07:24.570
And 98% of instances are in category

00:07:24.570 --> 00:07:26.881
one only 2% are in category Two.

00:07:26.881 --> 00:07:29.209
In such a case, we can have a very

00:07:29.210 --> 00:07:31.290
simple baseline that actually performs

00:07:31.290 --> 00:07:33.380
very, and the baseline would Simply put

00:07:33.380 --> 00:07:35.510
all instances in the major category.

00:07:36.220 --> 00:07:38.670
That would give us 98% accuracy.

00:07:38.670 --> 00:07:40.850
In this case, it's going to be

00:07:40.850 --> 00:07:43.260
appearing to be very effective, but in

00:07:43.260 --> 00:07:45.110
reality this is obviously not a good

00:07:45.110 --> 00:07:45.690
result.

00:07:46.380 --> 00:07:49.110
And so, in general, when we use

00:07:49.110 --> 00:07:50.855
classification accuracy as a measure,

00:07:50.855 --> 00:07:52.730
we want to ensure that the classes are

00:07:52.730 --> 00:07:53.430
balanced.

00:07:54.720 --> 00:07:56.600
And we wonder about equal number of

00:07:56.600 --> 00:07:57.210
instances.

00:07:57.210 --> 00:08:00.190
For example, in each class the minority

00:08:00.190 --> 00:08:02.600
categories or classes tend to be

00:08:02.600 --> 00:08:04.840
overlooked in the evaluation of

00:08:04.840 --> 00:08:05.920
classification accuracy.

00:08:06.790 --> 00:08:08.320
How to address these problems?

00:08:08.320 --> 00:08:09.940
We of course would like to also

00:08:09.940 --> 00:08:13.740
evaluate the results in other ways and

00:08:13.740 --> 00:08:14.510
in different ways.

00:08:14.510 --> 00:08:16.397
As I said, it's beneficial to look at

00:08:16.397 --> 00:08:18.135
the actual must multiple perspectives.

00:08:18.135 --> 00:08:20.377
So for example, we can look at the

00:08:20.377 --> 00:08:22.780
perspective from each document

00:08:22.780 --> 00:08:24.894
perspective based on each document.

00:08:24.894 --> 00:08:27.300
So the question here is, how could

00:08:27.300 --> 00:08:28.810
other divisions on this document?

00:08:29.780 --> 00:08:32.990
Now, as in the general cases of all

00:08:32.990 --> 00:08:35.570
decisions, we can think about four

00:08:35.570 --> 00:08:37.810
combinations of possibilities.

00:08:38.390 --> 00:08:40.221
Depending on whether the system has

00:08:40.221 --> 00:08:42.358
said yes, and depending on whether the

00:08:42.358 --> 00:08:44.420
human has said it correctly or

00:08:44.420 --> 00:08:46.873
incorrectly, or say yes or no, and so

00:08:46.873 --> 00:08:50.805
the four combinations are first.

00:08:50.805 --> 00:08:53.680
When both the human system said yes and

00:08:53.680 --> 00:08:56.304
that's true positives when the system

00:08:56.304 --> 00:08:58.488
says yes, it's actually positive.

00:08:58.488 --> 00:09:01.120
So when the system says yes, it's a

00:09:01.120 --> 00:09:02.140
positive.

00:09:02.140 --> 00:09:04.520
But when the human confirmed that it is

00:09:04.520 --> 00:09:06.510
indeed correct, that becomes true

00:09:06.510 --> 00:09:06.960
positive.

00:09:07.790 --> 00:09:10.020
When the system says yes, but human

00:09:10.020 --> 00:09:11.540
says no, that's incorrect.

00:09:11.540 --> 00:09:14.320
That's a false positive FP.

00:09:14.900 --> 00:09:16.890
And when the system says no, but the

00:09:16.890 --> 00:09:19.130
human says yes, then it's a false

00:09:19.130 --> 00:09:19.940
negative.

00:09:19.940 --> 00:09:21.550
We missed one assignment.

00:09:22.120 --> 00:09:25.590
When does the system and human said no?

00:09:25.590 --> 00:09:27.610
Then that's also corrected vision.

00:09:27.610 --> 00:09:28.720
That's true negatives.

00:09:29.420 --> 00:09:31.260
Alright, so then we can have some

00:09:31.260 --> 00:09:35.520
meshes to just better characterize the

00:09:35.520 --> 00:09:36.930
performance by using these phone

00:09:36.930 --> 00:09:39.605
numbers and so 2 popular measures of

00:09:39.605 --> 00:09:40.890
precision and recall.

00:09:40.890 --> 00:09:42.880
And these are also proposed by

00:09:42.880 --> 00:09:44.520
information retrieval researchers in

00:09:44.520 --> 00:09:46.690
19, six days for evaluating searching

00:09:46.690 --> 00:09:47.180
results.

00:09:47.180 --> 00:09:48.920
But now they have become a standard

00:09:48.920 --> 00:09:50.351
measure used everywhere.

00:09:50.351 --> 00:09:54.330
So when the system says yes, we can ask

00:09:54.330 --> 00:09:55.920
the question how many are correct?

00:09:55.920 --> 00:09:58.510
What's the percentage of correct

00:09:58.510 --> 00:10:00.410
decisions when the system says yes?

00:10:00.410 --> 00:10:01.610
That's called precision.

00:10:02.210 --> 00:10:04.570
It's a true positive divided by all the

00:10:04.570 --> 00:10:06.790
cases when the system says yes all the

00:10:06.790 --> 00:10:07.470
positives.

00:10:09.160 --> 00:10:10.750
The other recall the other meshes

00:10:10.750 --> 00:10:12.670
called Recall an this measures.

00:10:14.090 --> 00:10:16.500
Whether the document that has called

00:10:16.500 --> 00:10:18.651
all the categories it should have.

00:10:18.651 --> 00:10:20.590
So in this case it's divided the true

00:10:20.590 --> 00:10:24.580
positive by true positives and false

00:10:24.580 --> 00:10:25.305
negatives.

00:10:25.305 --> 00:10:28.670
So these are all the cases where this

00:10:28.670 --> 00:10:31.521
human says the document should have

00:10:31.521 --> 00:10:32.520
this category.

00:10:32.520 --> 00:10:35.034
So this represents the old categories

00:10:35.034 --> 00:10:36.940
that it should have got an.

00:10:36.940 --> 00:10:39.220
So recall tells us whether the system

00:10:39.220 --> 00:10:41.660
has actually indeed assigned all the

00:10:41.660 --> 00:10:44.195
categories that it should have to this

00:10:44.195 --> 00:10:44.610
document.

00:10:45.530 --> 00:10:47.800
This gives us a detailed view of the

00:10:47.800 --> 00:10:48.732
decision on each document.

00:10:48.732 --> 00:10:50.660
Then we can aggregate them later.

00:10:50.660 --> 00:10:52.830
And if you're interested in some

00:10:52.830 --> 00:10:55.250
documents and this would tell us how

00:10:55.250 --> 00:10:58.380
well we did that those documents a

00:10:58.380 --> 00:10:59.880
subset of them might be more

00:10:59.880 --> 00:11:00.743
interesting than others.

00:11:00.743 --> 00:11:02.770
For example, and this allows us to

00:11:02.770 --> 00:11:05.095
analyze errors in more detail as well.

00:11:05.095 --> 00:11:07.059
We can separate the documents of

00:11:07.060 --> 00:11:09.123
certain characteristic from others and

00:11:09.123 --> 00:11:10.340
then look at the errors.

00:11:10.340 --> 00:11:11.860
You might see a pattern here for this

00:11:11.860 --> 00:11:14.100
kind of documents along documents it

00:11:14.100 --> 00:11:15.400
doesn't do as well as.

00:11:15.820 --> 00:11:17.340
For short documents.

00:11:18.800 --> 00:11:20.480
And this gives you some insight for

00:11:20.480 --> 00:11:21.400
improving the better.

00:11:22.230 --> 00:11:24.520
Similarly, we can look at the popular

00:11:24.520 --> 00:11:25.840
category valuation.

00:11:25.840 --> 00:11:26.057
This.

00:11:26.057 --> 00:11:27.549
In this case we're going to look at the

00:11:27.550 --> 00:11:29.270
how good are the decision on a

00:11:29.270 --> 00:11:30.260
particular category.

00:11:30.260 --> 00:11:32.510
And as in the previous case, we can

00:11:32.510 --> 00:11:35.090
define precision and recall and it will

00:11:35.090 --> 00:11:37.460
just basically answer the questions

00:11:37.460 --> 00:11:38.890
from a different perspective.

00:11:39.530 --> 00:11:42.710
I saw when the system says yes, how

00:11:42.710 --> 00:11:45.750
many are corrected that means looking

00:11:45.750 --> 00:11:48.235
at this category to see if all the

00:11:48.235 --> 00:11:50.463
documents that are assigned with this

00:11:50.463 --> 00:11:53.329
category are indeed in this category.

00:11:53.330 --> 00:11:55.320
An recall would tell us has the

00:11:55.320 --> 00:11:56.851
category being actually assigned to all

00:11:56.851 --> 00:11:58.513
the documents that should have this

00:11:58.513 --> 00:11:58.839
category.

00:12:00.620 --> 00:12:02.490
Is sometimes also useful to combine

00:12:02.490 --> 00:12:04.810
precision and recall as one measure,

00:12:04.810 --> 00:12:07.770
and this is often done by using if

00:12:07.770 --> 00:12:07.992
mesh.

00:12:07.992 --> 00:12:10.210
And this is just the harmonic mean of

00:12:10.210 --> 00:12:12.120
precision and recall defined on this

00:12:12.120 --> 00:12:12.660
slide.

00:12:13.290 --> 00:12:13.960
Ann

00:12:14.520 --> 00:12:16.530
It's also controlled by a parameter

00:12:16.530 --> 00:12:20.970
beta two to indicate the weather

00:12:20.970 --> 00:12:23.167
precision is more important, or recall

00:12:23.167 --> 00:12:25.833
is more important when beta is set to

00:12:25.833 --> 00:12:28.240
one, we have a measure called F1, and

00:12:28.240 --> 00:12:31.430
in this case we just take a equal

00:12:31.430 --> 00:12:34.340
weight on both precision and recall.

00:12:34.340 --> 00:12:37.980
If one is very often used as a measure

00:12:37.980 --> 00:12:39.000
for categorisation.

00:12:39.810 --> 00:12:42.140
Now, as in all cases when we combine

00:12:42.140 --> 00:12:44.345
results, you always should think about

00:12:44.345 --> 00:12:45.873
the best way of combining them.

00:12:45.873 --> 00:12:47.323
So in this case I don't know if you

00:12:47.323 --> 00:12:49.316
have thought about it and we could have

00:12:49.316 --> 00:12:52.140
combining them just with the arithmetic

00:12:52.140 --> 00:12:52.820
mean, right?

00:12:52.820 --> 00:12:54.160
So that would still give it the same

00:12:54.160 --> 00:12:55.300
range of values.

00:12:56.260 --> 00:12:57.870
But obviously there's a reason why we

00:12:57.870 --> 00:12:59.339
didn't do that and why.

00:12:59.340 --> 00:13:01.530
If one is more popular and it's

00:13:01.530 --> 00:13:02.720
actually useful to think about

00:13:02.720 --> 00:13:03.340
difference.

00:13:03.960 --> 00:13:05.390
And if you think about that, you will

00:13:05.390 --> 00:13:08.030
see that there is indeed some

00:13:08.030 --> 00:13:09.520
difference and sum.

00:13:10.210 --> 00:13:12.430
Undesirable property of this arithmetic

00:13:12.430 --> 00:13:12.760
mean.

00:13:13.400 --> 00:13:15.100
Basically, it would be obvious to you

00:13:15.100 --> 00:13:18.520
if you think about a case when the

00:13:18.520 --> 00:13:20.910
system says yes for all the category

00:13:20.910 --> 00:13:22.020
and nothing appears.

00:13:22.640 --> 00:13:24.095
And even tried to compute the precision

00:13:24.095 --> 00:13:26.960
and recall in that case and see what

00:13:26.960 --> 00:13:27.530
would happen.

00:13:28.280 --> 00:13:32.885
I basically this kind of measure will

00:13:32.885 --> 00:13:35.720
not the arithmetic mean is not going to

00:13:35.720 --> 00:13:38.480
be as reasonable FF1, which tends to

00:13:38.480 --> 00:13:40.480
prefer a tradeoff between precision and

00:13:40.480 --> 00:13:41.190
recall.

00:13:42.680 --> 00:13:45.460
So that the two values are about equal,

00:13:45.460 --> 00:13:48.330
so we if there's an extreme case where

00:13:48.330 --> 00:13:51.560
you have 041 value and one for the

00:13:51.560 --> 00:13:54.370
other, than F1 will be low, but the

00:13:54.370 --> 00:13:55.920
arithmetic mean would still be

00:13:55.920 --> 00:13:56.880
reasonably high.


