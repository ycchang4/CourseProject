WEBVTT Kind: captions; Language: en-US

NOTE
Created on 2021-02-26T23:58:12.2717464Z by ClassTranscribe

00:00:00.300 --> 00:00:02.170
This lecture is about the text

00:00:02.170 --> 00:00:03.230
categorization.

00:00:11.240 --> 00:00:13.480
In this lecture we're going to talk

00:00:13.480 --> 00:00:15.450
about the text categorization.

00:00:16.310 --> 00:00:18.765
This is a very important technique for

00:00:18.765 --> 00:00:21.360
a text, data mining and analytics.

00:00:22.350 --> 00:00:26.680
It is relevant to discovery of various

00:00:26.680 --> 00:00:28.680
different kinds of knowledge as shown

00:00:28.680 --> 00:00:29.120
here.

00:00:29.120 --> 00:00:31.630
First is related to topic mining

00:00:31.630 --> 00:00:32.600
analysis.

00:00:33.270 --> 00:00:35.800
And that's because it has to do with

00:00:35.800 --> 00:00:38.780
analyzing text data based on some

00:00:38.780 --> 00:00:40.080
predefined topics.

00:00:40.870 --> 00:00:43.320
Secondly, it's also related to opinion

00:00:43.320 --> 00:00:45.830
mining and sentiment analysis, which

00:00:45.830 --> 00:00:47.750
has to do with discovering knowledge

00:00:47.750 --> 00:00:50.420
about the observer that the human

00:00:50.420 --> 00:00:50.830
sensor.

00:00:51.830 --> 00:00:55.920
Because we can categorize the authors,

00:00:55.920 --> 00:00:58.775
for example, based on the content of

00:00:58.775 --> 00:01:00.770
the articles that they have written.

00:01:01.560 --> 00:01:05.830
We can in general categorize the

00:01:05.830 --> 00:01:09.230
observer based on the content.

00:01:09.780 --> 00:01:11.120
That they produce.

00:01:11.710 --> 00:01:14.680
Finally, it's also related to text

00:01:14.680 --> 00:01:15.730
based prediction.

00:01:16.580 --> 00:01:18.600
Because we can often use text

00:01:18.600 --> 00:01:21.240
categorization techniques to predict

00:01:21.240 --> 00:01:23.840
some variables in the real world that

00:01:23.840 --> 00:01:26.340
are only remotely related to text data.

00:01:27.110 --> 00:01:31.270
And so this is a very important technique

00:01:31.270 --> 00:01:32.650
for text data mining.

00:01:34.750 --> 00:01:36.360
This is the overall plan for covering

00:01:36.360 --> 00:01:37.180
the topic.

00:01:37.750 --> 00:01:39.730
First we're going to talk about what is text

00:01:39.730 --> 00:01:41.990
categorization and why we are

00:01:41.990 --> 00:01:43.500
interested in doing that in this

00:01:43.500 --> 00:01:44.055
lecture.

00:01:44.055 --> 00:01:45.612
And then we're going to talk about how

00:01:45.612 --> 00:01:47.890
to do text categorisation followed by

00:01:47.890 --> 00:01:49.670
how to evaluate the categorisation

00:01:49.670 --> 00:01:51.300
results so.

00:01:51.980 --> 00:01:54.010
The problem of texture categorisation

00:01:54.010 --> 00:01:56.090
is defined as follows.

00:01:56.090 --> 00:01:58.430
We're given a set of predefined

00:01:58.430 --> 00:01:59.330
categories.

00:02:00.180 --> 00:02:02.840
Possibly forming a hierarchy so.

00:02:03.540 --> 00:02:06.759
And often also a set of training

00:02:06.760 --> 00:02:09.610
examples or training set of labeled

00:02:09.610 --> 00:02:10.690
text objects.

00:02:11.390 --> 00:02:13.820
Which means that text objects have

00:02:13.820 --> 00:02:16.800
already been labeled with known

00:02:16.800 --> 00:02:18.970
categories, and then the task is to

00:02:18.970 --> 00:02:23.060
classify any tax object into one or

00:02:23.060 --> 00:02:25.650
more of these predefined categories.

00:02:26.230 --> 00:02:28.270
So the picture on the slide shows

00:02:28.270 --> 00:02:29.200
what happens.

00:02:30.090 --> 00:02:32.460
When we do text categorization, we have

00:02:32.460 --> 00:02:34.930
a lot of text objects to be processed

00:02:34.930 --> 00:02:36.640
by a categorisation system.

00:02:37.280 --> 00:02:40.490
And the system will in general assign

00:02:40.490 --> 00:02:44.750
categories to these documents as shown

00:02:44.750 --> 00:02:46.180
on the right.

00:02:46.760 --> 00:02:48.330
And the categorisation results.

00:02:48.990 --> 00:02:52.970
And we often assume the availability of

00:02:52.970 --> 00:02:55.100
training examples, and these are the

00:02:55.100 --> 00:02:57.960
documents that are tagged with known

00:02:57.960 --> 00:03:00.900
categories, and these examples are very

00:03:00.900 --> 00:03:02.900
important for helping the system to

00:03:02.900 --> 00:03:05.580
learn patterns in different categories,

00:03:05.580 --> 00:03:08.349
and this would further help the system

00:03:08.350 --> 00:03:10.490
then learn how to recognize.

00:03:11.180 --> 00:03:14.580
The categories of new tax objects that

00:03:14.580 --> 00:03:15.780
it has not seen.

00:03:16.450 --> 00:03:19.250
So here are some specific examples of

00:03:19.250 --> 00:03:21.470
text categorization and

00:03:22.500 --> 00:03:24.900
In fact, there are many examples.

00:03:24.900 --> 00:03:26.260
Here are just a few.

00:03:27.110 --> 00:03:30.200
So first text objects can vary, so we

00:03:30.200 --> 00:03:32.190
can categorize a document.

00:03:32.850 --> 00:03:35.910
Or a passage or sentence or collections

00:03:35.910 --> 00:03:38.100
of text, as in the case of clustering

00:03:38.100 --> 00:03:40.860
the units to be analyzed can vary a

00:03:40.860 --> 00:03:42.630
lot, so this creates a lot of

00:03:42.630 --> 00:03:43.410
possibilities.

00:03:43.960 --> 00:03:46.800
Secondly, categories can also vary, and

00:03:46.800 --> 00:03:48.666
we can generally distinguish two kinds

00:03:48.666 --> 00:03:49.539
of categories.

00:03:49.540 --> 00:03:51.560
One is internal categories.

00:03:51.560 --> 00:03:53.900
These are categories that characterize

00:03:53.900 --> 00:03:55.700
content of text object.

00:03:55.700 --> 00:03:57.690
For example, topic categories.

00:03:58.660 --> 00:04:01.330
Or sentiment categories and they

00:04:01.330 --> 00:04:03.182
generally have to do with the content

00:04:03.182 --> 00:04:05.270
of the tax objects, direct

00:04:05.270 --> 00:04:07.030
Characterization of the content.

00:04:08.060 --> 00:04:10.780
The other kind is external categories

00:04:10.780 --> 00:04:13.230
that can characterize the entity

00:04:13.230 --> 00:04:16.010
associated with the text object.

00:04:16.010 --> 00:04:18.910
For example, authors or entities

00:04:18.910 --> 00:04:21.410
associated with the content that they

00:04:21.410 --> 00:04:22.140
produce.

00:04:22.690 --> 00:04:24.730
And so we can use their content,

00:04:24.730 --> 00:04:28.040
determine which author has written

00:04:28.040 --> 00:04:30.520
which part, for example, and that's

00:04:30.520 --> 00:04:31.830
called author attribution.

00:04:33.410 --> 00:04:36.650
Or we can have any other meaningful

00:04:36.650 --> 00:04:38.790
categories associated with text data,

00:04:38.790 --> 00:04:40.190
as long as.

00:04:41.470 --> 00:04:42.460
There is a.

00:04:43.530 --> 00:04:45.800
There are, there's a meaningful

00:04:45.800 --> 00:04:47.740
connection between the entity and text

00:04:47.740 --> 00:04:48.020
data.

00:04:48.020 --> 00:04:49.810
For example, we might collect a lot of

00:04:49.810 --> 00:04:51.680
reviews about a restaurant.

00:04:52.290 --> 00:04:55.020
Or a lot of reviews about the product.

00:04:55.650 --> 00:04:58.080
And then these text data can help

00:04:58.080 --> 00:05:02.190
us infer properties of product or

00:05:02.190 --> 00:05:03.730
a restaurant.

00:05:04.630 --> 00:05:06.590
In that case, we can treat this as a

00:05:06.590 --> 00:05:07.632
categorization problem.

00:05:07.632 --> 00:05:09.690
We can categorize restaurants or

00:05:09.690 --> 00:05:11.910
categorize products based on their

00:05:11.910 --> 00:05:13.350
corresponding reviews.

00:05:13.930 --> 00:05:15.600
So this is example of external

00:05:15.600 --> 00:05:16.100
category.

00:05:17.420 --> 00:05:19.170
Here are some specific examples of

00:05:19.170 --> 00:05:19.975
applications.

00:05:19.975 --> 00:05:22.510
News categorization is very common, has

00:05:22.510 --> 00:05:23.910
been stuided.

00:05:23.910 --> 00:05:24.470
A lot.

00:05:24.470 --> 00:05:27.680
News agencies would like to assign

00:05:27.680 --> 00:05:31.950
predefined categories to categorize

00:05:31.950 --> 00:05:34.470
news generated every day.

00:05:35.850 --> 00:05:38.690
And literature article categorizations

00:05:38.690 --> 00:05:41.210
another important task, for example, in

00:05:41.210 --> 00:05:42.043
biomedical domain,

00:05:42.043 --> 00:05:44.485
Is this mesh annotations , mesh stands

00:05:44.485 --> 00:05:46.060
for medical subject heading.

00:05:46.060 --> 00:05:48.030
And this is ontology of terms

00:05:48.030 --> 00:05:51.560
characterize content of literature

00:05:51.560 --> 00:05:52.650
articles in detail.

00:05:54.470 --> 00:05:57.520
Another example of application spam,

00:05:57.520 --> 00:05:59.920
email detection or filtering right?

00:05:59.920 --> 00:06:05.390
So we often have a spam filter to help

00:06:05.390 --> 00:06:09.090
us distinguish spam from legitimate

00:06:09.090 --> 00:06:11.840
emails, and this is clearly a binary

00:06:11.840 --> 00:06:13.360
classification problem.

00:06:14.240 --> 00:06:16.040
Sentiment categorization of

00:06:16.040 --> 00:06:18.460
product reviews or tweets is yet

00:06:18.460 --> 00:06:20.060
another kind of applications where we

00:06:20.060 --> 00:06:23.038
can categorize content into positive or

00:06:23.038 --> 00:06:25.920
negative or positive and negative or

00:06:25.920 --> 00:06:26.480
neutral.

00:06:27.230 --> 00:06:29.150
so you can have the same sentiment

00:06:29.150 --> 00:06:30.430
categories assigned.

00:06:30.430 --> 00:06:32.940
to text content.

00:06:35.430 --> 00:06:37.050
Another application is automatically

00:06:37.050 --> 00:06:39.840
email routing or sorting, so you might

00:06:39.840 --> 00:06:41.170
want to automatically sort your

00:06:41.170 --> 00:06:43.030
emails into different folders, and

00:06:43.030 --> 00:06:44.930
that's one application of text

00:06:44.930 --> 00:06:46.840
categorization, where each folder is a

00:06:46.840 --> 00:06:47.500
category.

00:06:48.160 --> 00:06:50.200
There is also another important kind of

00:06:50.200 --> 00:06:53.066
applications of routing emails to the

00:06:53.066 --> 00:06:54.179
right person to handle.

00:06:54.180 --> 00:06:58.110
So in helpdesk email messages generally

00:06:58.110 --> 00:07:01.716
routed to a particular person to handle

00:07:01.716 --> 00:07:03.633
different people attempt to handle

00:07:03.633 --> 00:07:06.210
different kinds of requests and in many

00:07:06.210 --> 00:07:09.578
cases a person will manually assign the

00:07:09.578 --> 00:07:11.469
messages to the right people.

00:07:11.470 --> 00:07:12.890
But you can imagine you can build

00:07:12.890 --> 00:07:15.940
automatic text categorization system to

00:07:15.940 --> 00:07:18.350
help routing a request.

00:07:18.970 --> 00:07:21.000
And this is to classify the incoming

00:07:21.000 --> 00:07:23.360
request in to one of the categories

00:07:23.360 --> 00:07:25.280
where each category actually

00:07:25.280 --> 00:07:28.625
corresponds to a person to handle the

00:07:28.625 --> 00:07:29.550
request.

00:07:31.080 --> 00:07:33.040
And finally, author Attribution.

00:07:33.040 --> 00:07:34.790
As I just mentioned, is yet another

00:07:34.790 --> 00:07:36.950
application, and it's another example

00:07:36.950 --> 00:07:38.930
of using text to actually infer

00:07:38.930 --> 00:07:42.550
properties of some other entities.

00:07:42.550 --> 00:07:45.010
And there are also many variants of the

00:07:45.010 --> 00:07:48.080
problem formulation and so first we

00:07:48.080 --> 00:07:49.660
have the simplest case, which is a

00:07:49.660 --> 00:07:51.430
binary categorization where there are

00:07:51.430 --> 00:07:54.040
only two categories and there are many

00:07:54.040 --> 00:07:55.700
examples like that information

00:07:55.700 --> 00:07:59.800
retrieval or search engine applications

00:07:59.800 --> 00:08:00.720
would want to.

00:08:01.090 --> 00:08:02.980
Distinguish it relevant documents from

00:08:02.980 --> 00:08:04.640
non relevant documents for a particular

00:08:04.640 --> 00:08:05.120
query.

00:08:05.940 --> 00:08:07.850
Spam filter is interesting.

00:08:07.850 --> 00:08:10.120
Distinguishing spams from non spam.

00:08:10.120 --> 00:08:12.180
So also two categories.

00:08:12.180 --> 00:08:15.260
Sometimes classification of opinions

00:08:15.260 --> 00:08:17.390
can be in two categories, positive and

00:08:17.390 --> 00:08:17.950
negative.

00:08:19.010 --> 00:08:20.740
A more general case would be K-category

00:08:20.740 --> 00:08:22.310
categorization and there are

00:08:22.310 --> 00:08:24.125
also many applications like that.

00:08:24.125 --> 00:08:25.510
There could be more than two

00:08:25.510 --> 00:08:28.060
categories, so topical categorisation

00:08:28.060 --> 00:08:29.920
is often such example where you can

00:08:29.920 --> 00:08:31.200
have multiple topics.

00:08:31.810 --> 00:08:34.220
Email routing would be another example

00:08:34.220 --> 00:08:36.200
when you may have multiple folders, or

00:08:36.200 --> 00:08:37.780
if you route the email to the right

00:08:37.780 --> 00:08:39.920
person to handle it, then there are

00:08:39.920 --> 00:08:41.940
multiple people, to clasify

00:08:43.250 --> 00:08:46.730
so in all these cases there are more

00:08:46.730 --> 00:08:48.110
than two kinds of categories.

00:08:49.130 --> 00:08:50.210
And another variation

00:08:50.210 --> 00:08:52.230
to have hierarchical categorization,

00:08:52.230 --> 00:08:54.360
where categories form hierarchy,

00:08:54.360 --> 00:08:56.250
again, topical hierarchy is very

00:08:56.250 --> 00:08:56.830
common. Yet another variation is joint categorization. That's when you have multiple categorization tasks that are related. And then you hope to kind of do joint categorization. Try to leverage the dependents of these tasks to improve accuracy for each individual task.

00:09:15.090 --> 00:09:17.095
Now among all these, binary

00:09:17.095 --> 00:09:19.670
categorization is most fundamental and

00:09:19.670 --> 00:09:23.670
partly also because it's simple and

00:09:23.670 --> 00:09:26.250
partly it's cause it can actually be

00:09:26.250 --> 00:09:29.055
used to perform all the other

00:09:29.055 --> 00:09:30.170
categorization tasks.

00:09:30.170 --> 00:09:33.590
For example, K category categorisation

00:09:33.590 --> 00:09:37.410
task can be actually performed by using

00:09:37.410 --> 00:09:38.760
binary categorization.

00:09:39.490 --> 00:09:41.705
And basically we can look at each

00:09:41.705 --> 00:09:44.290
category separately and then the binary

00:09:44.290 --> 00:09:46.860
categorization problem is whether

00:09:46.860 --> 00:09:50.060
object is in this category or not.

00:09:50.060 --> 00:09:52.060
Meaning in other categories.

00:09:53.310 --> 00:09:55.463
And the hierarchical category

00:09:55.463 --> 00:09:57.970
categorisation can also be done by

00:09:57.970 --> 00:10:02.400
progressively doing flat categorisation

00:10:02.400 --> 00:10:04.220
at each level.

00:10:04.220 --> 00:10:05.910
So we can first categorize all the

00:10:05.910 --> 00:10:06.760
objects in tune.

00:10:06.760 --> 00:10:08.655
It's a small number of high level

00:10:08.655 --> 00:10:10.486
categories an inside each category.

00:10:10.486 --> 00:10:13.000
We can further categorize into sub

00:10:13.000 --> 00:10:14.110
categories etc.

00:10:14.890 --> 00:10:17.070
So why is text categories important

00:10:17.070 --> 00:10:18.850
well, I already showed you several

00:10:18.850 --> 00:10:22.125
applications, but in general there are

00:10:22.125 --> 00:10:23.290
several reasons.

00:10:23.290 --> 00:10:24.930
One is text

00:10:24.930 --> 00:10:26.850
Categorization helps us enrich text

00:10:26.850 --> 00:10:29.750
representation, and that's to achieve

00:10:29.750 --> 00:10:31.830
more understanding of text data that's

00:10:31.830 --> 00:10:34.220
always useful for text analysis.

00:10:34.880 --> 00:10:37.240
So now with categorisation, text can be

00:10:37.240 --> 00:10:39.660
represented in multiple levels, meaning

00:10:39.660 --> 00:10:42.830
keyword bag of words representation as

00:10:42.830 --> 00:10:46.019
often used for a lot of text

00:10:46.020 --> 00:10:47.050
processing tasks.

00:10:47.050 --> 00:10:49.670
But we can also add categories and they

00:10:49.670 --> 00:10:52.559
provide 2 levels of representation.

00:10:54.160 --> 00:10:56.570
Semantic categories assigned can

00:10:56.570 --> 00:10:58.615
also be directly or indirectly useful

00:10:58.615 --> 00:10:59.560
for application.

00:10:59.560 --> 00:11:01.810
So for example, sentiment categories

00:11:01.810 --> 00:11:05.000
could be already very useful, or author

00:11:05.000 --> 00:11:07.660
Attribution might be directly useful.

00:11:10.750 --> 00:11:11.460
And.

00:11:12.410 --> 00:11:15.610
Another example is when semantic

00:11:15.610 --> 00:11:18.445
categories can facilitate aggregation

00:11:18.445 --> 00:11:20.569
of tax content, and this is another

00:11:20.570 --> 00:11:21.250
case of.

00:11:22.670 --> 00:11:24.930
Applications of text categorisation.

00:11:25.760 --> 00:11:28.030
For example, we if we want to know the

00:11:28.030 --> 00:11:31.960
overall opinions about the product, we

00:11:31.960 --> 00:11:35.510
could first categorize the opinions in

00:11:35.510 --> 00:11:38.990
each individual review as positive or

00:11:38.990 --> 00:11:41.203
negative, and then that would allow us

00:11:41.203 --> 00:11:44.660
to easily aggregate all the sentiments

00:11:44.660 --> 00:11:49.530
and it will tell us about 70% of the

00:11:49.530 --> 00:11:52.340
views positive and 30% are negative,

00:11:52.340 --> 00:11:53.070
etc.

00:11:53.670 --> 00:11:55.760
So without doing categorization it will

00:11:55.760 --> 00:11:58.260
be much harder to aggregate such

00:11:58.260 --> 00:11:59.000
opinions.

00:12:00.310 --> 00:12:03.840
So it provides a concise way of coding

00:12:03.840 --> 00:12:06.190
text in some sense based on our

00:12:06.190 --> 00:12:06.960
vocabulary.

00:12:07.640 --> 00:12:09.280
And sometimes you miss seeing some

00:12:09.280 --> 00:12:11.850
applications, text or categorization is

00:12:11.850 --> 00:12:15.370
called a text coding encoding with some

00:12:15.370 --> 00:12:16.460
controller vocabulary.

00:12:18.640 --> 00:12:23.560
The second kind of reasons is to use

00:12:23.560 --> 00:12:26.825
text categorization to infer properties

00:12:26.825 --> 00:12:27.860
of entities.

00:12:28.970 --> 00:12:31.140
And text categorisation allows us to

00:12:31.140 --> 00:12:34.550
infer the properties of such entities

00:12:34.550 --> 00:12:36.910
that are associated with text data.

00:12:36.910 --> 00:12:40.430
So this means we can use text

00:12:40.430 --> 00:12:42.790
categorization to discover knowledge

00:12:42.790 --> 00:12:45.310
about the world in general, as long as

00:12:45.310 --> 00:12:47.696
we can associate the entity with text

00:12:47.696 --> 00:12:50.056
data, we can always use the text data

00:12:50.056 --> 00:12:52.140
to help categorize the corresponding

00:12:52.140 --> 00:12:52.800
entities.

00:12:53.480 --> 00:12:55.200
So it's useful to think about the

00:12:55.200 --> 00:12:56.827
information network that will connect

00:12:56.827 --> 00:12:59.076
the other entities with text data.

00:12:59.076 --> 00:13:01.915
The obvious entities that can be

00:13:01.915 --> 00:13:04.265
directly connected are authors, but you

00:13:04.265 --> 00:13:05.839
can also imagine the authors

00:13:05.840 --> 00:13:08.385
affiliations or the authors ages and

00:13:08.385 --> 00:13:11.090
other things can be actually connected

00:13:11.090 --> 00:13:13.900
to text data indirectly.

00:13:13.900 --> 00:13:15.752
Once we can make the connection, then

00:13:15.752 --> 00:13:17.640
we can make predictions about those

00:13:17.640 --> 00:13:18.770
values.

00:13:18.770 --> 00:13:21.900
So this is a general way to allow us to

00:13:21.900 --> 00:13:23.270
use text mining tool.

00:13:23.270 --> 00:13:25.130
Sorry, text categorization to discover

00:13:25.130 --> 00:13:26.360
knowledge about the world.

00:13:26.840 --> 00:13:30.050
Very useful, especially in big text

00:13:30.050 --> 00:13:30.440
data.

00:13:30.440 --> 00:13:32.860
Analytics, where we are often interested in

00:13:32.860 --> 00:13:36.390
using text data as extra sensor data

00:13:36.390 --> 00:13:39.460
collected from humans to infer certain

00:13:39.460 --> 00:13:41.160
desicion factors.

00:13:41.720 --> 00:13:43.830
Often together with non text data

00:13:43.830 --> 00:13:45.150
specifically to text.

00:13:45.150 --> 00:13:46.600
For example, we can also think of

00:13:46.600 --> 00:13:48.550
examples of inferring properties of

00:13:48.550 --> 00:13:49.160
entities.

00:13:49.160 --> 00:13:51.070
For example discovery of non native

00:13:51.070 --> 00:13:53.690
speakers of a language and this can be

00:13:53.690 --> 00:13:57.200
done by categorizing the content of.

00:13:58.630 --> 00:13:59.520
Speakers

00:14:00.570 --> 00:14:02.610
Another example is to predict the

00:14:02.610 --> 00:14:05.760
party affiliation of a politician based on

00:14:05.760 --> 00:14:08.500
the political speech at this is again

00:14:08.500 --> 00:14:11.890
example of using text data to infer

00:14:11.890 --> 00:14:14.040
some knowledge about real world.

00:14:15.340 --> 00:14:18.276
In nature this all the problems are all

00:14:18.276 --> 00:14:21.580
the same and that's as we defined and

00:14:21.580 --> 00:14:23.990
it's a text categorization problem.


