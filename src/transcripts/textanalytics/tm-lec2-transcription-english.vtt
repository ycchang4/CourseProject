WEBVTT Kind: captions; Language: en-US

NOTE
Created on 2021-02-26T23:59:32.3684837Z by ClassTranscribe

00:00:00.290 --> 00:00:02.070
So looking at the text mining

00:00:02.070 --> 00:00:05.233
problem more closely, we see that the

00:00:05.233 --> 00:00:07.330
problem is similar to general data

00:00:07.330 --> 00:00:09.700
mining, except that we'll be focusing

00:00:09.700 --> 00:00:11.060
more on text data.

00:00:21.590 --> 00:00:23.260
And we're going to have text mining

00:00:23.260 --> 00:00:26.420
algorithms to help us to turn text data

00:00:26.420 --> 00:00:28.980
into actionable knowledge that we can

00:00:28.980 --> 00:00:31.540
use in (the) real world.

00:00:32.120 --> 00:00:34.480
Especially for decision making or for

00:00:34.480 --> 00:00:37.320
completing whatever tasks that require

00:00:37.320 --> 00:00:40.540
text data to support, now because in

00:00:40.540 --> 00:00:43.980
general in many real world problems of

00:00:43.980 --> 00:00:46.730
data mining, we also tend to have

00:00:46.730 --> 00:00:48.420
other kinds of data that are non

00:00:48.420 --> 00:00:49.040
textual.

00:00:49.610 --> 00:00:52.820
So a more general picture would be to

00:00:52.820 --> 00:00:55.100
include non text data as well.

00:00:55.870 --> 00:00:57.970
And for this reason, we might be

00:00:57.970 --> 00:01:00.820
concerned with joint mining of text and

00:01:00.820 --> 00:01:03.160
non text data and so in this course

00:01:03.160 --> 00:01:05.185
we're going to focus more on text

00:01:05.185 --> 00:01:05.590
mining.

00:01:05.590 --> 00:01:09.090
But we can also touch how to join the

00:01:09.090 --> 00:01:11.811
analysis of both text data and non-text

00:01:11.811 --> 00:01:14.163
data. With this problem definition we

00:01:14.163 --> 00:01:16.730
can now look at the landscape of the

00:01:16.730 --> 00:01:19.670
topics in text mining analytics.

00:01:20.810 --> 00:01:23.790
Now this slide shows the process of

00:01:23.790 --> 00:01:25.970
generating text data in more detail.

00:01:26.880 --> 00:01:29.870
Most specifically, human sensor or

00:01:29.870 --> 00:01:31.860
human observer would look at the world

00:01:31.860 --> 00:01:33.560
from some perspective.

00:01:34.460 --> 00:01:36.250
Different people would be looking at

00:01:36.250 --> 00:01:38.760
the world from different angles and

00:01:38.760 --> 00:01:40.020
they will pay attention to different

00:01:40.020 --> 00:01:40.440
things.

00:01:41.120 --> 00:01:43.220
The same person at a different time might

00:01:43.220 --> 00:01:46.070
also pay attention to different aspects

00:01:46.070 --> 00:01:49.420
of the observed world.

00:01:50.130 --> 00:01:52.195
And so the human sensor would perceive

00:01:52.195 --> 00:01:54.060
the world from some perspective.

00:01:55.310 --> 00:01:56.920
And that human...

00:01:56.920 --> 00:02:00.517
The sensor would then form a view of

00:02:00.517 --> 00:02:03.630
the world and that can be called the

00:02:03.630 --> 00:02:04.130
observed

00:02:04.130 --> 00:02:04.850
world.

00:02:04.850 --> 00:02:07.240
Of course this would be different from

00:02:07.240 --> 00:02:08.850
the real world because of the

00:02:08.850 --> 00:02:12.040
perspective that the person has taken.

00:02:12.040 --> 00:02:15.000
This can often be biased also.

00:02:16.700 --> 00:02:19.800
Now the observable world can be

00:02:21.270 --> 00:02:23.850
represented as for example entity

00:02:23.850 --> 00:02:27.330
relation graphs or more in a more

00:02:27.330 --> 00:02:29.830
general way, using knowledge

00:02:29.830 --> 00:02:31.010
representation language.

00:02:31.800 --> 00:02:35.140
But in general, this is basically what

00:02:35.140 --> 00:02:39.070
a person has in mind about the world,

00:02:39.070 --> 00:02:41.670
and we don't really know what exactly

00:02:41.670 --> 00:02:43.100
it looks like, of course.

00:02:43.710 --> 00:02:46.955
But then the human would express what

00:02:46.955 --> 00:02:50.690
the person has observed using a natural

00:02:50.690 --> 00:02:53.330
language such as English, and the

00:02:53.330 --> 00:02:54.920
result is text data.

00:02:55.750 --> 00:02:57.435
Of course, the person could have used a

00:02:57.435 --> 00:03:00.480
different language to express what he

00:03:00.480 --> 00:03:02.010
or she has observed.

00:03:02.010 --> 00:03:04.955
In that case, we might have text data

00:03:04.955 --> 00:03:07.785
of mixed languages for different

00:03:07.785 --> 00:03:08.310
languages.

00:03:09.850 --> 00:03:12.720
So the main goal of text mining is

00:03:12.720 --> 00:03:16.550
actually to revert this process of

00:03:16.550 --> 00:03:18.020
generating test data.

00:03:19.040 --> 00:03:22.370
And we hope to be able to uncover some

00:03:22.370 --> 00:03:24.510
aspect in this process.

00:03:26.490 --> 00:03:29.910
And so specifically we can think about

00:03:29.910 --> 00:03:32.440
the mining, for example, knowledge

00:03:32.440 --> 00:03:33.680
about the language.

00:03:35.310 --> 00:03:37.180
And that means by looking at text

00:03:37.180 --> 00:03:39.540
data in English, we may be able to

00:03:39.540 --> 00:03:42.230
discover something about English...

00:03:42.230 --> 00:03:43.680
Some usage of English...

00:03:44.460 --> 00:03:46.400
Some patterns of English.

00:03:47.660 --> 00:03:51.010
So this is 1 type of mining problems

00:03:51.010 --> 00:03:53.410
where the result is some knowledge

00:03:53.410 --> 00:03:55.390
about language which may be useful

00:03:56.130 --> 00:03:57.120
in various ways.

00:03:58.790 --> 00:04:01.860
If you look at the picture, we can also

00:04:01.860 --> 00:04:05.010
then mine knowledge about the "Observed

00:04:05.010 --> 00:04:05.650
World".

00:04:06.250 --> 00:04:08.570
As so, this has much to do with mining

00:04:08.570 --> 00:04:10.200
the content of text data.

00:04:11.390 --> 00:04:12.570
We're going to look at the what the

00:04:12.570 --> 00:04:15.920
text data are about and then try to get

00:04:15.920 --> 00:04:17.060
the essence of it.

00:04:17.060 --> 00:04:20.640
Or extracting high quality information

00:04:20.640 --> 00:04:24.460
about a particular aspect of the world

00:04:24.460 --> 00:04:25.760
that we're interested in.

00:04:26.780 --> 00:04:28.870
For example, everything that has been

00:04:28.870 --> 00:04:30.920
said about a particular person or

00:04:30.920 --> 00:04:32.990
particular entity, and this can be

00:04:32.990 --> 00:04:37.230
regarded as mining content to describe

00:04:37.230 --> 00:04:41.762
the observed world in the user's mind,

00:04:41.762 --> 00:04:43.550
in the person's mind.

00:04:44.890 --> 00:04:48.030
If you look further then you can also

00:04:48.780 --> 00:04:51.710
imagine we can mine knowledge about

00:04:51.710 --> 00:04:54.590
this observer himself or herself.

00:04:54.590 --> 00:04:58.450
So this has also to do with using text

00:04:58.450 --> 00:05:01.690
data to infer some properties of

00:05:01.690 --> 00:05:02.420
this person.

00:05:03.240 --> 00:05:05.420
And these properties could include the

00:05:05.420 --> 00:05:08.652
mood of the person or sentiment of the

00:05:08.652 --> 00:05:09.060
person.

00:05:10.080 --> 00:05:12.570
And note that we distinguish the

00:05:12.570 --> 00:05:15.150
observed the world from the person

00:05:15.150 --> 00:05:17.866
because text data can describe what

00:05:17.866 --> 00:05:19.499
the person has observed in an

00:05:19.500 --> 00:05:22.710
objective way, but the description can

00:05:22.710 --> 00:05:26.040
be also subject with sentiment, and so

00:05:26.040 --> 00:05:28.240
in general you can imagine the text

00:05:28.240 --> 00:05:30.250
data would contain some factual

00:05:30.250 --> 00:05:33.160
descriptions of the world plus some

00:05:33.160 --> 00:05:35.830
subjective comments, so that's why it's

00:05:35.830 --> 00:05:39.150
also possible to do text mining to mine

00:05:39.150 --> 00:05:40.070
knowledge

00:05:40.120 --> 00:05:41.500
about the observer.

00:05:41.500 --> 00:05:43.574
Finally, if you look at the picture to

00:05:43.574 --> 00:05:46.285
the left side of this picture, then you

00:05:46.285 --> 00:05:48.070
can see we can certainly also say

00:05:48.070 --> 00:05:50.470
something about the real world, right?

00:05:50.470 --> 00:05:53.960
So indeed we can do text mining to

00:05:53.960 --> 00:05:56.720
infer other real world variables, and

00:05:56.720 --> 00:05:58.490
this is often called predictive

00:05:58.490 --> 00:05:59.290
analytics.

00:05:59.880 --> 00:06:02.060
And we want to predict the value of

00:06:02.060 --> 00:06:03.730
certain interesting variables.

00:06:06.250 --> 00:06:09.020
So this picture basically covered

00:06:09.020 --> 00:06:11.410
multiple types of knowledge that we can

00:06:11.410 --> 00:06:13.600
mine from text in general.

00:06:14.360 --> 00:06:17.842
When we infer other real world

00:06:17.842 --> 00:06:22.468
variables, we could also use some of

00:06:22.468 --> 00:06:26.400
the results from mining text data as

00:06:26.400 --> 00:06:29.650
intermediate results to help the

00:06:29.650 --> 00:06:30.260
prediction.

00:06:30.260 --> 00:06:33.340
For example, after we mine the content

00:06:33.340 --> 00:06:36.046
of text data, we might generate some

00:06:36.046 --> 00:06:39.033
summary of content, and that summary

00:06:39.033 --> 00:06:42.872
could be then used to help us predict

00:06:42.872 --> 00:06:44.470
the variables of

00:06:44.640 --> 00:06:45.880
the real world.

00:06:45.880 --> 00:06:49.780
Now of course, this is still generated

00:06:49.780 --> 00:06:52.780
from the original text data, but I want

00:06:52.780 --> 00:06:56.770
to emphasize here that often the

00:06:56.770 --> 00:06:58.870
processing of text data to generate

00:06:58.870 --> 00:07:01.350
some features that can help

00:07:01.350 --> 00:07:03.960
with the prediction, is very important.

00:07:04.810 --> 00:07:08.100
And that's why here we show that the

00:07:08.100 --> 00:07:11.890
results of some other mining tasks,

00:07:11.890 --> 00:07:14.250
including mining the content of text

00:07:14.250 --> 00:07:16.150
data and mining knowledge above the

00:07:16.150 --> 00:07:19.030
observer can all be very helpful for

00:07:19.030 --> 00:07:19.650
prediction.

00:07:21.240 --> 00:07:24.490
In fact, when we have a non-text data,

00:07:24.490 --> 00:07:27.650
we could also use the non-text data to

00:07:27.650 --> 00:07:28.710
help prediction.

00:07:29.460 --> 00:07:31.090
And of course, it depends on the

00:07:31.090 --> 00:07:31.790
problem.

00:07:33.180 --> 00:07:35.990
In general, non-text data can be

00:07:35.990 --> 00:07:38.400
very important for such prediction

00:07:38.400 --> 00:07:39.020
tasks.

00:07:39.020 --> 00:07:41.080
For example, if you want to predict the

00:07:41.080 --> 00:07:41.780
stocks.

00:07:42.540 --> 00:07:46.639
Stock prices or changes of stock prices

00:07:46.640 --> 00:07:48.990
based on discussion in the news

00:07:48.990 --> 00:07:52.380
articles or in social media, then this

00:07:52.380 --> 00:07:54.870
is an example of using text data to

00:07:54.870 --> 00:07:57.200
predict some other real world

00:07:57.200 --> 00:07:58.080
variables.

00:07:58.080 --> 00:08:00.040
Now in this case, obviously the

00:08:00.040 --> 00:08:03.009
historical stock price data would be

00:08:03.010 --> 00:08:05.040
very important for this prediction, and

00:08:05.040 --> 00:08:07.750
so that's example of non-text data that

00:08:07.750 --> 00:08:08.340
would be

00:08:09.690 --> 00:08:13.960
very useful for the prediction and we

00:08:13.960 --> 00:08:16.660
can combine both kinds of data to make

00:08:16.660 --> 00:08:17.340
the prediction.

00:08:18.310 --> 00:08:20.260
Now non-text data can be also

00:08:20.260 --> 00:08:23.790
useful for analyzing text by supplying

00:08:23.790 --> 00:08:24.580
context.

00:08:25.440 --> 00:08:27.380
When we look at the text data alone

00:08:27.380 --> 00:08:29.290
will be mostly looking at the content

00:08:29.290 --> 00:08:31.810
and opinions expressed in text.

00:08:32.670 --> 00:08:35.250
But text data generally have also

00:08:35.250 --> 00:08:36.560
context associated.

00:08:37.280 --> 00:08:39.900
For example, the time, the location,

00:08:39.900 --> 00:08:44.040
of that associated with the text data

00:08:44.040 --> 00:08:47.050
and these are useful context

00:08:47.050 --> 00:08:47.740
information.

00:08:48.610 --> 00:08:50.430
And the context can provide

00:08:50.430 --> 00:08:53.270
interesting angles for analyzing text

00:08:53.270 --> 00:08:53.660
data.

00:08:53.660 --> 00:08:55.720
For example, we might partition text

00:08:55.720 --> 00:08:57.650
data into different time periods

00:08:57.650 --> 00:08:59.960
because of the availability of time.

00:09:00.530 --> 00:09:03.830
Now we can analyze text data in each

00:09:03.830 --> 00:09:05.700
time period and then make a comparison.

00:09:06.340 --> 00:09:08.640
Similarly, we can partition text data

00:09:08.640 --> 00:09:11.460
based on locations or any metadata that's

00:09:11.460 --> 00:09:12.180
associated

00:09:12.870 --> 00:09:14.760
to form interesting comparison

00:09:14.760 --> 00:09:15.800
scenarios.

00:09:15.800 --> 00:09:19.040
So in this sense, non-text data can

00:09:19.040 --> 00:09:22.350
actually provide interesting angles or

00:09:22.350 --> 00:09:24.720
perspectives for text analysis, and

00:09:24.720 --> 00:09:28.520
can help us make context sensitive

00:09:29.070 --> 00:09:32.160
analysis of content or the language

00:09:32.160 --> 00:09:34.699
usage or the

00:09:36.130 --> 00:09:39.440
opinions about the observer or the

00:09:39.440 --> 00:09:41.120
authors of text data.

00:09:41.120 --> 00:09:43.450
We could analyze the sentiment

00:09:45.190 --> 00:09:49.640
in different context, so this is fairly

00:09:49.640 --> 00:09:52.480
general landscape of the topics in text

00:09:52.480 --> 00:09:53.820
mining and analytics.

00:09:54.370 --> 00:09:55.840
In this course we're going to

00:09:55.840 --> 00:09:58.450
selectively cover some of those topics.

00:09:59.720 --> 00:10:02.230
We actually hope to cover most of

00:10:02.230 --> 00:10:04.580
these general topics.

00:10:06.780 --> 00:10:10.020
First, we are going to cover natural language

00:10:10.020 --> 00:10:12.220
processing very briefly because

00:10:12.220 --> 00:10:14.920
this has to do with understanding text

00:10:14.920 --> 00:10:18.679
data, and this determines how we can

00:10:18.680 --> 00:10:21.460
represent text for text mining.

00:10:21.460 --> 00:10:23.981
Second, we're going to talk about how

00:10:23.981 --> 00:10:27.360
to mine word associations from text

00:10:27.360 --> 00:10:30.860
data and word associations is a form of

00:10:30.860 --> 00:10:33.630
useful lexical knowledge about a

00:10:33.630 --> 00:10:34.170
language.

00:10:34.170 --> 00:10:36.100
Third, we're going to talk about the

00:10:36.100 --> 00:10:37.070
topic mining

00:10:37.120 --> 00:10:40.060
and analysis, and this is only one way

00:10:40.060 --> 00:10:43.350
to analyze content of text, but it's a

00:10:43.350 --> 00:10:45.925
very useful way of analyzing content.

00:10:45.925 --> 00:10:49.500
It's also one of the most useful

00:10:49.500 --> 00:10:51.520
techniques in text mining.

00:10:53.610 --> 00:10:56.080
And then we're going to talk about

00:10:57.160 --> 00:10:59.410
opinion mining and sentiment analysis.

00:10:59.410 --> 00:11:02.750
So this can be regarded as one example

00:11:02.750 --> 00:11:05.460
of mining knowledge about the observer.

00:11:07.000 --> 00:11:10.033
And finally, we are going to cover a text

00:11:10.033 --> 00:11:12.570
based prediction problems where we try

00:11:12.570 --> 00:11:14.950
to predict some real world variable

00:11:14.950 --> 00:11:16.190
based on text data.

00:11:17.260 --> 00:11:22.410
So this slide also serves as a road map

00:11:22.410 --> 00:11:24.040
for this course.

00:11:24.750 --> 00:11:28.190
And will use this as outline for the

00:11:28.190 --> 00:11:30.465
topics that will cover in the rest of

00:11:30.465 --> 00:11:31.090
this course.


