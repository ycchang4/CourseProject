WEBVTT Kind: captions; Language: en-US

NOTE
Created on 2021-02-26T23:59:24.9917707Z by ClassTranscribe

00:00:00.290 --> 00:00:03.380
So, as we explained, different

00:00:03.380 --> 00:00:05.960
textual representation tends to enable

00:00:05.960 --> 00:00:07.900
different analysis.

00:00:07.900 --> 00:00:10.700
In particular, we can gradually add

00:00:10.700 --> 00:00:13.990
more and more deeper analysis results

00:00:13.990 --> 00:00:16.580
to represent text data, and that would

00:00:16.580 --> 00:00:18.330
open up more interesting

00:00:18.330 --> 00:00:19.490
representation

00:00:29.400 --> 00:00:32.380
opportunities and also analysis

00:00:32.380 --> 00:00:33.430
capacities.

00:00:33.430 --> 00:00:36.180
So this table summarizes what we have

00:00:36.180 --> 00:00:37.260
just seen.

00:00:37.260 --> 00:00:39.060
So the first column shows the text

00:00:39.060 --> 00:00:42.140
recognition, the second visualizes the

00:00:42.140 --> 00:00:44.720
generality of such representation,

00:00:44.720 --> 00:00:47.120
meaning whether we can do this kind of

00:00:47.120 --> 00:00:49.135
representation accurate before all the

00:00:49.135 --> 00:00:51.926
text data, or only some of them, and third

00:00:51.926 --> 00:00:54.380
column shows the enabled analysis

00:00:54.380 --> 00:00:54.990
techniques.

00:00:55.920 --> 00:00:57.790
And the final column shows some

00:00:57.790 --> 00:01:00.480
examples of application that can be

00:01:00.480 --> 00:01:03.390
achieved through this level of

00:01:03.390 --> 00:01:04.200
representation.

00:01:04.200 --> 00:01:07.060
So let's take a look at them. So as a

00:01:07.060 --> 00:01:10.120
string text can only be processed by

00:01:10.120 --> 00:01:12.330
using stream processing algorithms, but

00:01:12.330 --> 00:01:14.230
it's very robust, it's general.

00:01:14.970 --> 00:01:16.290
And there are still some interesting

00:01:16.290 --> 00:01:17.990
applications that can be done at this

00:01:17.990 --> 00:01:20.300
level. For example, compression of text

00:01:20.300 --> 00:01:22.430
doesn't necessarily need to know the

00:01:22.430 --> 00:01:23.380
word boundaries.

00:01:23.950 --> 00:01:26.010
Although knowing word boundaries might

00:01:26.010 --> 00:01:27.470
actually also help.

00:01:28.440 --> 00:01:30.610
Word based representation is very

00:01:30.610 --> 00:01:32.420
important level of representation.

00:01:32.420 --> 00:01:35.090
It's quite general and relatively

00:01:35.090 --> 00:01:35.640
robust.

00:01:36.390 --> 00:01:38.170
It can enable a lot of analysis

00:01:38.170 --> 00:01:40.900
techniques such as word relation

00:01:40.900 --> 00:01:43.260
analysis, topic analysis and sentiment

00:01:43.260 --> 00:01:45.120
analysis, and there are many

00:01:45.120 --> 00:01:47.050
applications that can be enabled by

00:01:47.050 --> 00:01:48.760
this kind of analysis.

00:01:48.760 --> 00:01:51.810
For example, Thesaurus discovery has to

00:01:51.810 --> 00:01:54.893
do with discovering related words and

00:01:54.893 --> 00:01:58.510
topic and opinion related applications

00:01:58.510 --> 00:02:01.413
are abundant, and there are for

00:02:01.413 --> 00:02:04.150
example, and people might be interested

00:02:04.150 --> 00:02:06.215
in knowing the major topics covered in

00:02:06.215 --> 00:02:07.470
the collection of text.

00:02:08.090 --> 00:02:09.760
And this can be the case.

00:02:10.980 --> 00:02:13.320
In research literature, a scientist

00:02:13.320 --> 00:02:14.950
want to know what are the most

00:02:14.950 --> 00:02:18.750
important research topics today or

00:02:18.750 --> 00:02:20.546
customer service people might want to

00:02:20.546 --> 00:02:20.729
know

00:02:20.729 --> 00:02:22.640
what are the major complaints from

00:02:22.640 --> 00:02:27.260
their customers about by mining their

00:02:27.260 --> 00:02:28.500
email messages.

00:02:29.330 --> 00:02:31.730
And business intelligence people might

00:02:31.730 --> 00:02:34.860
be interested in understanding

00:02:34.860 --> 00:02:36.986
consumers opinions about their products

00:02:36.986 --> 00:02:39.580
and competitors products to figure out

00:02:39.580 --> 00:02:41.500
the what are the winning features of

00:02:41.500 --> 00:02:42.320
their products.

00:02:43.020 --> 00:02:46.750
And in general there are many

00:02:46.750 --> 00:02:50.120
applications that can be enabled by the

00:02:50.120 --> 00:02:51.450
representation at this level.

00:02:53.600 --> 00:02:55.413
Now moving down, we'll see

00:02:55.413 --> 00:02:57.110
we can gradually add additional

00:02:57.110 --> 00:02:59.590
representations. By adding syntactic

00:02:59.590 --> 00:03:01.110
structures we can enable,

00:03:01.110 --> 00:03:03.430
Of course, syntactic graph analysis.

00:03:03.430 --> 00:03:05.950
We can use graph mining algorithms to

00:03:05.950 --> 00:03:06.840
analyze

00:03:07.450 --> 00:03:08.590
Syntactic graphs.

00:03:09.350 --> 00:03:11.660
And some applications are related to

00:03:11.660 --> 00:03:13.510
this kind of representation.

00:03:13.510 --> 00:03:15.230
For example, stylistic analysis

00:03:15.230 --> 00:03:17.760
generally requires syntactical

00:03:17.760 --> 00:03:18.530
representation.

00:03:19.400 --> 00:03:21.130
Syntactical structure representation.

00:03:21.890 --> 00:03:23.380
We can also generate the structure

00:03:23.380 --> 00:03:27.030
based feature features and those are

00:03:27.030 --> 00:03:29.690
features that might help us classify

00:03:29.690 --> 00:03:32.870
text objects into different categories.

00:03:33.490 --> 00:03:35.325
By looking at the structures, sometimes

00:03:35.325 --> 00:03:39.050
the classification can be more

00:03:39.050 --> 00:03:39.500
accurate.

00:03:39.500 --> 00:03:41.600
For example, if you want to classify

00:03:41.600 --> 00:03:43.640
articles into

00:03:44.330 --> 00:03:46.120
different categories

00:03:46.120 --> 00:03:48.630
corresponding to different authors want

00:03:48.630 --> 00:03:52.360
to figure out which of the

00:03:53.450 --> 00:03:56.720
K authors has actually written this

00:03:56.720 --> 00:03:57.610
article.

00:03:57.610 --> 00:04:00.200
Then you generally need to look at the

00:04:00.200 --> 00:04:01.460
syntactic structures.

00:04:03.230 --> 00:04:05.320
When we add entities and relations,

00:04:05.320 --> 00:04:08.140
then we can enable lot of techniques

00:04:08.140 --> 00:04:10.860
such as knowledge graph analysis or

00:04:10.860 --> 00:04:13.355
information network analysis in general

00:04:13.355 --> 00:04:17.040
and this analysis would enable

00:04:17.040 --> 00:04:18.070
applications

00:04:19.640 --> 00:04:23.400
about entities, for example, discovery

00:04:23.400 --> 00:04:25.360
of all the knowledge and opinions about

00:04:25.360 --> 00:04:27.630
the real world energy entity.

00:04:28.270 --> 00:04:30.820
You can also use this level

00:04:30.820 --> 00:04:32.820
representation to integrate

00:04:32.820 --> 00:04:34.950
everything about entity from scattered

00:04:34.950 --> 00:04:35.520
sources.

00:04:36.660 --> 00:04:39.630
Finally, when we add logic predicates

00:04:39.630 --> 00:04:42.720
then we would enable logic inference

00:04:42.720 --> 00:04:45.580
ofcourse, and this can be very useful for

00:04:45.580 --> 00:04:47.790
integrative analysis of scattered

00:04:47.790 --> 00:04:48.310
knowledge.

00:04:49.640 --> 00:04:52.320
For example, we can also add ontology

00:04:52.320 --> 00:04:55.830
on top of the extracted information

00:04:55.830 --> 00:04:58.130
from text to make inferences.

00:04:59.700 --> 00:05:02.320
A good example of application in this

00:05:02.320 --> 00:05:04.660
enabled by this level of representation

00:05:04.660 --> 00:05:06.970
is a intelligent knowledge assistant

00:05:06.970 --> 00:05:07.940
for biologists.

00:05:08.570 --> 00:05:10.510
And this is intended program that can

00:05:10.510 --> 00:05:14.430
help biologists manage all the relevant

00:05:14.430 --> 00:05:16.680
knowledge from literature about the

00:05:16.680 --> 00:05:19.620
research problem, such as understanding

00:05:19.620 --> 00:05:21.100
functions of genes.

00:05:21.860 --> 00:05:25.760
And the computer can make inferences

00:05:25.760 --> 00:05:26.990
about

00:05:27.990 --> 00:05:31.180
some of the hypothesis that biologists

00:05:31.180 --> 00:05:33.080
might be interesting, for example,

00:05:33.080 --> 00:05:35.062
whether a gene has a certain function

00:05:35.062 --> 00:05:38.170
and then the intelligent program can

00:05:38.170 --> 00:05:40.890
read the literature to extract the

00:05:40.890 --> 00:05:42.105
relevant facts.

00:05:42.105 --> 00:05:44.490
Doing by doing information extraction

00:05:44.490 --> 00:05:47.360
and then using a logical system to

00:05:47.360 --> 00:05:48.690
actually track

00:05:48.690 --> 00:05:51.600
that's the answers to researchers

00:05:51.600 --> 00:05:54.150
questioning about what genes are

00:05:54.150 --> 00:05:56.260
related to what functions.

00:05:57.860 --> 00:06:00.120
So in order to support this level of

00:06:00.120 --> 00:06:03.100
application, we need to go as far as

00:06:03.100 --> 00:06:04.770
logical representation.

00:06:04.770 --> 00:06:08.240
Now this course is covering techniques

00:06:08.240 --> 00:06:10.310
mainly based on word based

00:06:10.310 --> 00:06:10.820
representation.

00:06:11.940 --> 00:06:15.060
These techniques are general and robust

00:06:15.060 --> 00:06:18.340
and thus are more widely used in

00:06:18.340 --> 00:06:19.660
various applications.

00:06:20.770 --> 00:06:24.220
In fact, in virtually all the text

00:06:24.220 --> 00:06:26.390
mining applications you need this

00:06:26.390 --> 00:06:28.230
level of representation and the

00:06:28.230 --> 00:06:31.740
techniques that support analysis of

00:06:31.740 --> 00:06:33.050
texting this level.

00:06:35.140 --> 00:06:38.690
But obviously all these other levels

00:06:38.690 --> 00:06:41.240
can be combined and should be combined

00:06:41.240 --> 00:06:43.270
in order to support sophisticated

00:06:43.270 --> 00:06:44.490
applications.

00:06:44.490 --> 00:06:46.870
So to summarize, here are the major

00:06:46.870 --> 00:06:47.840
takeaway points.

00:06:47.840 --> 00:06:49.950
Text representation determines what kind

00:06:49.950 --> 00:06:52.020
of mining algorithms can be applied.

00:06:53.500 --> 00:06:54.850
And there are multiple ways to

00:06:54.850 --> 00:06:58.050
represent text - strings, words,

00:06:58.050 --> 00:07:00.750
syntactic structures and the relation

00:07:00.750 --> 00:07:03.830
graphs, logical predicates, etc.

00:07:04.400 --> 00:07:05.880
And these different


00:07:05.880 --> 00:07:08.320
representations should in general be

00:07:08.320 --> 00:07:11.080
combined in real applications to the

00:07:11.080 --> 00:07:12.320
extent we can.

00:07:13.090 --> 00:07:15.820
For example, if even if we cannot do

00:07:15.820 --> 00:07:17.290
accurately,

00:07:19.140 --> 00:07:21.160
this application of syntactic

00:07:21.160 --> 00:07:23.120
structures we can stick at partial

00:07:23.120 --> 00:07:26.880
structures extracted and if we can

00:07:26.880 --> 00:07:28.980
recognize some entities and that would

00:07:28.980 --> 00:07:29.550
be great.

00:07:29.550 --> 00:07:32.270
So in general we want to do as much as

00:07:32.270 --> 00:07:32.790
we can.

00:07:34.370 --> 00:07:36.670
And when different levels are combined

00:07:36.670 --> 00:07:39.320
together, we can enable richer

00:07:39.320 --> 00:07:40.130
analysis.

00:07:40.130 --> 00:07:41.570
More powerful analysis.

00:07:42.260 --> 00:07:44.800
This course, however, focuses on word

00:07:44.800 --> 00:07:45.910
based representation.

00:07:45.910 --> 00:07:48.530
Such techniques have also several

00:07:48.530 --> 00:07:50.160
advantages.

00:07:50.160 --> 00:07:52.480
First, they are general and robust, so they

00:07:52.480 --> 00:07:54.989
are applicable to any natural language.

00:07:54.990 --> 00:07:57.020
That's a big advantage over other

00:07:57.020 --> 00:08:00.116
approaches that rely on more fragile

00:08:00.116 --> 00:08:02.160
natural language processing techniques.

00:08:03.380 --> 00:08:06.530
Secondly, it does not require much

00:08:06.530 --> 00:08:09.250
manual effort or sometimes it does not

00:08:09.250 --> 00:08:10.770
require any manual effort.

00:08:11.390 --> 00:08:14.850
So that's again important benefit,

00:08:14.850 --> 00:08:16.810
because that means you can apply

00:08:16.810 --> 00:08:18.500
directly to any application.

00:08:20.610 --> 00:08:24.120
Third, these techniques are actually

00:08:24.120 --> 00:08:26.040
surprisingly powerful

00:08:26.040 --> 00:08:27.930
and effective for many applications.

00:08:29.050 --> 00:08:31.620
Although not all, of course, as I just

00:08:31.620 --> 00:08:32.320
explained.

00:08:34.190 --> 00:08:37.260
Now they are very effective, partly

00:08:37.260 --> 00:08:41.060
because the words are invented by

00:08:41.060 --> 00:08:43.930
humans as basic units for

00:08:43.930 --> 00:08:44.820
communications.

00:08:45.480 --> 00:08:48.050
So they are actually quite sufficient

00:08:48.050 --> 00:08:50.310
for representing all kinds of

00:08:50.310 --> 00:08:51.130
semantics.

00:08:53.570 --> 00:08:56.460
So that makes this kind of word based

00:08:56.460 --> 00:08:59.040
representation also powerful.

00:09:00.160 --> 00:09:02.340
And finally such a word based

00:09:02.340 --> 00:09:04.420
representation and the techniques

00:09:04.420 --> 00:09:07.330
enabled by such a representation can be

00:09:07.330 --> 00:09:10.900
combined with many other sophisticated

00:09:10.900 --> 00:09:11.720
approaches.

00:09:13.920 --> 00:09:15.470
So they're not competing with each

00:09:15.470 --> 00:09:15.800
other.


