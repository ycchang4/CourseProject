WEBVTT Kind: captions; Language: en-US

NOTE
Created on 2021-02-26T23:59:32.6922861Z by ClassTranscribe

00:00:17.670 --> 00:00:20.720
This lecture is  about topic mining and analysis.

00:00:20.720 --> 00:00:22.730
We
are going to talk about its motivation and task definition. 
In this
 lecture, we are going to talk about the different type of mining task. 

00:00:23.680 --> 00:00:27.180
As you see on this roadmap, we have just
covered mining knowledge 

00:00:27.180 --> 00:00:30.510
we have just
covered mining knowledge

00:00:30.510 --> 00:00:33.490
about the language namely discovery of word 


00:00:33.490 --> 00:00:35.700
associations such as paradigmatic relations

00:00:35.700 --> 00:00:38.380
relations and syntagmatic relations.

00:00:39.070 --> 00:00:40.700
Now, starting from this lecture,

00:00:40.700 --> 00:00:42.350
we're going to talk about mining

00:00:42.350 --> 00:00:44.990
another kind of knowledge, which is

00:00:44.990 --> 00:00:48.810
content mining and trying to discover

00:00:48.810 --> 00:00:50.320
knowledge about.

00:00:51.370 --> 00:00:53.300
The main topics.

00:00:54.020 --> 00:00:55.120
In the text.

00:00:56.040 --> 00:00:58.020
And we call that topic mining and

00:00:58.020 --> 00:00:58.880
analysis.

00:00:59.790 --> 00:01:01.530
In this lecture we're going to talk

00:01:01.530 --> 00:01:03.000
about its motivation and the task

00:01:03.000 --> 00:01:03.755
definition.

00:01:03.755 --> 00:01:07.454
So first, let's look at the concept of

00:01:07.454 --> 00:01:07.948
topic.

00:01:07.948 --> 00:01:10.580
So topic is something that we all

00:01:10.580 --> 00:01:13.380
understand, I think, but it's actually

00:01:13.380 --> 00:01:15.760
not that easy to formally define it.

00:01:15.760 --> 00:01:18.260
Roughly speaking, topic is the main

00:01:18.260 --> 00:01:20.730
idea discussed in text data, and you

00:01:20.730 --> 00:01:23.300
can think of this as a theme or subject

00:01:23.300 --> 00:01:25.170
of discussion or conversation.

00:01:25.170 --> 00:01:26.860
It can also have different

00:01:26.860 --> 00:01:28.060
granularities.

00:01:28.060 --> 00:01:29.603
For example, we can talk about the

00:01:29.603 --> 00:01:30.910
topic of a sentence.

00:01:31.170 --> 00:01:33.269
A topic of article topic of a

00:01:33.270 --> 00:01:37.120
paragraph, or the topics of all the

00:01:37.120 --> 00:01:39.040
research articles in the digital

00:01:39.040 --> 00:01:39.630
library.

00:01:40.270 --> 00:01:43.680
So different granularities of topics

00:01:43.680 --> 00:01:45.740
obviously have different applications.

00:01:46.470 --> 00:01:48.320
Indeed, there are many applications

00:01:48.320 --> 00:01:50.929
that require discovery of topics in

00:01:50.930 --> 00:01:52.820
text and then analyze them.

00:01:52.820 --> 00:01:54.260
Here are some examples.

00:01:54.260 --> 00:01:56.801
For example, we might be interested in

00:01:56.801 --> 00:01:59.060
knowing what are Twitter users talking

00:01:59.060 --> 00:01:59.880
about today?

00:01:59.880 --> 00:02:03.764
Are they talking about NBA sports or

00:02:03.764 --> 00:02:05.960
talking about some international

00:02:05.960 --> 00:02:08.280
events, etc.

00:02:08.280 --> 00:02:11.377
Or we are interested in knowing about

00:02:11.377 --> 00:02:12.705
the research topics.

00:02:12.705 --> 00:02:15.035
For example, one might be interested in

00:02:15.035 --> 00:02:16.956
knowing what are the current research

00:02:16.956 --> 00:02:18.870
topics in data mining and how are they

00:02:18.870 --> 00:02:19.970
different from

00:02:20.040 --> 00:02:23.079
those five years ago. Now this involves

00:02:23.080 --> 00:02:25.820
discovery of topics in data mining,

00:02:25.820 --> 00:02:27.800
literatures and also we want to

00:02:27.800 --> 00:02:30.322
discover topics in today's literature

00:02:30.322 --> 00:02:32.595
and those in the past.

00:02:32.595 --> 00:02:34.215
And then we can make a comparison.

00:02:34.215 --> 00:02:36.830
We might be also interested in knowing

00:02:36.830 --> 00:02:39.283
what do people like about some product

00:02:39.283 --> 00:02:43.130
like iPhone 6 and what do they dislike?

00:02:43.130 --> 00:02:46.780
And this involves discovering topics in

00:02:46.780 --> 00:02:49.638
positive opinions about iPhone 6 and

00:02:49.638 --> 00:02:51.980
also negative reviews about it.

00:02:52.410 --> 00:02:54.320
Or perhaps we're interested in knowing

00:02:54.320 --> 00:02:56.745
what are the major topics debated in

00:02:56.745 --> 00:02:58.820
2012 presidential election?

00:02:59.660 --> 00:03:02.090
And all these have to do is discovering

00:03:02.090 --> 00:03:04.900
topics in texts and analyzing them, and

00:03:04.900 --> 00:03:06.340
we're going to talk about a lot of

00:03:06.340 --> 00:03:07.940
techniques for doing this.

00:03:08.510 --> 00:03:11.190
In general, we can view topic as some

00:03:11.190 --> 00:03:12.859
knowledge about the world.

00:03:12.860 --> 00:03:15.510
So from text that we expected to

00:03:15.510 --> 00:03:17.960
discover a number of topics and then

00:03:17.960 --> 00:03:19.740
this topic generally provide

00:03:19.740 --> 00:03:23.120
the description about the world and it

00:03:23.120 --> 00:03:24.953
tells us something about the world,

00:03:24.953 --> 00:03:27.710
about the product, about the person,

00:03:27.710 --> 00:03:28.410
etc.

00:03:29.240 --> 00:03:32.270
Now when we have some non-text data

00:03:32.270 --> 00:03:35.060
then we can have more context for

00:03:35.060 --> 00:03:36.323
analyzing the topics.

00:03:36.323 --> 00:03:38.450
For example, we might know the time

00:03:38.450 --> 00:03:41.619
associated with the text data or

00:03:41.620 --> 00:03:45.010
locations where the text data will be

00:03:45.010 --> 00:03:50.020
produced or the authors of text or the

00:03:50.020 --> 00:03:52.710
sources of the text etc.

00:03:52.710 --> 00:03:55.760
All such meta data or context variables

00:03:55.760 --> 00:03:58.228
can be associated with the topics that

00:03:58.228 --> 00:03:59.330
we discover.

00:03:59.390 --> 00:04:02.190
And then we can use these context

00:04:02.190 --> 00:04:04.500
variables to help us analyze patterns

00:04:04.500 --> 00:04:05.310
of topics.

00:04:05.310 --> 00:04:07.090
For example, looking at topics

00:04:07.090 --> 00:04:09.340
overtime, we would be able to discover

00:04:09.340 --> 00:04:12.480
whether there's a trending topic or

00:04:12.480 --> 00:04:14.450
some topics might be fading away.

00:04:15.060 --> 00:04:17.208
Similar looking at the topics in

00:04:17.208 --> 00:04:20.060
different locations, we might know some

00:04:20.060 --> 00:04:23.066
insights about people's opinions in

00:04:23.066 --> 00:04:23.919
different locations.

00:04:24.960 --> 00:04:27.990
So that's why mining topics is very

00:04:27.990 --> 00:04:28.640
important.

00:04:28.640 --> 00:04:31.470
Now let's look at the tasks of topic

00:04:31.470 --> 00:04:32.900
mining and analysis.

00:04:32.900 --> 00:04:35.930
In general, it would involve first

00:04:35.930 --> 00:04:37.667
discovering a lot of topics.

00:04:37.667 --> 00:04:39.060
In this case K topics.

00:04:40.690 --> 00:04:43.280
And then we also would like to know which

00:04:43.280 --> 00:04:45.420
topics are covered in which documents,

00:04:45.420 --> 00:04:46.540
to what extent.

00:04:46.540 --> 00:04:47.930
So for example in.

00:04:48.510 --> 00:04:51.063
Document one we might see that

00:04:51.063 --> 00:04:53.960
topic 1 is covered a lot, topic 2

00:04:53.960 --> 00:04:57.020
and topic k are covered with a small

00:04:57.020 --> 00:04:57.500
portion.

00:04:58.770 --> 00:05:00.400
And other topics perhaps are not

00:05:00.400 --> 00:05:00.870
covered.

00:05:02.570 --> 00:05:04.600
Document 2, on the other hand, 

00:05:04.600 --> 00:05:06.090
covered topic 2

00:05:06.970 --> 00:05:09.150
very well, but it did not cover topic

00:05:09.150 --> 00:05:12.740
1 at all and also covers topic K to

00:05:12.740 --> 00:05:13.480
some extent.

00:05:14.300 --> 00:05:15.745
etc., right?

00:05:15.745 --> 00:05:18.250
So now you can see there are generally

00:05:18.250 --> 00:05:20.456
two different tasks or subtasks.

00:05:20.456 --> 00:05:23.950
The first is to discover K topics from

00:05:23.950 --> 00:05:25.478
a collection of text data.

00:05:25.478 --> 00:05:27.090
What are these K topics?

00:05:27.090 --> 00:05:29.192
OK, major topics in the text data.

00:05:29.192 --> 00:05:31.396
The second task is to figure out which

00:05:31.396 --> 00:05:33.460
documents cover which topics to what

00:05:33.460 --> 00:05:34.040
extent.

00:05:34.040 --> 00:05:36.180
So more formally, we can define the

00:05:36.180 --> 00:05:37.600
problem as follows.

00:05:37.600 --> 00:05:40.880
First, we have as input a collection of

00:05:40.880 --> 00:05:42.700
N text documents.

00:05:42.700 --> 00:05:44.310
Here we can denote that text

00:05:44.310 --> 00:05:44.850
connection.

00:05:44.900 --> 00:05:46.140
as C.

00:05:46.720 --> 00:05:51.775
And denote a text article as di and

00:05:51.775 --> 00:05:54.550
we generally also need to have as input

00:05:54.550 --> 00:05:56.380
the number of topics K.

00:05:56.380 --> 00:05:58.720
But there may be techniques that can

00:05:58.720 --> 00:06:01.202
automatically suggest a number of

00:06:01.202 --> 00:06:02.780
topics, but in the techniques that we

00:06:02.780 --> 00:06:06.000
will discuss which are also the most

00:06:06.000 --> 00:06:09.720
useful techniques, we often need to

00:06:09.720 --> 00:06:12.470
specify a number of topics.

00:06:13.940 --> 00:06:17.450
Now the output would then be the K

00:06:17.450 --> 00:06:19.320
topics that we would like to discover

00:06:19.320 --> 00:06:21.895
denoted as theater sub one through

00:06:21.895 --> 00:06:23.060
theta sub k.

00:06:23.060 --> 00:06:26.690
Also we want to generate the coverage

00:06:26.690 --> 00:06:29.040
of topics in each document d sub i

00:06:29.040 --> 00:06:33.440
and this is denoted by π sub i j and

00:06:33.440 --> 00:06:36.060
π sub i j
 is the probability of

00:06:36.060 --> 00:06:39.290
document d sub i covering topic

00:06:39.290 --> 00:06:40.580
theta sub j.

00:06:40.580 --> 00:06:42.680
So obviously for each document we have

00:06:42.680 --> 00:06:44.700
a set of such values indicate.

00:06:45.370 --> 00:06:47.170
To what extent did the document covers

00:06:47.170 --> 00:06:47.940
each topic.

00:06:48.820 --> 00:06:51.330
An we can assume that these

00:06:51.330 --> 00:06:55.150
probabilities sum to one, because a

00:06:55.150 --> 00:06:57.265
document won't be able to cover other

00:06:57.265 --> 00:06:59.980
topics outside the topics that we

00:06:59.980 --> 00:07:01.980
discussed we discovered.

00:07:01.980 --> 00:07:05.008
So now the question is how do we define

00:07:05.008 --> 00:07:06.031
theta sub i?

00:07:06.031 --> 00:07:08.300
How do we define the topic now?

00:07:08.300 --> 00:07:10.340
This problem has not been completely

00:07:10.340 --> 00:07:14.890
defined until we define what is exactly

00:07:14.890 --> 00:07:15.340
theta.

00:07:16.860 --> 00:07:18.500
So in the next a few lectures, we're

00:07:18.500 --> 00:07:20.760
going to talk about different ways to

00:07:20.760 --> 00:07:22.270
define theta.


