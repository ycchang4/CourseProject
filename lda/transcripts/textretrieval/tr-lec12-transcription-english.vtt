WEBVTT Kind: captions; Language: en-US

NOTE
Created on 2021-02-27T00:07:09.7960741Z by ClassTranscribe

00:00:00.280 --> 00:00:02.200
This lecture is about

00:00:09.470 --> 00:00:12.360
how to do fast search by using inverted

00:00:12.360 --> 00:00:12.920
index.

00:00:14.600 --> 00:00:16.030
In this lecture, we're going to

00:00:16.030 --> 00:00:17.930
continue the discussion of system

00:00:17.930 --> 00:00:18.840
implementation.

00:00:19.670 --> 00:00:21.500
In particular, we're going to talk

00:00:21.500 --> 00:00:23.580
about how to support fast search by

00:00:23.580 --> 00:00:24.790
using inverted index.

00:00:27.070 --> 00:00:29.870
So let's think about what a general

00:00:29.870 --> 00:00:31.600
scoring function might look like.

00:00:32.620 --> 00:00:35.180
Now of course, the vector space model

00:00:35.180 --> 00:00:37.500
is a special case of this, but we can

00:00:37.500 --> 00:00:39.610
imagine many other retrieval functions

00:00:39.610 --> 00:00:41.080
of the same form.

00:00:41.750 --> 00:00:43.910
So the form of this function is as

00:00:43.910 --> 00:00:44.600
follows.

00:00:45.870 --> 00:00:48.740
We see this scoring function of

00:00:48.740 --> 00:00:52.570
document d and query q is defined as

00:00:52.570 --> 00:00:55.220
first a function of f(a).

00:00:55.220 --> 00:00:58.740
That's adjustment function that would

00:00:58.740 --> 00:01:00.620
consider two factors that are

00:01:00.620 --> 00:01:05.900
shown here at the end f sub d of (d) and f

00:01:05.900 --> 00:01:08.420
sub q of (q).

00:01:09.220 --> 00:01:11.934
These are adjustment factors of

00:01:11.934 --> 00:01:14.700
document and query so they are at the

00:01:14.700 --> 00:01:17.729
level of a document and query.

00:01:19.450 --> 00:01:22.790
And then inside of this function we

00:01:22.790 --> 00:01:24.560
also see there's another function

00:01:24.560 --> 00:01:25.690
called h.

00:01:27.290 --> 00:01:28.720
So this is

00:01:29.610 --> 00:01:33.750
the main part of the scoring function.

00:01:34.980 --> 00:01:39.330
And these as I just said, are the

00:01:39.330 --> 00:01:42.650
scoring factors at the level of the

00:01:42.650 --> 00:01:44.180
whole document and query.

00:01:44.180 --> 00:01:45.590
For example document lengths.

00:01:46.940 --> 00:01:49.800
And this aggregate functioning would

00:01:49.800 --> 00:01:52.000
then combine all these.

00:01:53.070 --> 00:01:56.370
Now inside this edge function there are

00:01:56.370 --> 00:02:01.030
functions that would compute the

00:02:01.030 --> 00:02:03.800
weights of the contribution of a

00:02:03.800 --> 00:02:06.440
matched query term t(i).

00:02:08.660 --> 00:02:11.926
So this is g.

00:02:11.926 --> 00:02:15.070
The function g gives us the weight of a

00:02:15.070 --> 00:02:19.570
match query term t(i) in document

00:02:19.570 --> 00:02:19.880
d.

00:02:23.610 --> 00:02:25.880
And this h function would then

00:02:25.880 --> 00:02:29.280
aggregate all these weights, so it will

00:02:29.280 --> 00:02:30.940
for example, take a sum

00:02:30.940 --> 00:02:34.530
of all the matched query terms.

00:02:35.590 --> 00:02:37.855
But it can also be a product or could

00:02:37.855 --> 00:02:39.970
be another way of aggregating them.

00:02:41.100 --> 00:02:44.150
And then finally, this adjustment

00:02:44.150 --> 00:02:45.110
function would

00:02:45.110 --> 00:02:47.570
then consider the document level or query

00:02:47.570 --> 00:02:50.260
level factors to further adjust

00:02:50.260 --> 00:02:50.540
the score.

00:02:50.540 --> 00:02:52.700
For example, documents normalization.

00:02:53.950 --> 00:02:57.110
So this general form would cover many

00:02:57.110 --> 00:02:58.820
state of the art retrieval functions.

00:02:58.820 --> 00:03:02.210
Let's look at how we can

00:03:02.210 --> 00:03:04.950
score documents with such a function

00:03:04.950 --> 00:03:06.750
using inverted index.

00:03:07.540 --> 00:03:09.490
So here's a general algorithm that

00:03:09.490 --> 00:03:10.830
works as follows.

00:03:10.830 --> 00:03:11.950
First these

00:03:13.490 --> 00:03:16.220
query level and document level factors

00:03:16.220 --> 00:03:19.240
can be precomputed in the indexing

00:03:19.240 --> 00:03:20.945
time. Of course, for the query we have

00:03:20.945 --> 00:03:22.966
the computed at query time, but for

00:03:22.966 --> 00:03:25.513
document, for example, document lengths can

00:03:25.513 --> 00:03:26.539
be precomputed.

00:03:28.050 --> 00:03:29.580
And then we'll maintain a score

00:03:29.580 --> 00:03:31.930
accumulator for each document d to

00:03:31.930 --> 00:03:33.090
compute h.

00:03:34.020 --> 00:03:36.250
And h is the aggregation function of

00:03:36.250 --> 00:03:38.040
all the matched query terms.

00:03:38.040 --> 00:03:39.730
So how do we do that?

00:03:39.730 --> 00:03:41.990
Well, for each query term we're going

00:03:41.990 --> 00:03:45.470
to fetch the inverted list from the

00:03:45.470 --> 00:03:46.275
inverted index.

00:03:46.275 --> 00:03:48.840
This would give us all the documents

00:03:48.840 --> 00:03:50.950
that match this query term.

00:03:52.530 --> 00:03:55.940
And that includes d1, f1

00:03:55.940 --> 00:03:57.530
through dn, fn.

00:03:57.530 --> 00:04:00.640
So each pair is document ID and

00:04:00.640 --> 00:04:03.070
the frequency of the term in the document.

00:04:03.700 --> 00:04:07.627
Then for each entry dj and fj

00:04:07.627 --> 00:04:10.110
are particular match of the term

00:04:10.110 --> 00:04:12.170
in this particular document dj.

00:04:12.170 --> 00:04:13.880
We're going to compute the

00:04:13.880 --> 00:04:14.920
function g.

00:04:15.550 --> 00:04:17.720
That would give us something like a TF

00:04:17.720 --> 00:04:18.660
if weights

00:04:19.270 --> 00:04:21.830
of this term. So we'll compute the

00:04:21.830 --> 00:04:23.610
weighted contribution of matching this

00:04:23.610 --> 00:04:25.480
query term in this document.

00:04:26.060 --> 00:04:27.660
And then we're going to update the

00:04:27.660 --> 00:04:30.250
score accumulator for this document.

00:04:31.220 --> 00:04:34.670
And this would allow us to add this to

00:04:34.670 --> 00:04:38.360
a accumulator that would incrementally

00:04:38.360 --> 00:04:40.890
compute the function h.

00:04:40.890 --> 00:04:45.018
So this is basically a general way to

00:04:45.018 --> 00:04:48.950
allow us to do computer all functions of

00:04:48.950 --> 00:04:51.290
this form by using inverted index.

00:04:51.290 --> 00:04:53.580
Note that we don't have to touch any

00:04:53.580 --> 00:04:56.140
document that didn't match any query term.

00:04:56.140 --> 00:04:56.480
But

00:04:57.100 --> 00:04:58.620
this is why it's fast.

00:04:58.620 --> 00:05:00.300
We only need to process the document

00:05:00.300 --> 00:05:03.900
that matched at least one query term.

00:05:04.630 --> 00:05:06.740
In the end, then, we're going to adjust

00:05:06.740 --> 00:05:09.389
the score to compute this function

00:05:09.390 --> 00:05:11.400
Fa, and then we can sort.

00:05:11.400 --> 00:05:13.550
So let's take a look at the specific

00:05:13.550 --> 00:05:13.883
example.

00:05:13.883 --> 00:05:16.320
In this case, let's assume the scoring

00:05:16.320 --> 00:05:18.270
function is very simple while it just

00:05:18.270 --> 00:05:19.820
takes the sum of TF.

00:05:20.620 --> 00:05:21.385
The raw TF.

00:05:21.385 --> 00:05:25.130
The count of a term in the document.

00:05:25.130 --> 00:05:27.560
Now this simplification would help

00:05:27.560 --> 00:05:31.810
showing the algorithm clearly it's very

00:05:31.810 --> 00:05:34.680
easy to extend the computation to

00:05:34.680 --> 00:05:36.750
include other weights, like the

00:05:36.750 --> 00:05:40.630
transformation of TF or document length 

00:05:40.630 --> 00:05:42.920
normalization or IDF weighting.

00:05:43.640 --> 00:05:45.080
So let's take a look at a specific

00:05:45.080 --> 00:05:47.510
example where the queries information

00:05:47.510 --> 00:05:48.080
security.

00:05:48.870 --> 00:05:52.620
And I show some entries of the inverted

00:05:52.620 --> 00:05:55.080
index on the right side information

00:05:55.080 --> 00:05:57.089
occurred four documents and their

00:05:57.090 --> 00:05:57.600
frequencies.

00:05:57.600 --> 00:06:00.170
Also their security occurred in three

00:06:00.170 --> 00:06:00.620
documents.

00:06:01.170 --> 00:06:03.355
So let's see how the algorithm works.

00:06:03.355 --> 00:06:05.840
So first we iterate over all the query

00:06:05.840 --> 00:06:06.380
terms.

00:06:07.110 --> 00:06:09.210
An we fetch the first query them what

00:06:09.210 --> 00:06:09.600
is that?

00:06:09.600 --> 00:06:10.570
That's information.

00:06:11.270 --> 00:06:14.040
Imagine we have all these

00:06:14.040 --> 00:06:16.310
score accumulators to store the scores

00:06:16.310 --> 00:06:18.610
for these

00:06:18.610 --> 00:06:19.280
documents.

00:06:19.280 --> 00:06:21.549
We can imagine there will be allocated

00:06:21.550 --> 00:06:24.060
but then they will only be allocated as

00:06:24.060 --> 00:06:25.020
needed.

00:06:25.020 --> 00:06:30.380
So before we do any weighting of terms, we

00:06:30.380 --> 00:06:31.630
don't even need a score

00:06:31.630 --> 00:06:32.280
accumulator.

00:06:33.200 --> 00:06:35.130
But conceptually we have these score

00:06:35.130 --> 00:06:38.420
accumulators eventually allocated.

00:06:38.420 --> 00:06:41.600
Let's fetch the entries from the

00:06:41.600 --> 00:06:44.280
inverted list for information first.

00:06:44.280 --> 00:06:45.320
That's the first one.

00:06:46.160 --> 00:06:49.210
So these score accumulators obviously

00:06:49.210 --> 00:06:51.080
will be initialized at 0.

00:06:51.730 --> 00:06:54.470
So the first answer is d1 and 3.

00:06:54.470 --> 00:06:54.980
3 is the

00:06:54.980 --> 00:06:57.570
occurrences of information in this

00:06:57.570 --> 00:06:58.310
document.

00:06:58.310 --> 00:07:01.020
Since our scoring function assumes that

00:07:01.020 --> 00:07:02.870
the score is just a sum of these raw

00:07:02.870 --> 00:07:05.697
counts, we just need to add 3 to the

00:07:05.697 --> 00:07:08.720
score accumulator to account for the

00:07:08.720 --> 00:07:10.050
increase of score

00:07:10.050 --> 00:07:13.110
due to matching this term information

00:07:13.670 --> 00:07:15.270
in document d1.

00:07:16.620 --> 00:07:18.000
And then we go to the next entry.

00:07:18.000 --> 00:07:20.010
That's d2 and 4 and then we added

00:07:20.010 --> 00:07:22.486
4 to the score accumulator of d2.

00:07:22.486 --> 00:07:24.290
Of course, at this point that we will

00:07:24.290 --> 00:07:25.990
allocated the score accumulator as

00:07:25.990 --> 00:07:26.520
needed.

00:07:27.660 --> 00:07:29.715
And so, at this point we allocated d1

00:07:29.715 --> 00:07:30.600
and d2.

00:07:31.470 --> 00:07:33.750
The next is d3 and we

00:07:33.750 --> 00:07:34.530
add 1.

00:07:34.530 --> 00:07:36.600
We allocate another score cumulative

00:07:36.600 --> 00:07:38.470
for d3 and add 1 to it.

00:07:39.370 --> 00:07:42.540
And then finding the d4 gets a 5

00:07:42.540 --> 00:07:46.460
because the term

00:07:46.460 --> 00:07:49.160
information occurred five times in this

00:07:49.160 --> 00:07:49.650
document.

00:07:50.320 --> 00:07:52.406
OK, so this completes the processing of

00:07:52.406 --> 00:07:54.920
all the entries in the inverted index

00:07:54.920 --> 00:07:57.639
for information. It processed all the

00:07:57.640 --> 00:07:59.425
contributions of matching information

00:07:59.425 --> 00:08:00.940
in these four documents.

00:08:01.730 --> 00:08:04.790
So now our algorithm will go to the

00:08:04.790 --> 00:08:06.586
next query term that security.

00:08:06.586 --> 00:08:08.030
So we're going to fetch all the

00:08:08.030 --> 00:08:10.050
inverted index entries for security.

00:08:10.720 --> 00:08:12.960
So in this case there are three entries

00:08:12.960 --> 00:08:15.320
and we're going to go through each of

00:08:15.320 --> 00:08:15.920
them.

00:08:15.920 --> 00:08:18.590
The first is d2 and 3, and that

00:08:18.590 --> 00:08:21.100
means security occurs three times in

00:08:21.100 --> 00:08:21.390
d2.

00:08:21.390 --> 00:08:22.840
And what do we do?

00:08:22.840 --> 00:08:24.699
Well, we do exactly the same as what we

00:08:24.700 --> 00:08:27.220
did for information, so this time we're

00:08:27.220 --> 00:08:29.475
going to change the score accumulator

00:08:29.475 --> 00:08:31.480
d2, since it's already allocated.

00:08:32.110 --> 00:08:35.799
And what we do is to add 3 to the

00:08:35.800 --> 00:08:37.860
existing value which is 4.

00:08:37.860 --> 00:08:42.950
So we now get the 7 for d2. d2 score is

00:08:42.950 --> 00:08:45.150
increased because it matched both the

00:08:45.150 --> 00:08:46.710
information and security.

00:08:47.720 --> 00:08:49.440
Go to the next entry.

00:08:49.440 --> 00:08:52.010
That's d4 and 1 so we would update

00:08:52.010 --> 00:08:55.098
the score for d4 and again we add 1 to

00:08:55.098 --> 00:08:55.522
d4.

00:08:55.522 --> 00:08:58.469
So d4 now goes from 5 to 6.

00:08:59.250 --> 00:09:02.680
Finally, we process d5 and 3.

00:09:02.680 --> 00:09:05.030
Since we have not yet allocated a score

00:09:05.030 --> 00:09:06.400
accumulator for d5.

00:09:06.400 --> 00:09:08.240
At this point, we're going to allocate

00:09:08.240 --> 00:09:12.070
1 for d5, and we're going to add 3 to it,

00:09:12.070 --> 00:09:15.110
So those scores

00:09:15.840 --> 00:09:18.380
on the last row are the final scores

00:09:18.380 --> 00:09:19.590
for these documents

00:09:20.330 --> 00:09:22.770
if our scoring function is just a

00:09:22.770 --> 00:09:25.890
simple sum of TF values.

00:09:26.980 --> 00:09:30.295
Now, what if we actually would like to

00:09:30.295 --> 00:09:31.420
do length normalization?

00:09:31.420 --> 00:09:33.440
We can do the normalization at this

00:09:33.440 --> 00:09:35.230
point for each document.

00:09:36.400 --> 00:09:40.140
So to summarize this you can see we

00:09:40.140 --> 00:09:43.240
first processed the

00:09:43.240 --> 00:09:44.525
query term information.

00:09:44.525 --> 00:09:47.400
We processed all the entries in the

00:09:47.400 --> 00:09:49.400
inverted index for this term.

00:09:49.400 --> 00:09:51.740
Then we processed the security.

00:09:53.240 --> 00:09:55.410
It's worth thinking about what should

00:09:55.410 --> 00:09:58.210
be the order of processing here.

00:09:58.210 --> 00:09:59.910
when we consider query terms.

00:10:00.720 --> 00:10:02.950
It might make difference, especially if

00:10:02.950 --> 00:10:06.925
we don't want to keep all the score

00:10:06.925 --> 00:10:07.620
accumulators.

00:10:07.620 --> 00:10:09.970
Let's say we only want to keep the most

00:10:09.970 --> 00:10:11.730
promising score accumulators.

00:10:12.410 --> 00:10:13.830
What do you think it would be a good

00:10:13.830 --> 00:10:15.110
order to go through?

00:10:15.800 --> 00:10:17.290
Would you go.

00:10:18.120 --> 00:10:20.620
Would you process a common term first

00:10:20.620 --> 00:10:22.770
or would you process a rare term first?

00:10:24.390 --> 00:10:27.780
The answer is we should

00:10:27.780 --> 00:10:30.820
process the rare term first.

00:10:30.820 --> 00:10:33.610
A rare term would match fewer documents

00:10:33.610 --> 00:10:35.650
and then the score contribution would

00:10:35.650 --> 00:10:37.540
be higher because the idea of value

00:10:37.540 --> 00:10:38.359
will be higher.

00:10:39.050 --> 00:10:42.400
And then it allows us to touch the

00:10:42.400 --> 00:10:45.710
most promising documents first, so it

00:10:45.710 --> 00:10:47.780
helps pruning some non promising ones

00:10:47.780 --> 00:10:49.505
if we don't need to so many documents

00:10:49.505 --> 00:10:51.320
to be returned to the user.

00:10:51.880 --> 00:10:53.740
Right, so those are all heuristics for

00:10:53.740 --> 00:10:55.930
further improving the accuracy here.

00:10:55.930 --> 00:10:57.710
You can also see how we can incorporate

00:10:57.710 --> 00:11:00.850
the IDF weighting so they can easily

00:11:00.850 --> 00:11:03.520
be incorporated when we process each

00:11:03.520 --> 00:11:04.164
query term.

00:11:04.164 --> 00:11:06.222
When we fetch the inverted index, we

00:11:06.222 --> 00:11:08.170
can fetch the document frequency and

00:11:08.170 --> 00:11:09.770
then we can compute the IDF.

00:11:09.770 --> 00:11:11.730
Or maybe perhaps the IDF value has

00:11:11.730 --> 00:11:13.070
already been precomputed.

00:11:13.070 --> 00:11:17.120
When we index the documents at that

00:11:17.120 --> 00:11:20.400
time, we already computed the IDF value

00:11:20.400 --> 00:11:22.690
that we can just fetch it.

00:11:22.760 --> 00:11:26.205
So all these can be done at this time,

00:11:26.205 --> 00:11:28.036
so that would mean when we process all

00:11:28.036 --> 00:11:30.870
the entries for information, these

00:11:30.870 --> 00:11:32.970
weights will be adjusted by the same

00:11:32.970 --> 00:11:35.620
IDF, which is IDF for information.

00:11:36.500 --> 00:11:38.590
So this is the basic idea of using

00:11:38.590 --> 00:11:40.550
inverted index for faster search and it

00:11:40.550 --> 00:11:43.050
works well for all kinds of formulas

00:11:43.050 --> 00:11:45.560
that are of the general form. This

00:11:45.560 --> 00:11:48.210
general form covers

00:11:48.210 --> 00:11:50.250
actually most state of the art

00:11:50.250 --> 00:11:51.430
retrieval functions.

00:11:53.650 --> 00:11:55.100
So there are some tricks to further

00:11:55.100 --> 00:11:56.840
improve the efficiency.

00:11:56.840 --> 00:12:00.170
Some general techniques

00:12:00.170 --> 00:12:02.950
include the caching.

00:12:02.950 --> 00:12:06.345
This is just to store some results of

00:12:06.345 --> 00:12:08.800
popular queries so that next time when

00:12:08.800 --> 00:12:10.510
you see the same query, you simply

00:12:10.510 --> 00:12:12.450
return the stored results.

00:12:12.450 --> 00:12:14.680
Similarly, you can also store the list

00:12:14.680 --> 00:12:17.900
of inverted index in the memory for

00:12:17.900 --> 00:12:20.460
popular term and if the query terms are

00:12:20.460 --> 00:12:22.370
popular, likely you will soon need to

00:12:22.370 --> 00:12:24.520
fetch the inverted index for the same

00:12:24.520 --> 00:12:25.530
term again.

00:12:25.580 --> 00:12:28.430
So keeping them in the memory would help

00:12:28.430 --> 00:12:30.300
and these are general techniques for

00:12:30.300 --> 00:12:31.590
improving efficiency.

00:12:31.590 --> 00:12:33.930
We can also keep only the most

00:12:33.930 --> 00:12:36.470
promising accumulators because a user

00:12:36.470 --> 00:12:38.720
generally doesn't want to examine so

00:12:38.720 --> 00:12:39.240
many documents.

00:12:39.240 --> 00:12:43.030
We only need to return high quality

00:12:43.030 --> 00:12:45.610
subset of documents that likely are

00:12:45.610 --> 00:12:49.140
ranked on the top. For that purpose,

00:12:49.140 --> 00:12:51.830
we can then prune the accumulators.

00:12:51.830 --> 00:12:53.396
We don't have to store all the

00:12:53.396 --> 00:12:53.799
accumulators.

00:12:53.800 --> 00:12:55.640
At some point, we just keep the

00:12:55.850 --> 00:12:58.490
highest value accumulators.

00:13:00.010 --> 00:13:01.460
Another

00:13:02.440 --> 00:13:04.879
technique is to do parallel processing and

00:13:04.880 --> 00:13:08.490
that's needed for really processing

00:13:08.490 --> 00:13:11.111
such a large data set like the web data

00:13:11.111 --> 00:13:13.660
set and to scale up to the web scale,

00:13:13.660 --> 00:13:16.280
we need a special to have special

00:13:16.280 --> 00:13:17.866
techniques to do parallel processing

00:13:17.866 --> 00:13:21.010
and to distribute the storage of files

00:13:21.010 --> 00:13:22.360
on multiple machines.

00:13:25.750 --> 00:13:29.040
So here, as here's a list of some text

00:13:29.040 --> 00:13:30.570
retrieval tool kits, it's not a

00:13:30.570 --> 00:13:31.750
complete list.

00:13:31.750 --> 00:13:34.760
You can find more information at this

00:13:34.760 --> 00:13:36.400
URL on the bottom.

00:13:37.060 --> 00:13:38.945
Here is the four here

00:13:38.945 --> 00:13:41.776
Lucene is one of the most popular toolkits

00:13:41.776 --> 00:13:45.350
that can support a lot of applications

00:13:45.350 --> 00:13:48.010
and it has very nice support for

00:13:48.010 --> 00:13:48.630
applications.

00:13:48.630 --> 00:13:50.400
You can use it to build a search engine

00:13:50.400 --> 00:13:51.780
application very quickly.

00:13:51.780 --> 00:13:54.200
The downside is that it's not that easy to

00:13:54.200 --> 00:13:55.366
extend it

00:13:55.366 --> 00:13:58.500
and algorithms implemented there also

00:13:58.500 --> 00:14:00.640
not the most advanced algorithms.

00:14:01.350 --> 00:14:03.905
Lemur/Indri is another tool kit

00:14:03.905 --> 00:14:04.730
that

00:14:05.390 --> 00:14:07.560
does not have such a nice support for

00:14:07.560 --> 00:14:09.790
application as lucene, but it has

00:14:09.790 --> 00:14:11.960
many advanced search algorithms.

00:14:12.530 --> 00:14:14.680
And it's also easy to extend.

00:14:16.310 --> 00:14:18.800
Terrier is yet another tool kit that

00:14:18.800 --> 00:14:21.650
also has good support for application

00:14:21.650 --> 00:14:24.150
capability and some advanced

00:14:24.150 --> 00:14:26.490
algorithms, so that's

00:14:28.150 --> 00:14:32.305
maybe in between Lemur or Lucene or

00:14:32.305 --> 00:14:34.620
maybe rather combining the strength of

00:14:34.620 --> 00:14:37.810
both, so that's also a useful tool kit.

00:14:37.810 --> 00:14:42.110
MeTA is the tool kit that we will use for the

00:14:42.110 --> 00:14:44.930
programming assignment and this is a

00:14:44.930 --> 00:14:48.896
new tool kit that has a combination of

00:14:48.896 --> 00:14:52.310
both text retrieval algorithms and text

00:14:52.310 --> 00:14:53.480
mining algorithms.

00:14:54.090 --> 00:14:56.155
And so topic of all those models are

00:14:56.155 --> 00:14:56.540
implemented there.

00:14:56.540 --> 00:14:57.010
There are

00:14:57.010 --> 00:14:59.634
a number of text analysis

00:14:59.634 --> 00:15:02.680
algorithms implemented in the toolkit

00:15:02.680 --> 00:15:05.280
as well as basic search

00:15:05.280 --> 00:15:05.880
algorithms.

00:15:06.640 --> 00:15:09.020
So to summarize, all the discussion

00:15:09.020 --> 00:15:11.910
about the system implementation, here

00:15:11.910 --> 00:15:14.100
are the major takeaway points.

00:15:14.100 --> 00:15:17.560
Inverted index is the primary data

00:15:17.560 --> 00:15:19.770
structure for supporting a search

00:15:19.770 --> 00:15:20.620
engine.

00:15:20.620 --> 00:15:23.760
That's the key to enable faster

00:15:23.760 --> 00:15:25.630
response to a user's query.

00:15:26.260 --> 00:15:28.640
And the basic idea is to preprocess

00:15:28.640 --> 00:15:31.656
the data as much as we can,

00:15:31.656 --> 00:15:33.720
and we want to do compression when

00:15:33.720 --> 00:15:36.130
appropriate so that we can save disk

00:15:36.130 --> 00:15:40.750
space and can speed up IO and

00:15:40.750 --> 00:15:42.719
processing of inverted index.

00:15:42.720 --> 00:15:45.240
In general we talked about how to

00:15:45.240 --> 00:15:47.354
construct the inverted index when the

00:15:47.354 --> 00:15:49.690
data can't fit into the memory, and then

00:15:49.690 --> 00:15:53.130
we talk about the fast search using

00:15:53.130 --> 00:15:54.070
inverted index.

00:15:54.070 --> 00:15:56.222
Basically to exploit the inverted index

00:15:56.222 --> 00:15:58.410
to accumulate the scores for documents

00:15:58.410 --> 00:15:59.210
matching or query term.

00:15:59.910 --> 00:16:02.130
And we explore the Zipf's law to avoid

00:16:02.130 --> 00:16:04.340
attaching many documents that don't

00:16:04.340 --> 00:16:05.870
match any query term.

00:16:06.970 --> 00:16:09.590
And this algorithm can for his support

00:16:09.590 --> 00:16:11.880
a wide range of ranking algorithms.

00:16:13.260 --> 00:16:17.070
So these basic techniques have great

00:16:17.070 --> 00:16:19.250
potential for further scaling up using

00:16:19.250 --> 00:16:21.470
distributed file system, parallel

00:16:21.470 --> 00:16:22.980
processing and caching.

00:16:22.980 --> 00:16:26.430
Here are two additional readings that

00:16:26.430 --> 00:16:28.410
you can take a look if you have time

00:16:28.410 --> 00:16:30.030
and you're interested in learning more

00:16:30.030 --> 00:16:30.710
about this.

00:16:30.710 --> 00:16:33.450
The first one is a classic textbook

00:16:34.990 --> 00:16:37.730
about the efficiency of

00:16:38.350 --> 00:16:40.910
Inverted index and compression

00:16:40.910 --> 00:16:44.200
techniques and how to in general build

00:16:44.200 --> 00:16:46.480
efficient search engine in terms of the

00:16:46.480 --> 00:16:48.810
space, overhead and speed.

00:16:49.840 --> 00:16:52.660
The second one is a newer textbook that

00:16:52.660 --> 00:16:54.660
has a nice discussion of implementing

00:16:54.660 --> 00:16:56.450
and evaluating search engines.


