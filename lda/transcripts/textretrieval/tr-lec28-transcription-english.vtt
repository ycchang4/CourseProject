WEBVTT Kind: captions; Language: en-US

NOTE
Created on 2021-02-27T00:07:08.0405893Z by ClassTranscribe

00:00:00.280 --> 00:00:02.525
This lecture is about the feedback in

00:00:02.525 --> 00:00:04.120
the language modeling approach.

00:00:12.430 --> 00:00:14.570
In this lecture we will continue the

00:00:14.570 --> 00:00:16.070
discussion of feedback in text

00:00:16.070 --> 00:00:16.730
retrieval.

00:00:17.400 --> 00:00:18.830
In particular, we're going to talk

00:00:18.830 --> 00:00:20.810
about the feedback in language modeling

00:00:20.810 --> 00:00:21.420
approaches.

00:00:23.340 --> 00:00:25.850
So we derive the query likelihood

00:00:25.850 --> 00:00:28.540
ranking function by making various

00:00:28.540 --> 00:00:29.280
assumptions.

00:00:30.290 --> 00:00:32.970
As a basic retrieval function, that

00:00:32.970 --> 00:00:35.800
formula of those formulas worked well,

00:00:35.800 --> 00:00:37.240
but if we think about the feedback

00:00:37.240 --> 00:00:38.980
information, it's a little bit of

00:00:38.980 --> 00:00:42.440
awkward to use query like hold too.

00:00:43.150 --> 00:00:45.740
Perform feedback because a lot of times

00:00:45.740 --> 00:00:47.640
the feedback information is additional

00:00:47.640 --> 00:00:48.940
information about the query.

00:00:49.540 --> 00:00:51.130
But we assume that the query is

00:00:51.130 --> 00:00:53.870
generated by assembling words from a

00:00:53.870 --> 00:00:55.830
language model in the query likelihood

00:00:55.830 --> 00:00:56.425
method.

00:00:56.425 --> 00:00:59.970
It's kind of a natural to sample words

00:00:59.970 --> 00:01:03.360
that form feedback documents as a

00:01:03.360 --> 00:01:06.970
result, then researchers proposed a way

00:01:06.970 --> 00:01:09.720
to generalize query like hold function

00:01:09.720 --> 00:01:12.300
and it's called a callback labeler

00:01:12.300 --> 00:01:14.290
divergance retrieval model.

00:01:15.360 --> 00:01:18.400
And this model is actually going to

00:01:18.400 --> 00:01:21.730
make the query likelihood retrieval

00:01:21.730 --> 00:01:24.640
function much closer to vector space

00:01:24.640 --> 00:01:25.010
model.

00:01:25.640 --> 00:01:28.815
Yet, this form of the language model

00:01:28.815 --> 00:01:32.300
can be regarded as a generalization of

00:01:32.300 --> 00:01:34.230
query like hold in the sense that it

00:01:34.230 --> 00:01:36.210
can cover query likelihood as a special

00:01:36.210 --> 00:01:36.620
case.

00:01:38.060 --> 00:01:40.630
And in this case, then, feedback can be

00:01:40.630 --> 00:01:42.990
achieved through simple query model

00:01:42.990 --> 00:01:44.035
estimation or updating.

00:01:44.035 --> 00:01:46.760
This is very similar to Rock Hill which

00:01:46.760 --> 00:01:48.420
updates the query vector.

00:01:49.900 --> 00:01:50.830
So let's see.

00:01:51.490 --> 00:01:53.710
What is this care?

00:01:53.710 --> 00:01:55.300
Divergent switchable model?

00:01:55.300 --> 00:01:58.610
So on the top, what you see is a query

00:01:58.610 --> 00:01:59.420
like hold.

00:02:00.150 --> 00:02:02.340
Retrieval function right this one.

00:02:05.230 --> 00:02:07.550
And then kill diversions or also called

00:02:07.550 --> 00:02:08.610
cross entropy.

00:02:10.140 --> 00:02:12.820
Whichever model is basically to

00:02:12.820 --> 00:02:13.890
generalize.

00:02:14.750 --> 00:02:16.940
The frequency part here.

00:02:17.550 --> 00:02:19.800
Into a language model.

00:02:21.030 --> 00:02:24.170
So basically it's the difference.

00:02:24.750 --> 00:02:28.360
Given by the probabilistic model here

00:02:28.360 --> 00:02:29.990
to characterize what the user is

00:02:29.990 --> 00:02:32.370
looking for versus the count of query

00:02:32.370 --> 00:02:33.310
words there.

00:02:35.710 --> 00:02:39.550
And this difference allows us to plug

00:02:39.550 --> 00:02:42.180
in various different ways to estimate

00:02:42.180 --> 00:02:44.260
this, so this can be estimated in many

00:02:44.260 --> 00:02:46.530
different ways, including using

00:02:46.530 --> 00:02:47.540
feedback information.

00:02:48.160 --> 00:02:50.190
Now this is called a care divergens

00:02:50.190 --> 00:02:50.905
becausw.

00:02:50.905 --> 00:02:53.610
This can be interpreted as measuring

00:02:53.610 --> 00:02:55.350
the care divergent of two

00:02:55.350 --> 00:02:55.990
distributions.

00:02:55.990 --> 00:03:02.060
One is the query model denoted by this

00:03:02.060 --> 00:03:02.850
distribution.

00:03:02.850 --> 00:03:05.620
One is talking the language model.

00:03:06.280 --> 00:03:09.800
Here smoothly with collection language

00:03:09.800 --> 00:03:11.500
model, of course an.

00:03:13.420 --> 00:03:14.680
We're not going to talk about the

00:03:14.680 --> 00:03:16.900
detail of and then find it in some

00:03:16.900 --> 00:03:17.650
references.

00:03:18.290 --> 00:03:20.090
It's also called a cross entropy,

00:03:20.090 --> 00:03:24.660
because in effect we can ignore some

00:03:24.660 --> 00:03:27.150
terms in the care divergent function

00:03:27.150 --> 00:03:29.200
and we will end up having actually

00:03:29.200 --> 00:03:31.690
cross entropy that both our terms in

00:03:31.690 --> 00:03:32.840
information theory.

00:03:34.300 --> 00:03:36.140
But anyway for.

00:03:36.870 --> 00:03:39.940
Our purpose here you can just receive

00:03:39.940 --> 00:03:42.720
the two formulas look almost identical,

00:03:42.720 --> 00:03:45.880
except that here we have a probability

00:03:45.880 --> 00:03:48.010
of award given by a query language

00:03:48.010 --> 00:03:48.490
model.

00:03:49.160 --> 00:03:49.770
All this.

00:03:50.420 --> 00:03:53.479
And here the sum is over all the words

00:03:53.480 --> 00:03:56.775
that are in the document and also with

00:03:56.775 --> 00:04:00.059
the non zero probability for the query

00:04:00.060 --> 00:04:00.610
model.

00:04:00.610 --> 00:04:03.190
So it's kind of again a generalization

00:04:03.190 --> 00:04:05.910
of some overall the match query words.

00:04:08.170 --> 00:04:10.640
Now you can also easy to see we can

00:04:10.640 --> 00:04:13.220
recover the query like hold retrieval

00:04:13.220 --> 00:04:16.270
function by simply setting this query

00:04:16.270 --> 00:04:18.950
model to the relative frequency of

00:04:18.950 --> 00:04:20.670
award in the query.

00:04:22.990 --> 00:04:25.050
This is very easy to see once you plug

00:04:25.050 --> 00:04:26.230
this into.

00:04:26.230 --> 00:04:28.370
Here you can eliminate this query

00:04:28.370 --> 00:04:28.740
Lance.

00:04:28.740 --> 00:04:30.540
That's a constant and then you get

00:04:30.540 --> 00:04:32.150
exactly like that.

00:04:33.240 --> 00:04:35.070
So you can see the equivalence.

00:04:36.090 --> 00:04:39.470
And that's also why this care divergent

00:04:39.470 --> 00:04:40.890
model can be regarded as a

00:04:40.890 --> 00:04:43.170
generalization of query, like whole

00:04:43.170 --> 00:04:46.130
because we can cover query like Rd as a

00:04:46.130 --> 00:04:47.230
special case.

00:04:47.230 --> 00:04:49.110
But it would also allow such rule much

00:04:49.110 --> 00:04:49.890
more than that.

00:04:50.650 --> 00:04:52.660
So this is how we can use the care

00:04:52.660 --> 00:04:55.730
divergent model to them the feedback

00:04:55.730 --> 00:04:57.720
the picture shows that we first

00:04:57.720 --> 00:04:59.820
estimate the document language model.

00:05:00.370 --> 00:05:02.610
Then we estimate the query name model

00:05:02.610 --> 00:05:05.450
and we compute the KL diversions, as is

00:05:05.450 --> 00:05:07.250
often denoted by AD here.

00:05:08.000 --> 00:05:11.430
But this basically means this is

00:05:11.430 --> 00:05:13.290
exactly like a vector space model

00:05:13.290 --> 00:05:15.660
'cause we computer vector for the

00:05:15.660 --> 00:05:17.306
document the computer, another vector

00:05:17.306 --> 00:05:19.760
for the query and then we compute the

00:05:19.760 --> 00:05:22.790
distance only that these vectors are of

00:05:22.790 --> 00:05:24.370
special forms their probability

00:05:24.370 --> 00:05:25.270
distributions.

00:05:27.830 --> 00:05:29.580
And then we got the results and we can

00:05:29.580 --> 00:05:31.610
find some feedback documents.

00:05:31.610 --> 00:05:34.450
Let's assume they are most inactive.

00:05:34.450 --> 00:05:37.320
Sorry, mostly positive documents,

00:05:37.320 --> 00:05:39.100
although we could also consider both

00:05:39.100 --> 00:05:40.210
kinds of documents.

00:05:40.210 --> 00:05:42.360
So what we could do is like in rock

00:05:42.360 --> 00:05:44.283
you'll ever know computer another

00:05:44.283 --> 00:05:46.376
language model, coder feedback,

00:05:46.376 --> 00:05:47.820
language model here.

00:05:48.460 --> 00:05:49.950
Again, this is going to be another

00:05:49.950 --> 00:05:51.850
vector, just like a computing central

00:05:51.850 --> 00:05:52.770
about the in Rock Hill.

00:05:52.770 --> 00:05:55.170
And then this model can be combined

00:05:55.170 --> 00:05:56.880
with the original query model.

00:05:57.450 --> 00:05:59.100
Using a linear interpolation.

00:06:00.370 --> 00:06:02.360
And this would then give us a update

00:06:02.360 --> 00:06:04.800
model just like again in Rock Hill.

00:06:05.720 --> 00:06:07.950
So here we can see the parameter Alpha

00:06:07.950 --> 00:06:10.110
can control the amount of feedback if

00:06:10.110 --> 00:06:12.410
it's set to 0, then it says here

00:06:12.410 --> 00:06:15.110
there's no feedback after set to one,

00:06:15.110 --> 00:06:15.950
we got 4 feedback.

00:06:15.950 --> 00:06:18.593
If we ignore the original query and

00:06:18.593 --> 00:06:21.390
this is generally not desirable, right?

00:06:21.390 --> 00:06:23.995
So this unless you are absolutely sure

00:06:23.995 --> 00:06:25.460
you have seen a lot of relevant

00:06:25.460 --> 00:06:28.370
documents and the query terms are not

00:06:28.370 --> 00:06:29.090
important.

00:06:30.900 --> 00:06:32.699
So of course the main question here is

00:06:32.700 --> 00:06:34.705
how do you compute this single F?

00:06:34.705 --> 00:06:37.090
This is the big question here, and once

00:06:37.090 --> 00:06:38.890
you can do that, the rest is easy.

00:06:38.890 --> 00:06:41.240
So here we will talk about one of the

00:06:41.240 --> 00:06:42.290
approaches and there are many

00:06:42.290 --> 00:06:42.582
approaches.

00:06:42.582 --> 00:06:44.420
Of course this approach is based on

00:06:44.420 --> 00:06:45.470
generated model.

00:06:46.200 --> 00:06:47.970
And I'm going to show you how it works.

00:06:47.970 --> 00:06:50.150
This is the user generated mixable.

00:06:50.150 --> 00:06:53.735
So this picture shows that we have this

00:06:53.735 --> 00:06:54.060
model.

00:06:54.060 --> 00:06:54.740
Here.

00:06:54.740 --> 00:06:56.630
The feedback model that we want to

00:06:56.630 --> 00:06:57.200
estimate.

00:06:57.950 --> 00:06:59.960
And will the basis is the feedback

00:06:59.960 --> 00:07:00.470
documents.

00:07:00.470 --> 00:07:03.420
Let's say we are observing the positive

00:07:03.420 --> 00:07:04.030
documents.

00:07:04.030 --> 00:07:06.490
These are the click the documents by

00:07:06.490 --> 00:07:08.756
users or relevant documents judged by

00:07:08.756 --> 00:07:11.470
users or simply top ranked blocking

00:07:11.470 --> 00:07:12.870
that we assume to be relevant.

00:07:14.580 --> 00:07:16.300
Now imagine how we can compute the

00:07:16.300 --> 00:07:19.752
centroid for these documents by using

00:07:19.752 --> 00:07:20.780
language Model 1.

00:07:20.780 --> 00:07:23.500
Approach is simply to assume these

00:07:23.500 --> 00:07:25.806
documents are generated from this

00:07:25.806 --> 00:07:27.990
language model as we did before.

00:07:27.990 --> 00:07:29.915
What we could do is do just normalize

00:07:29.915 --> 00:07:33.990
the word frequency here and then we got

00:07:33.990 --> 00:07:35.120
this world distribution.

00:07:36.100 --> 00:07:37.680
Now the question is whether this

00:07:37.680 --> 00:07:39.460
distribution is good for feedback.

00:07:39.460 --> 00:07:40.960
But you can imagine.

00:07:42.300 --> 00:07:44.380
The top ranked the world would be what?

00:07:45.620 --> 00:07:46.360
What do you think?

00:07:48.170 --> 00:07:50.769
Those words would be common words,

00:07:50.770 --> 00:07:51.180
right?

00:07:51.180 --> 00:07:53.665
As we always see in a language model,

00:07:53.665 --> 00:07:55.076
the top ranked words are actually

00:07:55.076 --> 00:07:57.510
common words like the etc.

00:07:57.510 --> 00:08:00.500
So it's not very good for feedback

00:08:00.500 --> 00:08:02.270
because we would be adding a lot of

00:08:02.270 --> 00:08:04.030
such words to our query when we

00:08:04.030 --> 00:08:06.915
interpret this with the original query

00:08:06.915 --> 00:08:07.630
model.

00:08:08.770 --> 00:08:10.970
So this is not good.

00:08:10.970 --> 00:08:13.680
So when it do something in particular

00:08:13.680 --> 00:08:16.370
will are trying to get rid of those

00:08:16.370 --> 00:08:18.450
common words and we are we have seen

00:08:18.450 --> 00:08:20.330
actually one way to do that by using

00:08:20.330 --> 00:08:21.500
background language model.

00:08:21.500 --> 00:08:24.390
In the case of learning the

00:08:24.390 --> 00:08:28.370
associations with words, words that are

00:08:28.370 --> 00:08:29.790
related to the water computer.

00:08:30.710 --> 00:08:32.320
We could do that and there will be

00:08:32.320 --> 00:08:34.680
another way to do this, but here we are

00:08:34.680 --> 00:08:36.289
going to talk about another approach

00:08:36.290 --> 00:08:38.430
which is more principled approach.

00:08:39.050 --> 00:08:40.400
In this case, we're going to state,

00:08:40.400 --> 00:08:43.040
well, you said that there are common

00:08:43.040 --> 00:08:44.870
words here in this.

00:08:44.870 --> 00:08:47.640
These documents that should not belong

00:08:47.640 --> 00:08:49.490
to this topic model, right?

00:08:50.160 --> 00:08:52.300
So now what we can do is to assume

00:08:52.300 --> 00:08:55.040
that, well, those words are generated

00:08:55.040 --> 00:08:57.210
from background language model, so they

00:08:57.210 --> 00:08:59.930
were generated those words like the.

00:09:00.710 --> 00:09:01.540
Example.

00:09:02.330 --> 00:09:04.270
And if we use maximum likelihood

00:09:04.270 --> 00:09:06.900
estimator, note that if all the words

00:09:06.900 --> 00:09:11.090
here must be generated from this model,

00:09:11.090 --> 00:09:11.880
then.

00:09:12.470 --> 00:09:14.490
This model is forced to assign high

00:09:14.490 --> 00:09:16.850
probabilities to award like that

00:09:16.850 --> 00:09:18.750
because it occurs so frequently here.

00:09:19.510 --> 00:09:21.390
Note that in order to reduce its

00:09:21.390 --> 00:09:23.450
probability in this model.

00:09:24.250 --> 00:09:26.205
We have to have another model which is

00:09:26.205 --> 00:09:29.680
this one to help explain the world.

00:09:29.680 --> 00:09:33.260
The here and in this case it's not

00:09:33.260 --> 00:09:34.940
appropriate to use the background

00:09:34.940 --> 00:09:37.520
language model to achieve this goal,

00:09:37.520 --> 00:09:39.380
because this model would assign high

00:09:39.380 --> 00:09:42.320
probabilities to these common words.

00:09:43.270 --> 00:09:46.780
So in this approach, then we assume

00:09:46.780 --> 00:09:48.350
this machine that was generated.

00:09:48.350 --> 00:09:50.720
These words would work as follows.

00:09:50.720 --> 00:09:53.480
We have a source controller here.

00:09:53.480 --> 00:09:56.750
Imagine we flip a coin here to decide

00:09:56.750 --> 00:09:59.216
what distribution to use with

00:09:59.216 --> 00:10:00.950
probability of Lambda.

00:10:00.950 --> 00:10:03.330
The coin shows up as head and we're

00:10:03.330 --> 00:10:04.602
going to use the background language

00:10:04.602 --> 00:10:06.910
model and we can do that simple word

00:10:06.910 --> 00:10:10.629
from that model with probability of 1

00:10:10.630 --> 00:10:11.230
minus them.

00:10:11.230 --> 00:10:13.360
Now will do decide to use the unknown.

00:10:13.430 --> 00:10:16.600
Topic model here that we would like to

00:10:16.600 --> 00:10:18.020
estimate and we're going to then

00:10:18.020 --> 00:10:20.000
generate award here.

00:10:20.000 --> 00:10:21.750
If we make this assumption and this

00:10:21.750 --> 00:10:24.926
whole thing would be just one model and

00:10:24.926 --> 00:10:27.905
we call this mixture model 'cause there

00:10:27.905 --> 00:10:29.550
are two distributions that are mixed

00:10:29.550 --> 00:10:31.400
together and we actually don't know

00:10:31.400 --> 00:10:33.930
when each distribution is used.

00:10:35.050 --> 00:10:38.720
So again, think of this whole thing as

00:10:38.720 --> 00:10:40.190
one model.

00:10:42.170 --> 00:10:44.450
And we can still ask for words, and it

00:10:44.450 --> 00:10:46.560
will still give us a word in a random

00:10:46.560 --> 00:10:47.250
manner, right?

00:10:47.800 --> 00:10:49.710
And of course, which word will show up

00:10:49.710 --> 00:10:51.736
would depend on both this distribution

00:10:51.736 --> 00:10:53.200
and that distribution.

00:10:53.200 --> 00:10:55.230
In addition, it would also depend on

00:10:55.230 --> 00:10:57.870
this Lambda, because if you say Lambda

00:10:57.870 --> 00:10:59.910
is very high and it's going to always

00:10:59.910 --> 00:11:01.920
use the background distribution, you'll

00:11:01.920 --> 00:11:03.982
get different words than if you say

00:11:03.982 --> 00:11:06.078
lemme's very small, we're going to use

00:11:06.078 --> 00:11:06.310
this.

00:11:07.010 --> 00:11:09.200
Right, so all these are parameters.

00:11:09.960 --> 00:11:11.020
In this model.

00:11:12.530 --> 00:11:14.540
And then if you think in this way,

00:11:14.540 --> 00:11:18.290
basically we can do exactly the same as

00:11:18.290 --> 00:11:19.190
what we did before.

00:11:19.190 --> 00:11:21.680
We are going to use maximum likelihood

00:11:21.680 --> 00:11:23.990
estimator to adjust this model to

00:11:23.990 --> 00:11:25.380
estimate the parameters.

00:11:25.380 --> 00:11:27.790
Basically we're going to adjust well

00:11:27.790 --> 00:11:29.000
this parameter.

00:11:30.010 --> 00:11:32.720
So that we can best explain all the

00:11:32.720 --> 00:11:33.170
data.

00:11:33.170 --> 00:11:35.680
The difference now is that we are not

00:11:35.680 --> 00:11:39.635
asking this model alone to explain

00:11:39.635 --> 00:11:40.380
this.

00:11:41.110 --> 00:11:42.990
But rather, we're going to ask this

00:11:42.990 --> 00:11:46.120
whole model mixture model to explain

00:11:46.120 --> 00:11:48.290
the data becauses there has got some

00:11:48.290 --> 00:11:50.185
help from the background model.

00:11:50.185 --> 00:11:52.288
It doesn't have to assign high

00:11:52.288 --> 00:11:53.980
probabilities towards like the.

00:11:53.980 --> 00:11:56.400
As a result, it would then assign

00:11:56.400 --> 00:11:58.730
higher probabilities to other words

00:11:58.730 --> 00:12:00.442
that are common here.

00:12:00.442 --> 00:12:04.860
But not having high probability here.

00:12:04.860 --> 00:12:06.990
So those will be common here.

00:12:09.720 --> 00:12:10.210
I.

00:12:11.480 --> 00:12:13.753
And if they are common, they would have

00:12:13.753 --> 00:12:15.600
to have high probabilities according to

00:12:15.600 --> 00:12:17.050
maximum likelihood estimator.

00:12:17.780 --> 00:12:20.590
An if they are rare here.

00:12:21.570 --> 00:12:23.850
Right, so if they are rare here.

00:12:25.370 --> 00:12:28.630
Then you don't get much help from this

00:12:28.630 --> 00:12:29.520
background model.

00:12:29.520 --> 00:12:31.940
As a result, this topic model must

00:12:31.940 --> 00:12:34.509
assign high probabilities, so the high

00:12:34.510 --> 00:12:36.600
probability words according to the

00:12:36.600 --> 00:12:38.910
topic model would be those that are

00:12:38.910 --> 00:12:41.506
common here, but rare in the

00:12:41.506 --> 00:12:41.819
background.

00:12:43.320 --> 00:12:46.940
OK, so this is basically a little bit a

00:12:46.940 --> 00:12:48.250
IDF waiting here.

00:12:49.120 --> 00:12:51.420
But this would allow us to achieve the

00:12:51.420 --> 00:12:53.970
effect of removing this top awards that

00:12:53.970 --> 00:12:56.020
are meaningless in the feedback.

00:12:56.690 --> 00:12:59.370
So mathematically, what we have is to

00:12:59.370 --> 00:13:01.920
compute the like hold again local, like

00:13:01.920 --> 00:13:05.510
hold of the feedback documents and.

00:13:06.080 --> 00:13:07.710
And note that we also have another

00:13:07.710 --> 00:13:09.569
parameter Lambda here, but we assume

00:13:09.569 --> 00:13:11.610
that the Lambda denotes the noise in

00:13:11.610 --> 00:13:13.090
the feedback document.

00:13:13.090 --> 00:13:15.160
So we are going to, let's say set this

00:13:15.160 --> 00:13:18.020
to a parameter that say 50% of the

00:13:18.020 --> 00:13:21.738
words are noise or 9% are noise and

00:13:21.738 --> 00:13:25.076
this can be assumed to be fixed if we

00:13:25.076 --> 00:13:26.550
assume this is fixed.

00:13:27.360 --> 00:13:28.130
Then

00:13:28.730 --> 00:13:31.960
We only have these probabilities as

00:13:31.960 --> 00:13:33.820
parameters, just like in the simplest

00:13:33.820 --> 00:13:34.880
unigram language model.

00:13:34.880 --> 00:13:37.370
We have end parameters and is the

00:13:37.370 --> 00:13:38.110
number of words.

00:13:38.960 --> 00:13:40.650
And then the likelihood function would

00:13:40.650 --> 00:13:41.500
look like this.

00:13:42.720 --> 00:13:44.790
It's very similar to the likelihood

00:13:44.790 --> 00:13:45.710
function local.

00:13:45.710 --> 00:13:48.100
I can hold a function we see before,

00:13:48.100 --> 00:13:50.110
except that inside the logarithm

00:13:50.110 --> 00:13:53.400
there's a some here, and this sum is

00:13:53.400 --> 00:13:54.130
becausw.

00:13:54.130 --> 00:13:56.150
We consider two distributions.

00:13:56.950 --> 00:13:59.420
And which one is used would depend on

00:13:59.420 --> 00:14:01.080
Lambda and that's why we have this

00:14:01.080 --> 00:14:01.500
form.

00:14:02.400 --> 00:14:04.950
But mathematically, this is their

00:14:04.950 --> 00:14:07.720
function with theater as unknown

00:14:07.720 --> 00:14:08.820
variables, right?

00:14:08.820 --> 00:14:11.050
So this is just a function or the other

00:14:11.050 --> 00:14:14.000
values are known except for this guy.

00:14:14.900 --> 00:14:17.410
So we can then choose this probability

00:14:17.410 --> 00:14:21.130
distribution to maximize this locali

00:14:21.130 --> 00:14:21.680
code.

00:14:22.390 --> 00:14:24.040
The same idea as the maximum, like

00:14:24.040 --> 00:14:25.850
Horace made it as a mathematical

00:14:25.850 --> 00:14:26.294
problem.

00:14:26.294 --> 00:14:28.850
We just we just have to solve this

00:14:28.850 --> 00:14:29.845
optimization problem.

00:14:29.845 --> 00:14:32.010
We essentially would try all the

00:14:32.010 --> 00:14:34.410
theater values and until we find one

00:14:34.410 --> 00:14:36.789
that gives this whole thing the maximum

00:14:36.790 --> 00:14:37.600
probability.

00:14:37.600 --> 00:14:39.450
So it's a well defined math problem.

00:14:40.720 --> 00:14:42.800
Once we have done that, will obtain the

00:14:42.800 --> 00:14:45.020
serial F that can be there, interpreted

00:14:45.020 --> 00:14:47.450
with the original query model to do

00:14:47.450 --> 00:14:48.070
feedback.

00:14:50.890 --> 00:14:53.670
So here are some examples of the

00:14:53.670 --> 00:14:56.010
feedback model learned from a Web

00:14:56.010 --> 00:14:59.020
document collection, and we do sudo

00:14:59.020 --> 00:14:59.253
feedback.

00:14:59.253 --> 00:15:01.228
Are we just use the top ten documents

00:15:01.228 --> 00:15:03.990
and we use this mixture model so the

00:15:03.990 --> 00:15:05.880
query is airport security?

00:15:05.880 --> 00:15:08.190
What we do is we first retrieve 10

00:15:08.190 --> 00:15:10.630
documents from the web database.

00:15:11.240 --> 00:15:12.570
And this is of course a pseudo

00:15:12.570 --> 00:15:13.710
feedback.

00:15:13.710 --> 00:15:16.080
I and then we're going to feed that

00:15:16.080 --> 00:15:18.710
mixture model to this 10.

00:15:19.280 --> 00:15:20.220
Document set.

00:15:21.030 --> 00:15:24.880
And these are the words learned using

00:15:24.880 --> 00:15:25.740
this approach.

00:15:25.740 --> 00:15:27.950
This is the probability of award given

00:15:27.950 --> 00:15:30.310
by the feedback model in both cases.

00:15:31.510 --> 00:15:33.829
So in both cases you can see the

00:15:33.830 --> 00:15:36.472
highest probability words include very

00:15:36.472 --> 00:15:39.220
relevant words to the query, so airport

00:15:39.220 --> 00:15:40.145
security, for example.

00:15:40.145 --> 00:15:42.540
This query words still show up as high

00:15:42.540 --> 00:15:45.340
probabilities in each case naturally

00:15:45.340 --> 00:15:47.289
becausw they occur frequently in the

00:15:47.290 --> 00:15:49.650
top ranked documents, but we also see

00:15:49.650 --> 00:15:52.210
beverage, alcohol, bomb, terrorists,

00:15:52.210 --> 00:15:53.190
etc.

00:15:53.190 --> 00:15:58.265
So these are relevant to this topic and

00:15:58.265 --> 00:16:01.160
they if combined with the original

00:16:01.160 --> 00:16:01.730
query.

00:16:01.780 --> 00:16:04.130
Can help us match more accurately

00:16:04.130 --> 00:16:07.600
documents and also they can help us

00:16:07.600 --> 00:16:10.200
bring up a documents that only imagine

00:16:10.200 --> 00:16:12.620
the some of these other words.

00:16:12.620 --> 00:16:14.940
Maybe for example just the airport and

00:16:14.940 --> 00:16:18.120
then bomb for example this.

00:16:18.120 --> 00:16:20.580
So this is how single feedback works.

00:16:20.580 --> 00:16:22.919
Issues that this model really works and

00:16:22.920 --> 00:16:25.540
picks up some related words to the

00:16:25.540 --> 00:16:26.100
query.

00:16:26.710 --> 00:16:29.000
What's also interesting is that if you

00:16:29.000 --> 00:16:31.469
look at the two tables here and you

00:16:31.470 --> 00:16:34.160
compare them and you see in this case

00:16:34.160 --> 00:16:36.970
when Lambda is set to a small value and

00:16:36.970 --> 00:16:39.080
we still see some common words here.

00:16:40.640 --> 00:16:41.450
And that means.

00:16:42.580 --> 00:16:45.090
When we don't use the background more

00:16:45.090 --> 00:16:46.780
often, remember Lambda can use the

00:16:46.780 --> 00:16:48.310
probability of using the background

00:16:48.310 --> 00:16:50.210
model to generate the text.

00:16:50.810 --> 00:16:52.805
If we don't rely much on background

00:16:52.805 --> 00:16:55.343
model, we still have to use this topic

00:16:55.343 --> 00:16:57.800
model to account for the common words,

00:16:57.800 --> 00:17:00.960
whereas if we set Lambda to a very high

00:17:00.960 --> 00:17:03.396
value, we will use the background model

00:17:03.396 --> 00:17:05.440
very often to explain these words.

00:17:05.440 --> 00:17:07.540
Then there's no burden on explaining

00:17:07.540 --> 00:17:09.620
those common words in the feedback

00:17:09.620 --> 00:17:11.849
documents by the topic model.

00:17:11.850 --> 00:17:14.210
So as a result of the topic model, here

00:17:14.210 --> 00:17:18.160
is very discriminant if it contains all

00:17:18.160 --> 00:17:19.710
the relevant words without common

00:17:19.710 --> 00:17:20.020
words.

00:17:21.150 --> 00:17:23.890
So this can be added to the original

00:17:23.890 --> 00:17:26.280
query to achieve feedback.

00:17:28.070 --> 00:17:31.040
So to summarize, in this lecture we

00:17:31.040 --> 00:17:32.290
have talked about the feedback in

00:17:32.290 --> 00:17:34.050
language model approach.

00:17:34.050 --> 00:17:37.785
In general, feedback is to learn from

00:17:37.785 --> 00:17:38.230
examples.

00:17:38.230 --> 00:17:40.136
These examples can be assumed, examples

00:17:40.136 --> 00:17:42.390
can be sued, examples like.

00:17:43.640 --> 00:17:46.660
Assume that the top ten documents that

00:17:46.660 --> 00:17:48.762
are assumed to be random in there could

00:17:48.762 --> 00:17:51.015
be based on using fractions like a

00:17:51.015 --> 00:17:54.010
feedback based on pixels or implicit

00:17:54.010 --> 00:17:54.640
feedback.

00:17:54.640 --> 00:17:56.525
We talked about the three major

00:17:56.525 --> 00:17:58.860
feedback scenarios, relevance feedback,

00:17:58.860 --> 00:18:00.330
sooner feedback, and in principle

00:18:00.330 --> 00:18:00.820
feedback.

00:18:01.900 --> 00:18:04.640
We talked about how to use Rock You to

00:18:04.640 --> 00:18:07.684
do feedback in vector space model and

00:18:07.684 --> 00:18:11.900
how to use query model is missing for

00:18:11.900 --> 00:18:14.870
feedback in language model and we

00:18:14.870 --> 00:18:16.833
briefly talked about the mixture model

00:18:16.833 --> 00:18:18.780
and the basic idea.

00:18:19.440 --> 00:18:21.730
There are many other methods, for

00:18:21.730 --> 00:18:23.630
example, the relevance model is a very

00:18:23.630 --> 00:18:26.250
effective model for estimating query

00:18:26.250 --> 00:18:26.890
model.

00:18:26.890 --> 00:18:29.390
So you can read more about these

00:18:29.390 --> 00:18:32.670
methods in the references that listed

00:18:32.670 --> 00:18:34.750
at the end of this lecture.

00:18:36.100 --> 00:18:38.050
So there are two additional readings

00:18:38.050 --> 00:18:38.740
here.

00:18:38.740 --> 00:18:41.360
The first one is a book that has a

00:18:41.360 --> 00:18:43.700
systematic review and discussion of

00:18:43.700 --> 00:18:45.070
language models for information

00:18:45.070 --> 00:18:47.590
retrieval and signal.

00:18:47.590 --> 00:18:50.620
One is important research paper that's

00:18:50.620 --> 00:18:53.743
about relevance based language models,

00:18:53.743 --> 00:18:55.540
and it's a very effective way of

00:18:55.540 --> 00:18:56.890
computing query model.


