lecture natural_language content picture step process text data text data natural computers understand natural_language extent order use thats topic going cover natural_language processing main technique processing natural_language obtain understanding second state art nlp stands natural_language finally going cover relation natural_language processing text nlp best way explain think text foreign language order understand text basically computers facing right looking simple sentence like dog chasing boy dont problem understanding imagine computer order understand general know dogs noun chasing verb called lexical analysis speech_tagging need figure syntactic categories thats going figure structure example shows dog form noun_phrase wont dog structures structure shows look sentence try interpret words 1st noun phrases intermediate components verbal finally structure need called syntactic analysis parsing computer program automatically create point know structure sentence dont know meaning sentence semantic_analysis mind usually map sentence know knowledge example imagine dog looks like theres boy theres computer use symbols denote right use symbol d1 denote dog b1 denote boy p1 denote playground chasing activity thats happening relation chasing connects computer obtain understanding representation infer things naturally think read text called example believe chased person scared rule computers infer boy extra knowledge infer based understanding understand person said sentence reduced use pragmatic order understand speech actor like basically achieve theres purpose use case person said sentence reminding person bring possible intent reach level understanding require computer steps order completely understand humans trouble understanding thats large knowledge base brain use common_sense knowledge help interpret computers unfortunately hard obtain dont knowledge base incapable reasoning makes natural_language processing difficult fundamental reason natural_language processing difficult computers simply natural_language designed natural languages designed languages designed example program harder natural languages designed communication result omit lot common_sense knowledge assume lot ambiguities assume receiver hearer know disambiguate ambiguous word based knowledge theres need invent different words different overload word different meanings reasons makes step natural_language processing computers ambiguity main common_sense reasoning thats let examples consider word level word different syntactic example design noun word root multiple meanings square root math sense root able think syntactical ambiguities main topic lecture natural_language processing actually interpreted ways terms think moment usually think processing natural_language think language processes alright example syntactic ambiguity different structures applied sequence common example ambiguous sentence man saw boy case question telescope right called prepositional_phrase ambiguity pp attachment generally dont problem lot background knowledge help disambiguate example difficulties anaphora resolution think sentence like john persuaded bill buy question refer john bill use background context finally presupposition consider quit obviously implies imagine computer wants understand subtle_differences use lot knowledge maintain large knowledge knowledge base meanings words connected common_sense knowledge result perfect fact far perfect understanding natural_language slide sort gives simplified view state art speech_tagging pretty showed 97 number obviously based certain data set dont shows pretty terms parsing partial_parsing means noun_phrase structures verbal phrases structures segment sentence understood correctly terms evaluation results seen 90 accuracy terms partial_parsing numbers relative data set data numbers existing work evaluated news data set lot numbers biased news think social_media data accuracy likely terms semantic_analysis far able complete_understanding techniques allow partial understanding example techniques allow extract entities relations mentioned text example recognizing mentions people locations organisations etc called entity able recognize relations example person visited place person met person company acquired relations extracted current natural_language processing_techniques theyre perfect entities word sense_disambiguation figure word sentence certain meaning computer figure different perfect sentiment_analysis meaning figure weather sentence positive especially useful review analysis examples semantic_analysis help obtain partial understanding giving complete_understanding showed sentence help gain understanding content terms inference partly general difficulty inference general challenging artificial thats partly dont complete semantic representation natural_language text hard domains limited domains lot restrictions word uses maybe able perform extent speech act analysis far analysis special_cases roughly gives idea state talk little bit cant percent speech_tagging looks like simple task think users different syntactic try fine grained distinguishing easy figure hard general complete parsing sentence saw ambiguity hard disambiguate imagine example use lot knowledge context sentence background order figure actually sentence looks simple actually pretty hard cases sentence imagine prepositional phrases possibilities hard precise deep semantic_analysis heres example john owns define owns exactly word understand hard precisely describe meaning result robust general natural_language processing_techniques process lot text shallow way meaning superficial example parts speech_tagging partial_parsing recognizing sentiment deep understanding cause understanding exact meaning hand deeper understanding techniques tend scale meaning fail unrestricted dont restrict text domain use words techniques tend work based machine_learning techniques data similar training_data program trained generally wouldnt data different training_data pretty summarizes state art natural_language course short time cant complete view nlp big field expect multiple courses natural_language topic relevance topic talk useful know case havent mean text retrieval text retrieval dealing kinds hard restrict text certain dealing lot text means nlp_techniques general robust efficient implies today use fairly shallow nlp_techniques text fact search engines today use called bag words probably simplest representation possibly turn text data simply bag words meaning individual words ignore orders duplicated occurrences called bag words represent text way ignore lot information makes harder understand exact meaning sentence weve lost representation tends actually work pretty search tasks partly search task matching query words text document chances document topic comparison tasks example machine translation require understand language accurately translation comparison search task relatively representation sufficient thats representation major search engines today like google course course queries answered current search engines require representation bag words representation require natural_language reason sophisticated nlp_techniques modern_search engines thats retrieval techniques actually naturally solve problem example word sense_disambiguation think world like mean coffee mean program look world ambiguous user uses word query usually example im looking usage java applet java means program context help naturally prefer documents java referring program language cause documents probably match applet java occurs document way means match applet small probability right case retrieval techniques naturally achieve goal word sense_disambiguation technical code feedback talk later technical code allow add additional words query additional words related query words help matching documents original_query words achieves semantic matching techniques helped bypass difficulties natural_language long run need deeper_natural language processing_techniques order improve accuracy current search engines particularly needed complex search question google recently launched knowledge_graph step cause knowledge_graph contain entities relations goes simple bag words representation technique help improve search_engine utility open topic research summary lecture talked nlp weve talked state art techniques finally explain bag words representation remains dominant representation modern_search engines deeper nlp needed future search want know look additional_readings cited thats good starting
lecture going talk text previous_lecture talk natural_language content explained state art natural_language processing_techniques good process lot unrestricted text data robust result bag words representation remains popular applications like search lecture going talk high level help users access text important step convert raw big text data small relevant data actually needed specific main question address text information system help users access relevant text data going cover complementary strategies push_versus going talk ways implement pull_mode querying versus push_versus different ways connect users right information right takes party takes initiative pull_mode users start information_access case user typically use search_engine fulfill example user type query browse results find relevant usually appropriate satisfying users ad_hoc information ad_hoc information need temporary information need want buy product suddenly need read reviews related collected information purchased generally longer need information temporary information case hard system predict need appropriate users initiative thats search engines useful today people ad_hoc information needs speaking google probably processing queries ad_hoc information pull_mode contrast push mode system initiative push information user recommend information case usually supported recommender appropriate user stable information example research interest topic interest tends stay awhile relatively hobby example stable information case system interact learn interest monitor information system seen relevant items interest system initiative recommend example news filter news recommender system monitor news stream identify interesting news simply push news_articles mode information_access maybe appropriate system good knowledge users need happens search example search information web_search engine infer interested related recommend information remind example advertisement placed search high level strategies modes text lets look pull_mode pull_mode distinguish ways help users querying versus querying user enter typical keyword query search_engine system return relevant_documents works user knows exactly know exactly youre looking tend know right keywords querying work know doesnt work dont know right keywords use query want browse information topic case browsing case browsing users simply navigate relevant information following paths structures system maintain kind structures user follow structures works user wants explore information user doesnt know key words use simply user finds inconvenient type user knows query type user cell search information hard enter query browsing tends relationship browsing query best understood making analogy sight imagine touring know exact address attraction taking taxi fastest way directly site dont know exact address need walk taxi nearby place turns exactly information know exactly youre looking use right keywords query find information thats usually fastest way find dont know exact keywords use query probably wont work youll land related pages need walk information space meaning following links finally relevant want learn topic likely lot like looking area want interesting attractions related analogy tells good spot query dont good support order browse effectively need map like need map chicago tour city chicago need topic map tour information construct topic map fact interesting research question likely bring interesting browsing experience web summarize lecture weve talked high level strategies text access push push tends supported recommender_systems pull tends supported search_engine course sophisticated intelligent_information system pull_mode distinguish querying browsing generally want combine ways help users support querying want know relationship pull read gives excellent discussion relationship information filtering information information filtering similar information recommendation push mode information_access
lecture text retrieval picture_shows overall plan lecture talked high level strategies text talked push_versus search engines main tools supporting pull_mode starting lecture going talk search engines work text retrieval going talk things define text second going comparison text retrieval related task database finally going talk document selecting versus document ranking strategies responding users text retrieval task thats familiar web_search engines text retrieval basically task system respond users query relevant_documents basically support way implement pull_mode information_access scenario following collection text documents web pages literature articles digital maybe text files user typically query system express information need system return relevant_documents relevant_documents refer documents useful user typing task called information literally information retrieval broadly include retrieval non textual example audio video worth noting text retrieval core information retrieval sense medias video retrieved exploiting companion text current image search actually match users query companion text data problem called search technology called search technology course useful pause lecture differences text retrieval database tasks similar ways important spend moment think think data information managed search_engine versus managed database think difference queries typically specify database versus queries typed users search_engine finally think whats difference ok think information data managed text retrieval data unstructured free text structured data clear definer schema column names people column ages unstructured text obvious names people mentioned difference text information tends ambiguous talked natural_language processing databases data tended defined important difference partly difference text queries tend database queries typically think sql query clearly specify records returned defined keyword_queries natural_language queries tend doesnt fully specify document database sql query regarded computer specification differences answers case texy retrieval looking relevant_documents database search retrieving records match sql query case tax retrieval right answers query specified unclear right answers query important consequences text retrieval empirically_defined empirically_defined mathematically prove method better means rely empirical evaluation involving know method_works thats lecture actually lectures cover issue important topic search knowing evaluate algorithm appropriately theres way tell got better algorithm system lets look problem formal slide_shows formal formulation text retrieval vocabulary set words considering language reality web multiple natural text data kinds simplicity assume kind language techniques retrieving data multiple languages similar techniques retrieving documents important difference principles query sequence defined sequence q sub word document defined way sequence words d sub word typically documents longer documents think example hope think twitter search right tweets general documents longer collection collection large think goal text retrieval find set relevant_documents denoted r q depends query general subset documents unfortunately set relevant_documents generally user dependent sense query typed different expected relevant_documents query given user hint document user generally unable specify exactly set especially case web_search collection large user doesnt complete knowledge best search compute approximation relevant set denote r prime formally task compute r prime q approximation relevant_documents imagine asked write think right query compute answers set documents useful solve problem strategies strategies document selection going binary classification function binary thats function document query zero output indicate document relevant case relevant document set defined follows value 1 case system decide document basically called absolute_relevance basically needs know exactly going useful alternatively theres strategy called document case system going document relevant system going use real value function simply value indicate document likely going document relevant document likely function rank going let user decide stop user looks determine documents approximation assume documents ranked threshold cause effect documents deliver theta cut determined weve_got collaboration user sense dont cut user kind helped system case system needs decide document likely relevant needs determine relative opposed absolute_relevance probably relevant relative relevance easier determine absolute_relevance case exactly document turns ranking generally_preferred document lets strategies picture_shows left documents use indicate relevant_documents true relevant_documents set random documents consist pluses document functioning going basically classify groups relevant_documents non_relevant course classifier perfect approximation relevant_documents got non_relevant similarly relevant document thats miss classified non_relevant case document ranking system like simply ranks documents descending order going let users stop user wants user wants examine documents user list examine stop lower user wants read relevant_documents user stop case user_stops d4 effect delivered said ranking generally_preferred reasons case document selection unlikely clue usually query query accurate sense overly example expect relevant_documents topics specific vocabulary match random documents collection discussed topic case relevant_documents return case overly constraint hand query underconstrained query sufficient discriminating words find relevant_documents actually end having thought words sufficient help find relevant_documents turns sufficient distraction documents similar case unfortunately hard find right position cause user looking information general user good knowledge information case user good vocabularies random hard user pre specify right level classifier want rank red generally equally relevance matter documents user note prioritization user digest contents user general look document sense feed users relevant_documents thats reasons ranking generally_preferred preference theoretical justification given probability ranking end lecture principle says returning ranked_list documents descending order probability document relevant query optimal strategy following utility document user independent utility 2nd user assumed browse results easy understand assumptions needed order justify ranking documents independent evaluate utility document allow compute score document independently going rank documents based second assumption user follow ranked_list user going follow ranked_list going examine documents sequentially obviously ordering theoretically justify rankings strategy fact ive assumptions hold suggest pause lecture moment think examples assumptions arent necessarily think moment assumptions actually example case independence_assumption identical documents similar content exactly user assume generally useful user similar clearly utility document dependent documents user cases scenario document useful user particular documents provide answer users collective relevance suggests value document depend sequential browse general sense ranked_list ranked_list evidence showing users dont strictly sequentially entire look example think complicated interface possibly use like 2 dimensional interface additional information screen seek youre browsing restrictive assumptions probability ranking principle established solid foundation ranking primary task search actually basis lot research work information retrieval algorithms designed based assumption assumptions arent necessarilly true address problem post processing ranked_list example remove summarize lecture main away text retrieval empirical defined means algorithm better judged second document ranking generally_preferred help users prioritize examination search bypass difficulty determining absolute_relevance help users determining suggests main technical challenge designing search_engine redesigned effective ranking_function words need define value function query document function main topic following_lectures suggested additional_readings classic paper probability ranking second read research information classic ir excellent coverage main research results early time book written chapter 6 book depth discussion probability ranking principle probabilistic retrieval models
lecture overview text retrieval previous_lecture introduced problem text explained main problem design ranking_function rank documents query lecture overview different ways designing ranking_function problem query sequence words document thats sequence words hope define function compute score based query main challenge design good ranking_function rank relevant_documents non_relevant clearly means function able measure likelihood document d relevant query means way define particular order implement program computational definition achieve goal designing retrieval model gives formalization decades researchers designed different kinds retrieval fall different thing models based similarity basically assume document similar query document document relevant case ranking_function defined similarity query known example case vectors space_model cover detail later second kind models called probabilistic_models family models follow different strategy queries documents observations random assume binary random_variable called indicate document relevant define score document respect query probability random_variable r equal 1 given particular document different cases general classic probabilistic language_model divergent randomness later lecture talk case language_model kind models based probabilistic influence idea associate uncertainity inference_rules quantify probability query follows finally family models axiomatic idea define set constraints good retrieval case problem seek good ranking_function satisfy desired interestingly different models based different retrieval tends functions tend involve similar lets look common form state retrieval examine common ideas models based assumption bag words represent text explained natural_language processing bag words representation remains main search assumption score query presidential_campaign respect document d based scores computed based individual means score depend score presidential_campaign different components corresponding document matches query inside number example factor function g times world presidential occur called term_frequency denote c presidential word occurs frequently document value function factor long use document_length term occurs long document occurred number times short document long term expected occur finally factor called document want look presidential occurs entire document frequency df use characterize probability presidential trying characterize popularity term collection general matching rare_term contributing overall score matching common captures main ideas pretty state art retrieval natural question model works best turns models work equally list major models generally regarded state art retrieval pivoted_length bm25 query likelihood optimized models tend perform discussed detail reference end bm25 probably likely virtually search engines method discussed research_papers talk method main points lecture design good ranking_function pre requires computational definition relevance achieve goal designing appropriate retrieval second models equally effective dont single researchers actively working trying find truly optimal retrieval finally state art ranking functions tend rely following bag words tf document frequency words weighting function determine overall contribution matching document combined interesting ways discuss exactly combined rank documents lectures suggested additional_readings paper find detailed discussion comparison multiple state art second book chapter gives broad review different retrieval
lecture vector_space retrieval model going introduction basic_idea lecture talked different ways designing retrieval different ranking_function lecture going talk specific way designing ranking_function called vector_space retrieval going brief introduction basic_idea vector_space model special case similarity based models discussed means assume relevance roughly similarity document assumption true actually order solve search problem convert vague notion relevance precise definition implemented programming process number basically assume document similar query document document assumed relevant second basis ranking documents questionable best definition later ways model basic_idea vector_space retrieval model actually easy imagine high dimensional_space dimension corresponds 3 dimensional_space words programming library term defines consider vectors 3 dimensional_space going assume documents query placed vector_space example document represented vector means document probably covers library presidential doesnt talk alright mean terms representation document means going look document perspective going basically vector representation course document example orders words simply ignored thats assume bag words representation d1 suggest topic presidential different document represented different vector case document covers programming library talk remind probably guess topic likely programming language library software shows vector_space representation actually capture differences topics imagine vectors example d3 pointing present fact place documents vector_space pointing kinds similarly going place query space going measure similarity query vector document case example easily d2 closest query vector d2 basically main_idea vector_space vector_space model framework following represent document query term term basic concept example word ngram sequence characters inside term assumed define n terms vocabulary define n dimensional_space query vector consist number corresponding weights different document vector number elements value element indicating weight corresponding assume n_dimensions n corresponding weight particular relevance case assumed similarity ranking_function defined similarity query vector document ask write program implement approach search_engine realize far clear right havent said lot things detail impossible actually write program thats said refined order actually suggest particular ranking_function implement framework actually hasnt set things required order implement define select basic concepts clearly assume concepts orthogonal example synonyms distinguished different concepts defining different dimensions clearly cause redundancy emphasizing matching match dimensions actually match semantic secondly exactly place documents query basically showed examples query document vectors exactly vector particular document point equivalent define term compute element values vectors important question term weight query vector indicates importance depending assign weights prefer terms similarly term weight document indicates term characterizes got wrong clearly dont represent document finally define similarity measure questions addressed operational function actually implement program solve problems main topic
lecture going talk instantiate vector_space model lecture going talk instantiate vector_space model specific ranking_function continue discussion vector_space model particular approach design ranking_function going talk use general framework vector_space model guidance instantiate framework derive specific ranking_function going cover simplest instantiation discussed previous_lecture vector_space model discussed previous_lecture vector_space model doesnt example shows define place document vector_space place query vector vector_space finally measure similarity query vector document imagine order implement model specifically compute vectors exactly xi exactly yi determine place document vector place query course need exactly similarity provide definition concepts define dimensions xis yis weights terms query document able place document vectors query vector defined space specify similarity function defined ranking_function lets think simplest actually suggest pause lecture point spend couple minutes suppose asked implement come idea vector_space figure compute exactly define similarity function couple minutes lets think simplest ways instantiating vector_space model define dimension obvious choice use word vocabulary define dimension n words vocabulary n_dimensions word defines dimension basically bag words lets look place vectors simplest strategy use bit vector represent query means element xi yi taking value means corresponding word present document zero going mean imagine user types words query query vector ones document vector general ones zeros vocabulary generally words dont occur words occasionally occur lot words absent particular placed documents query vector_space lets look measure commonly similarity measure dot_product dot_product vectors simply defined sum products corresponding_elements product x1 x2 y2 finally xn multiplied yn thats dot_product represent general way different ways measuring defined dimensions defined vectors defined similarity function finally simplest vector_space based bit vector represntation dot_product similarity bag words formula looks formula thats actually particular retrieval function ranking_function right find implement function programming language rank documents point pause think interpret gone process modeling retrieval vector_space model assumptions place vectors vector_space define end weve_got specific retrieval function step think retrieval function actually makes expect function actually perform rank documents users queries worth value calculate end number number mean meaningful spend couple minutes course general question believe good ranking_function actually work think interpret actually meaningful mean related document matches order assess simplest vector_space model actually works lets look sample documents simple query news presidential_campaign 5 cover different terms look documents moment realize documents probably relevant probably non_relevant ask rank documents rank basically ideal ranking humans examine documents try think moment look slide pausing think agree d4 d3 probably better cover match news presidential_campaign looks like documents probably better d2 d1 d5 non_relevant d4 d3 relevant_documents d1 d2 d5 non_relevant lets simplest vector_space model lets think actually use model score right 2 documents d1 d3 vectors space_model course want 1st compute vectors documents vocabulary n_dimensions think vector representation query note assuming use zero indicate term absent present query document 01_bit think query vector query words words rest documents t1 words ones rest lets compute going use dot_product use dot_product multiply corresponding_elements forming forming product generate product generate product actually dont zero product sum pairs zero entries long 1 zero product effect counting pairs case seen mean means number value scoring_function simply count unique query terms matched document term matched document 2 0 similarly document term term query zero query vector dont result scoring_function basically matches unique query terms matched interpret look case result 3 d3 matched distinct query words news presidential_campaign d1 case reasonable rank d3 d1 simplest vector_space model looks pretty examine model detail likely find im going scores easily verify correct basically counting number unique query terms matched note matching actually makes sense right basically means document matches unique query terms document assumed relevant problem notice documents d2 d3 d4 tied 3 thats problem look carefully d4 ranked d3 d3 mentioned presidential d4 mentioned multiple_times case d3 presidential extended d4 clearly presidential_campaign problem d2 d3 look words matched case d2 matched news case d3 matched news presidential_campaign intuitively d3 better matching presidential important matching presidential intuitively like d3 ranked model means model solve summarize lecture talked instantiate vector_space need define second decide place documents vectors vector_space place query vector_space 3rd define similarity vectors particularly query vector document talk simple way instantiate vector_space thats probably simplest vector_space model case use word define user 01_bit vector represent document case basically care word presence ignore use dot_product similarity instantiation showed scoring_function basically score document based number distinct query words matched simple vector_space model doesnt work need topic going cover
lecture going talk improve instantiation vector_space continued_discussion vector_space going focus improve instantiation previous_lecture seen simple instantiations vector_space come simple scoring_function basically count unique query terms matching seen function shown slide particular look documents score matched 3 unique query intuitively like d4 ranked d3 d2 non_relevant problem function following heuristics like credit d4 matched presidential times second intuitively matching presidential important matching common word doesnt carry natural lets improve model solve worth thinking point pro problems look assumptions instantiating vector_space model realize problem coming particular place vectors vector_space naturally order fix problems revisit use different ways instantiate vector_space particular place vectors different lets natural thought order consider multiple_times term document consider term_frequency instead absence order consider difference document aquarium occurred multiple_times query term occurs consider term_frequency count term simplest model model presence absence ignore actual number times term occurs lets add represent document vector term_frequency elements queries vector document vector 0 1s instead counts word query bring additional information seen accurate representation lets formula look like change slide use dot_product formula looks similar fact looks identical inside sum course xi yi different counts word query point suggest pause lecture moment think interpret score new similar simplest change vector new score different difference consideration multiple occurrences term important like know fix problems simplest vector_space lets look suppose change vector representation term_frequency lets look query vector words occur exactly query vector 001 fact d2 essentially representing way words repeated times result score goes d4 presidential occured element presidential document factor 2 instead result score d4 means term_frequency rank d4 d2 d3 solved problem d2 d3 treated identical scores fix fix problem intuitively like credit matching presidential matching solve problem general way way determine word treated importantly word basically ignored word care content essentially ignore word stop generally frequently occur matching doesnt mean capture encourage think little come statistical approaches distinguish presidential think moment realize differences words like count occurrence word collection higher frequency presidential tends occur idea suggest use global statistics terms information try weight element vector representation time hope increase weight presidential expect d2 overall score d3 score 3 able rank lead systematically rely statistical counts case particular idea called inverse_document seen document frequency signal modern retrieval_functions discussed previous_lecture heres specific document frequency count documents contain particular said inverse_document frequency actually want reward word doesnt_occur way incorporate vector representation modify frequency multiplying idea corresponding word penalize common words generally low idf reward rare words high specifically idf defined logarithm m 1 k m total_number documents collection k df document frequency total_number documents containing word plot function varying k curve look general higher value low df word rare maximum value function log m interesting think whats minimum value function interesting specific function important heuristic simply penalize popular turns particular function form better form function open research question clear use linear panelization like whats shown line reasonable standard particular standard idf turning point gonna terms essentially essentially ignored makes sense term occurs frequently lets term occurs 50 documents term unlikely important basically common important match word standard idea basically assuming lower theres look linear panelization point intuitively want focus discrimination low df words common course works_better validated empirical created dataset use users judge results lets solve problem alright lets look idf_weighting term_frequency vectors idf_weighting adjust tf weight multiplying idf example adjustment particular adjustment idf value smaller idf value look idf distinguishing words result adjustment larger weight score new vectors happen course share weights news matching presidential result idf_weighting d3 ranked d2 becauses matched rare word d2 matched common shows idf_weighting solve problem effective model general use tf_idf weighting lets look obvious documents seen new scores new documents effective new weighting method new scoring_function lets overall effective new ranking_function tf_idf weighting documents seen scores 4 documents new d5 high score simplest vector_space model actually high fact highest_score creates new actually common phenomenon designing retrieval_functions basically try fix problem tend introduce problems thats tricky design_effective ranking_function whats best ranking_function open research questions researchers working lectures gonna_talk additional ideas improve model try fix summarize lecture weve talked improve vector_space model weve_got improve instantiation vector_space model based tf_idf improvement placement vector higher weight term occured times document infrequently seen improvement model works_better simplest vector_space lecture going look address additional
lecture continue discussion vector_space particular going talk tf previous_lecture derived tf_idf weighting formula vector_space shown model actually works pretty examples shown slide d5 received high received highest_score documents document intuitively non_relevant lecture gonna_talk use tf transformation solve discuss details lets look formula simple tf_idf weighting ranking_function document received high formula look formula carefully involves sum matched query inside sum matching query term particular weight way tf_idf idea component total_number documents document number documents contain word variables involved formula included count query term w query count word look document hard realize reason hasnt received highest_score cause high count count campaign document higher documents contributed high score intuitively order lower score document need restrict contribution matching term think matching terms document carefully actually probably shouldnt reward multiple mean occurrence term says lot matching term goes zero count count 1 increase means word document likely document talking extra occurrence 2nd kind confirmed accidental matching sure document talking imagine seen lets 50 times word adding extra occurrence good tell evidence cause sure document think way restrict contribution high count idea tf transformation function going turn raw_count word term_frequency wait word x axis raw_count y axis showed term_frequency previous ranking functions actually implicitly kind example 01_bit vector representation actually use researcher transformation function basically count 0 zero weight weight term count tf wait thats linear function right exactly way seen want example logarithm function sub_linear transformation looks like control influence high weight going lower inference retain inference small want bend curve applying logarithm people tried methods working better linear form far works best special transformation called bm25 bm stands best transformation theres parameter k controls upper_bound easy function upper_bound look x x k k non negative number numerator able exceed denominator right upper bounded k_1 difference transformation function logarithm transformation doesnt upper_bound furthermore 1 interesting property function vary k actually simulate different transformation functions including extremes ive_shown 01_bit transformation linear example set k 0 function value precisely recover 01_bit set k large number hand going look like linear transformation sense transformation allows control shape nice block upper_bound upper_bound useful control influence particular prevent spammer increasing count term spam queries match words upper_bound ensure terms counted aggregate weights computer said transformation function worked summarize main point need linear tv tf transformation needed capture intuition diminishing return higher term avoid dominance single bm25 transformation talked far best performing tf transformation upper_bound social robust plug function tf_idf weighting vector_space end having following ranking_function bm_25 tf close state art ranking_function called bm_25 discuss improve formula
lecture document_length vector_space lecture going continue discussion vector_space particular going discuss issue document_length far lectures vector_space model signals document assess matching document particular considered term_frequency count term considered global idf inverse_document considered document_length 2 example d4 shorter 100 d6 hand 5000 look matching query words d6 matchings query reason d6 matched query words scattered maybe topic d6 topic discussion campaign beginning document mention presidential general think long documents higher chance match query generate long document randomly simply sampling distribution words eventually probably match sense penalize_long documents naturally better chances matching idea document_length need careful avoiding penalize_long hand want penalize_long document hand dont want reason document long different case document long uses think text article research use words corresponding case probably penalize long documents compare matching words long document matching words short long papers generally higher chance matching query case document long document simply consider case long document simply concatenated lot abstracts different case obviously dont want penalize_long probably dont want penalize document thats need right degree method working based research results called pivotal length_normalization case idea use average document_length pivot reference means assume average length documents score right normalizer document longer average document_length penalization shorter theres illustrated axis xaxis length y axis normalizer case pivoted_length normalization formula interpolation 1 normalized document_length controlled parameter divide length document average document_length gives sense document compared average document_length benefits worrying length measure length words normalizer interesting set parameter b 0 value theres b sense controls length_normalization set b nonzero value normalizer look like value higher documents longer average document_length value normalizer smaller shorter sense panelization long reward short degree penalization controlled b set b larger value normalizer look like theres penalization long documents reward short adjusting b varies zero control degree length_normalization plug length_normalization factor vector_space model ranking functions end having following fact state art vector_space model lets called pivoted_length normalization vector_space reference end details derivation model basically tf_idf weighting model idea component query term_frequency middle normalized case double discussed achieve sub_linear document_length right cause penalization long document larger denominator smaller tf course controlled parameter b set zero length_normalization ok effective vector_space model called bm25 similar idf query tf middle normalization little bit okapi tf sublinear_transformation upper_bound case length_normalization factor adjusting k achieves similar factor normalizer document longer term weight model gone analysis end reached basically state art retrieval_functions far talked mainly place document vector vector_space played important_role determining effectiveness retrieval dimensions examine example improve instantiation dimension vector_space model weve assumed bag words representation dimension obviously consider example stemmed words transformed root computation computing stop word remove common words dont carry content use phrases define use latent semantic_analysis find clusters words represent latent concept use smaller units like character sequences n characters practice people found bag words representation phrases effective far popular dimension instantiation major search mention need languagespecific domainspecific tokenization actually important variations prevent matching mean thing languages like chinese challenge segmenting text obtain word boundaries sequence word correspond 1 character characters 3 easier english space separate words languages need natural_language processing figure boundaries possibility improve similarity function far dot_product imagine example measure cosine angle vectors use euclidean distance dot_product best reason fact sufficiently consider possibilities weighting different example cosine measure regarded dot_product normalized means normalize vector dot_product equivalent cosine mentioned bm_25 effective development improving 25 works changed bm25 line work people derived f stands field use bm25 documents example consider title field abstract body research article anchor_text web pages text fields describe links pages combined appropriate weights different fields help improve_scoring use bm25 obvious choice apply bm25 field combine basically idea bm25f combine frequency counts terms apply bm_25 advantage avoiding counting occurrence remember sub_linear transformation tf occurrence important contributes large weight fields term gained lot advantage combine word frequencies time time extra occurrences counted fresh method working scoring structure line extension called pm 25 line researchers addressed problem penalization long documents bm_25 address problem fix actually simply add small constant tf normalization formula whats_interesting analytically prove small fix problem penalization long documents original bm25 new formula called empirically analytically shown better summarize said vector_space major takeaway model use similarity notion relevance assuming relevance document respect basically proportional similarity query document naturally implies query document represented way case represent vectors high dimensional vector_space dimensions defined words concepts terms generally need use lot heuristics design ranking_function examples need heuristics including tf weighting idf_weighting document_length major heuristics important heuristics ensure general ranking_function work kinds finally bm25 pivoted normalization effective formulas vector_space ive bm_25 category vector_space fact bm_25 derived probabilistic reason ive vector_space ranking_function actually nice interpretation vector_space model easily looks like vector_space model special weighting second reason original bm25 somewhat different form form idf actually doesnt work standard seen effective retrieval function bm25 probably use heuristic modification idf look like vector_space additional_readings paper pivoted_length excellent example empirical data analysis suggest need length_normalization derived length_normalization second original paper bm25 3rd paper thorough discussion bm25 particularly finally paper discussion improving bm25 correct penalization long
lecture implementation text retrieval lecture discuss implement text retrieval method build search_engine main challenge manage lot text data enable query answered quickly respond typical text retrieval system documents processor tokenizer tokenized units example words words tokens processed indexer create index data structure search_engine use quickly answer query going similar process step tokenizer applied query text processed way units queries representation given scorer use index quickly answer users query scoring documents results given user user look results provide feedback expressed judgments documents good documents bad implicit_feedback click slows user doesnt extra user look results skip click results interaction signals system improve ranking accuracy assuming view documents better skiped search_engine system divided 3 indexer second scorer responds users query feedback typically indexer offline manner preprocess collected data build inverted_index introduce data structure online module scorer process users query dynamically quickly generate search feedback mechanism online offline depending implementation indexer scorer fairly standard main topic lectures feedback mechanism hand variations depends usually algorithm specific lets talk tokenization normalize lexical units form semantically similar words language like stemming map inflectional forms words root example computer computation computing matched root form way different forms computing normally good idea increase coverage documents matched query beneficial subtle difference computer computation suggest difference coverage content cases stemming tokenize text languages example chinese face special challenges segmenting text find word boundaries obvious boundary theres space course use language specific natural_language processing_techniques tokenization index text documents convert documents data structure enable fast_search basic_idea precompute commonly indexes called inverted_index search engines support basically search algorithms indices example document index needed order support like said kind techniques standard vary lot according feedback understand want use inverted_index useful think respond single term query want use time think pause think preprocess text data quickly respond query word thought question realize best simply create list documents match term way basically pre construct term simply fetch ranked_list documents term return list thats fastest way respond single term idea inverted indexes actually basically like going pre construct index allow quickly find documents match particular lets look documents documents seen previous suppose want create inverted_index maintain dictionary dictionary entry term going store basic statistics example number documents match term total_number frequency term means count duplicated occurrences example term ocurred count documents realize need count documents document frequency computing statistics vector_space think weighting heuristic need count thats idf right inverse_document idf property turn compute document account easy compute idf time build index running time addition basic statistics store documents match news entries stored file called case matched documents store information document id document frequency 1 tf 1 second document 1 list documents match term news know frequency news query word news easily look table find entry quickly postings fetch documents match lets look time lets look word word occured document document document occurred twice document frequency count 2 frequency count useful retrieval method use frequency assess popularity term collection similarly pointer case entry term occured document document id 3 occured basic_idea inverted_index actually pretty simple right structure easily fetch documents match term basis scoring documents want store positions cases term occured document theres example case time occurred twice store position information useful checking matching query terms actually small window lets 5 words 10 words matching query terms fact phrase checked quickly position inverted_index good fast_search talked possibility answer single word thats multiple term queries lets look special_cases boolean boolean query basically boolean expression want relevant document match term term b right thats conjunctive query want relevant_documents match term term thats disjunctive answer query inverted_index think bit obvious cause simply fetch documents match term fetch documents match term b intersection answer query aampb union answer query easy going multi term keyword query talked vector_space model example match query document generated score score based aggregated term case boolean scoring acted similar basically similar disjunctive boolean basically like union documents match query term aggregate term basic_idea inverted_index scoring documents general going talk detail later lets look question inverted_index good basically efficient sequentially scanning documents like obvious compute score document sorry straight forward method going imagine web lot long time answer question inverted_index faster word distribution heres common phenomenon word distribution language independent patterns patterns basically characterized following pattern words like common words occur frequently account large percent occurrences words occur words occur lets document true frequently words corpus means general phenomenon applicable observed cases exact words common vary context phenomenon characterized whats called zipfs law says rank word multiplied frequency word roughly formally use fw denote frequency rw denote rank word basically says thing mathematical term basically constant right parameter alpha adjusted better fit empirical plot word frequencies sorted order x axis basically world rank rw y axis word frequency curve basically shows product roughly look words separated middle intermediate frequency words tend occur documents like frequent words theyre tend queries tend high tf_idf weights intermediate frequency look left highest frequency words occur usually stop words like words fact frequent discriminated generally useful removed called stop words removal use pretty count words collection kind infer words stop basically highest frequency words occupy lot space inverted_index imagine posting entries word long remove words save lot space inverted_index tail lot rare words dont occur frequently words actually useful user happens interested topic theyre true users unnecessary interested words retain allow match document accurately generally high kind data structures use store inverted_index parts right recall dictionary dictionary modest size web going large compared postings need fast random access entries cause want look query term prefer dictionary memory possible collection large feasible collection large general possible vocabulary size obviously cant general thats goal data structures use storing dictionary directly accessed data structures like hash table btree cant store memory use try build structure allow quickly look postings theyre general dont direct access specific entry look sequence document ids frequencies documents match query term read entries large generally store postings disk stay contain information document ids term frequencies term positions large compression save disk space course benefit going occupy help improving know input output cost lot time comparison time taken cpu cpu io takes time compressing inverted_index posting files smaller entries read memory process query time smaller reduce trafficing io save lot course processing data uncompress data said cpu fast overall save compression save disk space speed loading inverted_index
lecture inverted_index lecture continue discussion system particular going discuss construct inverted_index construction inverted_index actually easy data set small easy construct dictionary store postings problem data able fit memory use special methods unfortunately retrieval applications data set large generally loaded approaches solve problem sorting based method works steps collect local term id document id frequency basically count terms small set collect counts sort counts based terms build local partial inverted_index called write temporary file disk merge step pairwise merging runs eventually merge runs generate single inverted_index illustration left right shown term lexicon documentid lexicons map streambased representations document ids terms integer representations map integers stream reason interested integers represent ids integers easier example integers index easy reason tend map strings dont carry approach work going scan documents sequentially parse document count frequencies stage generally sort frequencies document ids process document encounter terms document ids 1s followed document ids naturally sorted order process data sequential order point run memory write sort use sort time going sort based term notice term ids key entries share term case ids documents match term going write disk temporary file allow use memory process batch going going write lot temporary files stage merge going merge eventually single inverted_index entries sorted based term old entries documents match term basically construction inverted_index data loaded mentioned earlier postings large desirable lets talk little bit compress inverted_index idea compression general leverage skewed distributions values generally use variable length encoding instead fixed length encoding use default program languages like leverage skewed distributions values compress values general use fewer bits encode frequently awards cost longer bits encode rare case lets think compress tf term_frequency picture inverted_index look like postings lot term frequencies terms think kind values frequent probably able guess small_numbers tend occur far frequently large think distribution words zipfs law words occur lot small_numbers use fewer bits small highly frequent integers cost bits large trade values distributed uniformly save lot tend small values save average large number use lot document ids saw postings distributed skewed way deal turns use trick called dgap restore difference term imagine term matched documents long list document gap im going difference adjacent document gaps small lot small_numbers term according documents gap large numbers creates skewed distribution allow compress possible order uncover uncompress document sequential process store difference order recover exact document id 1st recover previous document ids add difference previous document id restore current document possible need sequential access documents look term fetch document ids match sequentially thats trick different methods example binary code commonly code programming languages use basically fixed length unary_code gamma_code delta code possibilities lets look binary coding equal length encoding thats property randomly distributed unary coding variable length encoding case integer thats encoded x1 bits followed example encoded ones followed zero encoded 4 ones followed zero imagine bits use large number like bits use exactly number like 100 exactly use 100 bits right number bits value number likely large numbers imagine occasionally number like use 1000 bits works absolutely sure large numbers small_numbers decode code variable length encoding methods cant count bits 8 bits 32 bits start variable lengths youll rely case unary easy easily zero signal end count ones seen hit zero finished start saw unary coding aggressive rewarding small_numbers occasionally big aggressive method gamma method going use unary coding transformed form value plus floor log magnitude value lower original thats afford unary_code unary_code log followed uniform_code binary code basically uniform_code binary code going use code code remaining value basically precise x 1 floor log unary_code basically coded floor log x remaining uniform_code actually code difference x log easy value difference need use bits floor log x easy understand difference large higher floor log example 3 encoded 2 digits unary_code value 10 encodes 2 unary means log x floor log x 1 want actually use unary_code encode plus floor log 2 know floor log x larger difference 1 encoded thats 101 similarly 5 encoded 110 followed 01 case unary_code encodes unary_code floor log x means going compute difference 5 2 thats time going use 2 bits cause level floor log x numbers 5 6 7 share prefix order differentiate use 2 bits end imagine 10 end instead 01 true form gamma_code odd number bits center thats end unary_code left zero ones right zero binary coding uniform decode code unary coding right hit zero got unary_code tell bits read decode uniform_code decode gamma_code error code thats basically gamma_code replace unary prefix gamma_code thats conservative gamma_code terms rewarding small means ok occasionally large ok delta fine gamma_code big loss unary_code operating course different degrees favoring small appropriate certain distribution perfect method_works best depend actual distribution data inverted_index compression people found gamma coding uncompressed invert index talked decode encode integers think discussed decode unary coding gamma wont document ids compressed going sequential suppose encoded id list x1 x2 x3 decode x1 obtain document id decode x2 actually difference second add decoder value x2 id1 recover value id second position advantage converting document ids integers allows kind compression repeat decode documents time use document id previous position help recover document id
lecture fast_search inverted_index lecture going continue discussion system particular going talk support fast_search inverted_index lets think general scoring_function look course vector_space model special case imagine retrieval_functions form function scoring_function document d query q defined function thats adjustment function consider factors shown end f sub d d f sub q adjustment factors document query level document inside function theres function called main scoring_function said scoring factors level document example document aggregate functioning inside edge function functions compute weights contribution matched query term function g gives weight match query term ti document h function aggregate weights example sum matched query product way finally adjustment function consider document level query level factors adjust example documents general form cover state art retrieval_functions lets look score documents function inverted_index heres general algorithm works query level document level factors precomputed indexing course query computed query time document example document lengths maintain score_accumulator document d compute h aggregation function matched query query term going fetch inverted list inverted_index documents match query includes d1 f1 dn pair document id frequency term entry dj fj particular match term particular document going compute function like tf weights compute weighted contribution matching query term going update score_accumulator allow add accumulator incrementally compute function basically general way allow computer functions form inverted_index note dont touch document didnt match query need process document matched query end going adjust score compute function fa lets look specific case lets assume scoring_function simple takes sum raw count term simplification help showing algorithm clearly easy extend computation include weights like transformation tf document_length normalization idf_weighting lets look specific example queries information entries inverted_index right information occurred documents security occurred lets algorithm iterate query fetch query thats imagine score accumulators store scores imagine allocated allocated weighting terms dont need score_accumulator conceptually score accumulators eventually lets fetch entries inverted list score accumulators obviously initialized answer d1 3 occurrences information scoring_function assumes score sum raw counts need add 3 score_accumulator account increase score matching term information document thats d2 4 added 4 score_accumulator course point allocated score_accumulator point allocated d1 d3 add allocate score cumulative d3 add finding d4 gets 5 term information occurred times ok completes processing entries inverted_index processed contributions matching information algorithm query term going fetch inverted_index entries case entries d2 3 means security occurs times exactly information time going change score_accumulator d2 add 3 existing value 7 d2 score increased matched information thats d4 1 update score d4 add 1 d4 goes 5 finally process d5 allocated score_accumulator point going allocate 1 d5 going add 3 scores row final scores documents scoring_function simple sum tf actually like length_normalization normalization point summarize processed query term processed entries inverted_index processed worth thinking order consider query difference especially dont want score lets want promising score think good process common term process rare_term answer process rare_term rare_term match fewer documents score contribution higher idea value allows touch promising documents helps pruning non promising ones dont need documents returned right heuristics improving incorporate idf_weighting easily incorporated process query fetch inverted_index fetch document frequency compute maybe idf value index documents time computed idf value time mean process entries information weights adjusted idf idf basic_idea inverted_index faster search works kinds formulas general general form covers actually state art retrieval_functions tricks improve general techniques include store results popular queries time query simply return stored similarly store list inverted_index memory popular term query terms popular likely soon need fetch inverted_index keeping memory help general techniques improving promising accumulators user generally doesnt want examine need return high quality subset documents likely purpose prune dont store point highest value technique parallel_processing thats needed processing large data set like web data set scale web scale need special special techniques parallel_processing distribute storage files multiple heres list text retrieval tool kits complete find information lucene popular toolkits support lot applications nice support use build search_engine application downside easy extend algorithms implemented advanced_algorithms lemurindri tool_kit nice support application lucene advanced search easy terrier tool_kit good support application capability advanced_algorithms thats maybe lemur lucene maybe combining strength thats useful tool_kit meta tool_kit use programming assignment new tool_kit combination text retrieval algorithms text mining topic models number text analysis algorithms implemented toolkit basic search summarize discussion system implementation major takeaway inverted_index primary data structure supporting search_engine thats key enable faster response users basic_idea preprocess data want compression appropriate save disk space speed io processing inverted_index general talked construct inverted_index data cant fit memory talk fast_search inverted_index basically exploit inverted_index accumulate scores documents matching query explore zipfs law avoid attaching documents dont match query algorithm support wide range ranking basic techniques great potential scaling distributed file_system parallel_processing additional_readings look time youre interested classic textbook efficiency inverted_index compression techniques general build efficient search_engine terms space overhead second newer textbook nice discussion implementing evaluating search
lecture evaluation text retrieval previous lectures talked number text retrieval methods different kinds ranking know works best order answer question compare means evaluate retrieval main topic lets think evaluation reason use evaluation figure retrieval method_works important advancing knowledge wouldnt know new idea works_better old beginning course talked problem text compared database mentioned text retrieval empirically_defined evaluation rely system works_better judged users challenging users involved evaluation fair comparison different methods reasons listed second reason basically said reason assess actual utility text retrieval imagine youre building search_engine interested knowing search_engine works case matches reflect utility actual users real typically user studies real search_engine second case second measures actually correlated utility actual dont accurately reflect exact utility measure needs good tell method_works usually test_collection main_idea talking important comparing different algorithms improving search_engine system talk measure right aspects search_engine measure listed major effectiveness accurate search case measuring systems capability ranking relevant_documents non random second quickly user results computing resources needed answer query case need measure space time overhead aspect basically question useful system real user obviously interfaces things important typically user course going talk effectiveness accuracy measures efficiency usability dimensions unique search needed evaluating software systems good coverage materials evaluate search engines quality accuracy unique text retrieval going talk main_idea people proposed test set evaluate text retrieval algorithm called cranfield_evaluation actually developed long time ago developed methodology laboratory system components actually methodology useful search_engine evaluation evaluating virtually kinds empirical example natural_language processing fields problem empirically_defined typically need use today big data challenge use machine_learning methodology popular developed search_engine application basic_idea approach build reusable test collections define test_collection test different algorithms going define measures allow quantify performance system exactly work going sample collection documents simulate real document collection search sample set queries simulate users relevance_judgments judgments documents returned ideally users formulated queries cause people know exactly documents useful finally measures quantify systems result matches ideal ranked_list constructed based users relevance_judgments methodology useful starting retrieval algorithms tested connection reused times provide fair comparison criteria data set compare different allows compare new algorithm older algorithm developed years ago illustration said need queries q1q2 need documents thats called document collection right need relevance_judgments binary judgments documents respect example d1 judged relevant q1 d2 judged d3 judged non_relevant q1 created basically text collection systems want compare run system queries documents system return lets query q1 r_sub results remember task computing approximation relevant document set r_sub system r_sub b system bs approximation relevant_documents lets look better imagine user like lets look differences documents returned look results feel maybe better sense dont non_relevant documents documents returned relevant thats good hand maybe b better weve_got relevant_documents weve_got 3 better quantify obviously question highly depends users task depends able imagine users system user interested getting relevant case user doesnt read user relevant_documents hand imagine user need relevant_documents example literature survey segment category find system_b case define measures need define multiple users different perspectives looking
lecture basic measures evaluation text retrieval lecture going discuss design basic quantitatively compared retrieval slide seen_earlier lecture cranfield_evaluation test_collection consists queries documents relevance_judgments run systems datasets quantitatively evaluate raised question set results system better system_b better lets talk actually quantify suppose total 10 relevant_documents collection relevance_judgments shown include obviously seen relevant_documents imagine relevant_documents judge intuitively thought system better noise particular seen results system_b 5 results intuitively looks like system accurate intuition captured measure called precision simply compute extent retrieval results relevant 100 precision mean retrieval documents case system precision system_b 3 shows system better talked system_b preferred users like retrieve relevant_documents case compare number relevant_documents retrieve measure called measures completeness coverage relevant_documents result assume 10 relevant_documents weve_got system record 2 10 system_b 3 recall system_b better measures turn basic measures evaluating search engines important task evaluation problems example look applications machine_learning tend precision_recall numbers reported kinds ok lets define measures precisely measures evaluate set retrieval means considering approximation set relevant_documents distinguish 4 cases depending situation document retrieved retrieved right talking set document relevant non_relevant depending user thinks useful counts documents represent number documents retrieved b documents retrieved relevant table define relevant retrieved documents total_number retrieval documents divided sum sum similarly recall defined dividing sum aampb thats divide sum rule instead right precision_recall focused thats number retrieval relevant_documents going use different ok ideal result easily ideal case precision_recall 0 means got 1 relevant_documents results results return theres single nonrelevant document reality high record tends associated low imagine thats case list try relevant_documents possible tend encounter lot non_relevant documents note set defined cut ranked_list thats measures defined set retrieval documents actually useful evaluating ranked_list fundamental measures text retrieval interested precision 10 documents web_search means look documents 10 results actually meaningful measure tells relevant_documents user expect page search results typically 10 precision_recall basic measures need use evaluate search_engine building said tends tradeoff precision_recall naturally interesting heres measure thats called f_measure harmonic mean precision_recall defined inverse r p interpret depending parameter transformation easily case combination precision_recall beta parameter thats control emphasis precision_recall set beta end having special case f_measure called popular measure thats little combine precision_recall formula looks easy larger precision larger recall f_measure whats_interesting tradeoff precision_recall captured interesting way order understand look natural question combine simple arithmetic_mean shown likely natural way think want think pause good f1 whats think arithmetic_mean sum multiple case sum precision_recall case sum total value tends dominated large means high p high r dont care value low sum desirable easily perfect perfect recall imagine probably easy imagine simply retrieve document perfect point results clearly useful users average formula relatively contrast f1 reward case precision_recall roughly similar penalize case extremely high means f1 encodes example shows actually important try solve naturally think 1 solution lets case arithmetic_mean important settle important think ways think multiple variants important analyze think makes sense think carefully feel f1 probably makes sense simple arithmetic_mean cases different results case arithmetic_mean dont pay attention subtle_differences easy way combine later find doesnt methodology actually important general solving problem try think best try understand problem know need measure need combine precision_recall use guide finding good way solve summarize talked addresses retrieval results talked addresses question relevant_documents basic measures text retrieval useful talked f_measure way combine precision_recall talked tradeoff precision_recall turns depend users search tasks discuss point later
lecture evaluate ranked_list lecture continue discussion particular going look evaluate ranked_list previous_lecture precision_recall basic measures quantitatively measuring performance search talked ranking framed tax retrieval problem ranking need evaluate quality ranked_list use precision_recall evaluate ranked_list naturally look precision_recall different cut offs end approximation relevant_documents set given ranked_list determined user_stops browsing right assume user sequentially browses list results user stop point point determine set thats important cut consider compute precision_recall knowing exactly user stop consider positions user lets look look slide lets look user_stops document whats precision_recall point think easy document relevant got document thats recall note assume 10 relevant_documents query collection user_stops second position precision 100 record 2 user_stops position interesting case got additional relevant recall doesnt precision lower weve_got random exactly precision right recall 2 point recall different look list wont happen seen relevant case point recall increased d8 documents relevant recall recall 10 list dont convenience assume precision precision zero levels recall search course pessimistic actual precision higher assumption order easy way compute measure called average_precision discuss assumptions clearly usually ok purpose comparing text retrieval methods relative comparison ok actual measure actually actual number deviates little bit true number soon deviation biased particular retrieval method ok accurately tell method_works better important point compare different algorithms keys avoid bias method long avoid ok transformation measures preserve ok talked lot precision_recall numbers different positions imagine plot curve shows x axis y axis precision levels marked 1 2 3 different levels y axis different amounts plotted precision_recall numbers got points link points form curve assumed precision start high level records 0 thats right actual curve probably like discussed doesnt matter comparing cause underestimate ok precision_recall curve compare 2 ranked lists right means compare pr 2 cases system shown red system_b showing blue alright better hope system clearly level recall level recall precision point system better system_b theres imagine curve look like ideal search perfect precision_recall points ideal higher curve better right problem case like actually happens like case better think real problem actually suppose build search_engine old algorithm thats shown blue system_b come new idea test results shown red question new method better older method practically replace algorithm search_engine new algorithm use system method replace method b going real replacement search_engine behave like system dont like system_b want spend time think pause video useful said real decision building search_engine youre working company cares thought moment realize case users like system users like system_b whats difference difference low level recall region system_b better theres higher precision high recall reading system means depends user cares high recall low recall high imagine going check whats happening today want find random better think case clearly system_b better user unlikely examining lot user doesnt care high hand think case user literature survey youre starting want find idea case emphasize high recall want relevant_documents favor means better actually depends users precisely users means necessarily able come number accurately depict look overall picture said practical decision replace algorithm actually come single number quantify compare different methods research ideally number compare easily lot reasons desirable single number needs number summarize precision_recall curve way summarize ranked_list curve look area underneath right way measure ways measure turns particular way measuring popular long time ago text retrieval basically computed way called average_precision basically going look different recall look precision different dont count recall look number thats precision different recall level provisions different points corresponding retrieving relevant 2nd fourth missed mini random cases assumed zero finally divided 10 total_number relevant_documents note dividing sum 4 number retrieved relevant_documents imagine divide 4 happen think common mistake people divide 4 actually fact favoring system retrieve documents case denominator small good note dinominator total_number relevant_documents basically compute area underneath standard method evaluating ranked_list note actually combines recall precision precision second consider recall miss combines precision_recall furthermore measure sensitive small change position relevant lets relevant document little bit increase average_precision relevant document lets random document decrease average_precision good sensitive ranking relevant tell small differences 2 ranked lists thats algorithm works slightly better want contrast look precision 10 look whats precision think thats 10 right precision meaningful tells thats pretty useful right meaningful measure users_perspective use measure compare systems wouldnt good wouldnt sensitive relevant_documents precision right good measure comparing different contrast average_precision better tell difference different difference ranked lists subtle
average_precision computed generally experiment different queries avoid variance depending queries use different conclusions better use use queries average average_precision naturally think arithmetic_mean tend think called mean average_precision case arithmetic_mean average precisions set queries mentioned lecture good recall talked different ways combining precision_recall conclude arithmetic_mean good f_measure think alternative ways aggregating dont automatically lets arithmetic_mean average_precision lets think whats best way think different ways naturally probably able think way geometric_mean called kind average gmap think different ways thing natural question ask use map gmap thats important imagine testing new algorithms comparing old algorithm search_engine test multiple youve got average precisions thinking looking overall performance strategy use think question difference think scenarios difference different rankings means depending way average average average precisions different makes question use look difference different ways aggregating average position realize arithmetic_mean sum dominant large large menu value mean means query relatively high average_precision gmap tends affected lower values queries dont good average_precision think improving search_engine difficult queries gmap hand want improvement kinds queries particular popular queries easy want perfect maybe map answer depends users users tasks think multiple ways solve problem compare think carefully differences makes sense situation sense different situation important figure situations special case mean average_precision think case precisely relevant example whats called known item search know target lets want find amazon home page relevant document hope thats called known item case precisely relevant document application like question maybe theres answer rank answers goal ranked particular answer right case easily verify average_precision basically boil reciprocal_rank r r rank position single relevant document ranked r 1 reciprocal_rank ranked second 1 2 average average position reciprocal_rank set topics called mean reciprocal_rank popular value known item search ranking problem relevant r actually meaningful r basically indicating effort user order find relevant ranked effort little effort ranked 100 actually read presumably 100 documents order sense r meaningful measure reciprocal_rank reciprocal r instead r natural question simply r imagine design measure measure performance ranking system relevant thought r directly measures users effort right think average large number topics difference right single topic r overall wouldnt larger r correspond small overall difference think average mean reciprocal_rank versus average whats difference difference difference change order systems conclusion turns actually big difference think want think pause basically difference r directly dominated large values values basically large values indicate lowly ranked means relevant item ranked low list sum average dominated relevant_documents ranked lower portion ranked_list users_perspective care highly ranked taking transformation reciprocal_rank emphasize difference think big r think 100 101 wont difference use big 100 lets right hand wont difference case multiple choices thing need figure makes summarize precision_recall curve characterize overall accuracy ranked_list emphasized actual utility ranking list depends rankings results user actually users examine average_precision standard measure comparing ranking combines precision_recall sensitive rank relevant
lecture evaluate text retrieval system multiple levels lecture continue discussion going look evaluate text retrieval system multiple level far talked binary means document judged relevant non_relevant earlier talk relevance matter degree distinguishing high relative useful documents moderately relevant_documents ok non_relevant documents imagine ratings multiple levels example example levels 3 relevant sorry 3 relevant marginally relevant non_relevant evaluate search_engine system judgments obviously map doesnt average_precision doesnt precision_recall doesnt work rely binary lets look ranked results judgments right imagine user care 10 right marked reading levels relevance levels documents shown 32113 reason gain measure introducing called ndcgnormalized discounted cumulative_gain gain basically measure gain relevant information user obtain looking alright looking document user gain looking non random document user gain looking moderately relevant marginal relevant_documents user gain intuitively matches utility document users_perspective course assume user_stops 10 documents looking cut 10 look total game whats thats simply sum cumulative_gain user_stops position theres user looks document thats 3 user looks documents cumulative_gain course cost spending time examine cumulative_gain gives idea total gain user user examines ndcg letter d cumulative_gain want discounting look cumulative_gain deficiency consider rank position example looking know highly relevant document marginally relevant document non_relevant dont care ideally want ranked capture intuition means contribution gain different positions weighted position idea discounting going doesnt need discounted user assumed document second discounted little bit theres small possibility user wouldnt divide gain weight based position log rank position position discount normalizes log sum lower rank document contribute contribute highly ranked means example switch position lets position example relevant document imagine discounted idea ok point got discounted cumulative_gain measuring utility ranked_list multiple levels happy use rank need little bit order measure comfortable different way showed dcg right total sum overall 10 step called n normalization normalized idea going normalize dcg ideal_dcg ideal_dcg dcg ideal imagine 9 documents rated means total 9 documents rated ideal rank lister 3 followed thats best run positions right ideal ranked_list compute dcg ideal ranked_list given formula ideal_dcg normalizer ideal_dcg imagine normalization essentially compare actual dcg best dcg possibly want map dcg values range zero best value highest value thats ranked_list fact ideal general dont transformation normalization doesnt affect relative comparison systems topic ideal_dcg systems ranking systems based dcg exactly rank based normalized difference multiple dont normalization different topics different scales topic like 9 highly relevant_documents dcg high imagine case relevant_documents total highest dcg system achieve topic face problem different scales dcg values dont want average dominated high easy queries normalization avoid avoid problem making queries contribute equally idea useful measuring ranked_list based multiple level relevance_judgments general way basically measure applied rank task multiple level scale judgments binary multiple levels like 1 5 depending main_idea measure summarize measure total utility k choose cut measure total utility discount contribution lower ranked finally normalization ensure comparability
lecture practical issues address evaluation text retrieval lecture continue discussion evaluation cover practical issues solve actual evaluation text retrieval order create test_collection create set queries set documents set relevance_judgments turns actually challenging documents queries represent real queries real documents users handle use queries documents order avoid biased matching relevant_documents queries need ensure exists lot relevant_documents query lets document collection know informative compare different methods query theres room difference ideally relevant_documents collection queries represent real queries terms relevance_judgments challenge ensure complete judgments documents queries minimizing human_effort use human labor label documents labor intensive result impossible actually label documents queries especially considering giant dataset like actually major difficult measures challenging want measures accurately reflect perceived utility consider carefully users design measures measure measuring right thing conclusion going talk couple statistical_significance test reason use lot question sure observed difference doesnt simply result particular queries choose sample results average position system system_b different mean average_precision mean look mean average_precision mean average precisions exactly 4 system_b 2 4 look exact average precisions different look numbers detail realize case feel trust conclusion given case case feel im dont look numbers moment pause look average mean average_precision easily system_b better right 4 twice 2 thats better look look detail results confident case case numbers consistently better system_b experiment 2 sure looking results actually system better system look average system_b think know reliable conclusion look average case intuitively feel experiment quantitatively answer question need statistical_significance idea statistical_significance test basically assess variance different big variance means results fluctuate lot according different believe lot queries results change use set high variance lets look results second case right different ways signed test look system_b better system plus sign system better minus sign case seven actually 4 cases system_b better 3 cases system like random result right random sample flip 7 coins use plus denote head minus denote tail easily results randomly flipping 7 fact average larger doesnt tell reliably conclude quantitatively measured p value basically means probability result infected random case probability means surely random wilcoxon test nonparametric test looking science looking magnitude difference draw similar conclusion likely illustrate lets think distribution called null assume mean start assumption theres difference assume random fluctuations depending observe difference actual difference left right right curve kind shows probability actually observe values deviating look difference observed chance high fact random observation right define region know likely observation random fluctuation 95 outcomes interval observed values random observe value region difference difference unlikely random fluctuation right theres small probability observe difference random case conclude difference system_b idea statistical_significance takeaway message use queries avoid jumping conclusion case system_b different ways statistical_significance lets talk problem making said earlier hard judge documents completely small data question afford judging documents collection subset judge solution pulling strategy cases solve idea pulling choose diverse set ranking text retrieval hope methods help nominate likely relevant_documents goal figure relevant_documents want judgments relevant_documents useful documents users_perspective going return k k vary systems right point ask suggest likely relevant_documents simply combine k sets form pool documents human assessors imagine systems return k documents k documents formed course documents duplicated bcause systems retrieved relevamnt duplicate documents unique documents returned system idea having diverse set ranking methods ensure pool broad include possible relevant_documents human assistance completely judgment data set unjudged documents usually assumed non_relevant pool large assumption pool large actually reconsidered use strategies deal methods handle cases strategy generally ok comparing systems contributed means participated contributing pool unlikely penalize system ranked documents problematic evaluating new system contributed case new system penalized nominated relevant_documents judged documents assumed non_relevant thats summarize text retrieval evaluation extremely important problem empirically_defined dont rely users theres way tell method_works inappropriate experiment design misguide research applications draw wrong seen discussion sure right research main methodology cranfield_evaluation methodology main paradigm kinds empirical evaluation tasks search_engine map ndcg main measures definitely know appropriate comparing ranking research_papers proceeding 10 documents easier interpret users_perspective thats whats covered evaluation strategy like ab test system mix 2 results methods randomly mixed results course users dont result method users judge results click documents search_engine case search_engine track clicked documents method clicked documents user tends click results method method better leverage real users search_engine called ab test strategy thats modern_search commercial search way evaluate ir text retrieval user studies havent ive references look want additional_readings mini books evaluation excellent covering broad review information retrieval evaluation discovered things lot
lecture probabilistic retrieval lecture going continue discussion tax retrieval look kind different way design ranking functions vector_space model probabilistic_models define ranking_function based probability document relevant words introduce binary random_variable variable assume query documents observations random note vector_space model assume vectors assume data observed random problem retrieval probability category models different classical problem model led bm_25 retrieval function discussed vector_space form actually similar objectives space_model lecture discuss big called language modeling approaches particular going discuss query likelihood retrieval effective models probabilistic_models line called divergent randomness model pl2 effective state travel inquiry likelihood assumption probability relevance approximated probability query given document intuitively captures following probability user likes document likely user enter query q order retrieve documenting assume user likes relevance value asked question likely particular query basic_idea understand idea lets look general idea basic_idea probabilistic retrieval imagine relevance status values relevance_judgments queries example line shows query user tightly d1 document user seen means user thinks relevant r approximated click data search_engine collect watching interact search case lets user clicked document user clicked d2 words d2 assumed relevant hand d3 non_relevant theres voice relevant d5 maybe data collected different user typing q1 found d1 actually divine actually non_relevant contrast query user different d2 relevant et queries imagine lot ask question estimate probability relevance right compute probability relevance intuitively means look entries particular d particular q likely column basically means collect count times seen qampd table count times actually seen compute lets look specific suppose trying compute probability d1d2 d3 estimated probability pause video try look try estimate seen interested q1 d1 looking pairs actually user said relevant r equal 1 case d1 case r equal approach actually score documents query right score d1d2 query simply rank based probabilities thats basic_idea probabilistic retrieval model makes lot case going rank d2 documents cases seen d1 eyes equals user clicked lot click data search_engine learn lot data improve search_engine simple example shows small number entries estimate probabilities sense document relevant useful user typing course problems dont_observe queries documents relevance lot unseen general collected data documents shown unseen queries predict queries typing obviously approach wont work apply unseen queries unseen shows basic_idea problems control model makes sense case lot unseen documents queries solutions approximate right particular case code query like retrieval model approximate conditional p q given d r equal assume user likes document seen user clicked shows interested likely user actually enter likely query role interesting basically assume user types query user likes words actually following user formula query based imaginary relevant look conditional obvious making use new conditional probability help score knew conditional probability able estimate conditional probability relying big having similar problems making assumption way bypass big table try model user formulates ok simplify general model derive specific iranian function lets look model work example basically going case ask following question documents likely imaginary relevant document users mind user formulates ask question quantify probability probability conditional observing query particular document infected imaginary relevant document users compute query likelihood likelihood queries given values rank documents based summarize general idea modern relevance probabilistic model assume introduce binary random_variable r lets scoring_function defined based conditional talked approximate query case ranking_function thats basically based probability query given document probability interpreted probability user likes document d pose queria question course compute conditional probability general compute probability text q model called language_model kind models proposed model specifically interested following conditional probability issuing document likely user oppose ann lecture working introduction language models model text probabilistic model
lecture statistical language_model lecture going introduction statistical language_model model text data probabilistic_models related model query based going talk language_model going talk simplest language_model called unigram_language model happens useful model text finally discussed possible uses language_model language_model probability distribution word model sequence today wednesday probability gave wednesday small becauses probability given sentences sequences words vary lot depending clearly context ordinary conversation probably today wednesday popular imagine context discussing applied math maybe eigenvalues positive higher means represent topic mortal council regarded probabilistic mechanism generating called generating mean imagine thats visualized hands stochastic system generate sequences ask sequence simple sequence device want example today generated example possibilities right sense view data basically sample observable generating model useful quantify uncertainties natural_language unvertainties source simply ambiguity natural_language discussed_earlier lab source dont complete_understanding lack knowledge understand case uncertainties let examples questions answer language_model interesting application different given john likely happy opposed habit word sequence words obviously useful speech recognition happy happy similar acoustical sound acoustic look language_model know john feels happy far likely john feels example given observe baseball 3 times game news article likely sports obviously related text categorization information given user interested sports news likely user baseball query clearly related query likelihood discussed previous lets look simplicity language_model called unigram_language assume generate text generating word means probability sequence product probability normally theyre right seen word like language far likely observe model havent seen assumption necessarily true assumption simplify model precisely parameters vocabulary probability word probabilities strictly speaking actually n1 said text assumed assembled drawn world example ask device model stochastic general words instead instead giving sequence like todays wednesday gives word kinds words assemble words allows little computer probability todays wednesday product asked model generate sequence actually allows compute probability model needs n parameters means specify probabilities words models behavior completely specified dont assumption specify probabilities kinds combinations making assumption makes easier estimate parameters lets specific unigram_language models probabilities high probability words clearly suggests topic text mining high probability words related second related ask question likely observe particular text models suppose sample lets distribution simple words think generated maybe text maybe maybe word fooled small probability general high probability words imagine gender text looks like text fact small probability able actually generate actual text mining paper actually meaningful probability extreme case imagine able generate attacks paper text mining paper accepted major case public non zero probability assume words non zero similarly second topic imagine generate folder nutrition doesnt mean generate paper text probability small maybe smaller generating paper accepted major conference point given talk probability observing certain kind text higher lets look problem different suppose available particular case maybe abstract text reminding world total_number words question ask estimation ask question model word distribution generate assuming text generated sampling words guess decide text mining pause video second try think best_guess youre like lot people guessed best_guess text probability 10 100 ive seen text 10 times total 100 words simply simply_normalize thats fact word justified intuition consistent mathematical derivation called maximum_likelihood estimator assume parameter settings observed data maximum means change probabilities probability observing particular text data somewhat simple basically need look count word document divided total_number words document document_length normalized consequences course going assign zero probabilities unseen oveserve word incentive assign non zero probability cause away probability_mass ovbserved words obviously wouldnt maximize probability particular observer text question best answer depends kind model want find gives best model based particular youre interested model explain content paper abstract second thought right thing words body zero probabilities observed going cover little later discussing query likelihood retrieval model lets look possible uses use simply use represent general english background use text estimate language_model model look common words like way etc common words like rare background_language represents frequency words english right background lets look maybe time look computer science research_papers collection computer science research_papers use maximum microarrays better simply_normalize case distribution looks looks similar words common words related computer science computer software text words example imagine probability smaller probability words common general distribution characterizes topic corresponding look smaller case lets look text mining expected occur soon text mining association relatively higher probabilities contrast distribution text relatively_small means based different attacks today different model model captures document language_model collection language_model later retrieval lets look use statistically find words semantically_related computer find words thought lets look text match computer look documents contain word lets build language_model surprisingly common case language_model gives conditional probability seeing world context computer common words naturally high_probabilities computer software relatively high_probabilities use model words semantically_related intuitively like common turns possible use langage suggested dont know words common want kind rid model tell maybe background_language model precisely information tells words common use background model know words common words general surprising observe context computer small probability general surprising seen computer probability true use models figure words related example simply ratio probabilities normalize topic language_model probability world background_language ratio computer ranked followed software words related occur frequently context computer frequently common words high fact ratio related taking sample text contains computer dont occurrences shows simple language models limited analysis lecture language_model basically probability distribution talked simplest language_model called unigram model word talked uses language_model represented topic document collection general rediscovered water lecture going talk model design retrieval additional_readings textbook statistical natural_language second article survey statistical language models lot pointers research
lecture query likelihood probabilistic retrieval lecture continue discussion probabilistic retrieval particular going talk query likelihood retrieval query likelihood retrieval idea model likely user likes document pose particular case imagine user likes particular document presidential_campaign assume user use document basis post query try retrieve imagine user use works follows assume query generated sampling words example user pick word like presidential use query user pick word like campaign second query course assumption user pose user actually followed maybe different question assumption allowed formulate characterize conditional allows rely big table showed earlier use empirical data estimate use derive retrieval function implement program assumption weve query word independently sampled word basically obtained lets works computing query probability probability particular query sequence assumption word generated_independently result probability query product probability query compute probability query word based assumption word picked user know probability word relative frequency word example probability presidential given count presidential document divided total_number words document document_length assumptions actually simple formula retrieval right use rank model work lets example documents suppose query presidential_campaign score documents simple right count times seen presidential times seen campaign et cetera d4 seen presidential twice thats length document 4 multiplied 1 length document 4 probability similarly probabilities look numbers formulas scoring sense cause assume d3 d4 length looks like going rank d4 d3 d2 expect looks like capture tf try different query like presidential_campaign problem think documents mentioned according assumption user pick word document generate query probability obtaining word like 0 right caused problem cause documents zero probability generating fine zero probability d2 non_relevant ok zero d3 d4 longer whats worse cant distinguish d2 right thats obviously weve think caused examine derive ranking_function examine assumptions carefully realize caused right moment think think reason update zero fix right think moment realize thats assumption query word drawn document users order fix assume user drawn word necessarily document lets improve model improvement instead drawing word document lets imagine user actually draw word document showed assume document generated unigram_language doesnt necessarily assign zero probability fact consume model assign zero probability think way generation_process little bit user model instead particular model estimated based user generate query similar process pick example word difference time pick word like update update occur document potentially generate query word like update query update want zero fix problem reasonable thinking user looking general unigram_language model instead fixed compute query likelihood assumption involves 2 steps right compute document language_model example ive_shown possible language models based given query data mining second step compute likelihood query making independent assumptions probability product probability query documents going score documents thats basic_idea query likelihood retrieval generally ranking_function look like following right assume query n w wn scoring_function ranking_function probability observe query given user thinking assumed product probabilities individual based independence_assumption actually score document query log query likelihood shown second_line avoid having lot small multiply cause underflow lose precision transforming value logarithm maintain order documents avoid underflow logarithm transformation course product sum shown second_line sum query words inside value log probability word given rewrite sum different sum query words n query sum sum possible words count word essentially considering words query word query count considering n different form going sum words course word occur multiple_times thats log probability word given document language_model retrieval function actually know count word thing dont know document language_model converted retrieval problem include problem estimating document language_model compute probability query word given different estimation methods lead different ranking like different ways place document vector vector_space lead different ranking_function vector_space different ways estimate document language_model lead different ranking_function query
lecture smoothing language lecture going continue talking probabilistic retrieval particular going talk smoothing language_model query likelihood retrieval seen slide previous_lecture ranking_function based query assume independence generating query formula look like following sum query words inside log probability word given document document language_model main task estimate document language_model said different methods estimating model lead different retrieval_functions lecture going look estimate language_model obvious choice maximum_likelihood estimate seen going normalize word frequencies estimated probability look step means words frequency count identical right frequent account different note words occurred document zero probability know like model assumed earlier lecture assume user sample word formulate theres chance sampling word thats document know thats improve order assign non zero probability words observed away probability_mass words observed example away probability_mass need extra probability_mass unseen want probabilities transformation improve maximum_likelihood estimate assigning non zero probabilities words observed smoothing smoothing improving estimate considering possibility author written asked write document author written think factor smoother language_model accurate representation actual imagine seen abstract research lets document right unseen words probability mean chance sampling word outside abstract formulate imagine user interested topic user actually choose word thats abstract use obviously asked author write author written text smoothing language_model attempt try recover model article course dont knowledge words observed thats smoothing actually tricky lets talk little smooth language_model key question probability assigned unseen different idea thats useful retrieval let probability unseen word proportional probability given reference language_model means dont_observe word data set going assume probability kind governed reference language_model tell unseen words likely higher case retrieval natural choice collection language_model reference language_model dont_observe word going assume probability word proportional probability word formally estimating probability word given document word seen probability maximum_likelihood estimate p sub word seen document going let probability proportional probability word coefficient control probability_mass assign unseen obviously probabilities sum alpha_sub d constrained plug smoothing formula query likelihood running right sum query words note written form sum sum words vocabulary note count word effect taking sum query words common way said query smoothing method assume words observed document somewhat different form probability going decompose sum sum query words matching means sum words nonzero probability document sorry non 0 count word occurred course non 0 count query words query words matching hand sum taking sum query words matched occur term dont occur case words probability assumption seen words different rewriting second difference sums basically sum actually sum query know original sum query query words matched pretend query words sum query obviously sum extra sum extra terms taking sum query matched order equal subtract sum query words matching makes sense considering query words subtract query words matched query words matched reverse process want want thats different forms terms inside words match query words matched document kind set match query terms document inside sum sums clearly form formula looks like note interesting formula query words matched document sum decomposed parts look simpler probabilities unseen formula interesting sum matched query like vector_space model sum terms intersection query vector document looks little bit like vector_space fact theres similarity explain
showed rewrite query likelihood retrieval function form looks like formula assumption smoothing language_model based collection language_model look rewriting actually benefit helps better understand ranking_function particular going formula smoothing collection language_model like tf_idf weighting length_normalization second benefit allows compute query likelihood particular main formula sum matched query better sum smooth document language_model send non zero probabilities new form formula easier score interesting note term actually independent document goal rank documents query ignore term going ignoring wouldnt affect order inside sum matched query term weight weight actually looks like tf_idf frequency word query like vector_space dot_product word frequency query naturally pot correspond vector element document vector actually encodes weight similar factor tf_idf ill let capturing tf capturing idf_weighting want pause video noticed p seen related term_frequency sense word occurs frequently document estimated probability tend means term like tf notice term actually achieving effect idf popularity term probability collection larger weight actually smaller means popular actually smaller weight precisely idf_weighting different form tf_idf remember idf log logarithm document intuitively achieves similar interestingly related length_normalization factor related document_length term related idf_weighting collection probability turns term actually related document_length normalization particular alpha_sub d related length encodes probability_mass want unseen smoothing want intuitively document long need smoothing assume data probably observed words author written document alpha_sub d expected need like words term appears penalize_long documenting alpha_sub d tend longer long note alpha_sub d actually penalizing long documents effect later consider specific smoothing_methods turns penalize_long documents like tf_idf weighting document_length normalization formulas vector_space thats interesting observation means dont think specific way need assume smooth collection language_model looks like tf_idf weighting documents length_normalization whats_interesting fixed form ranking_function heuristically fact think look assumptions logarithm query likelihood turned product sum logarithm probability thats note want heuristically implement tf weight idf_weighting dont necessarily imagine drop logarithm tf_idf whats nice probabilistic modeling automatically given logarithm thats basically fixed form formula heuristically design case try drop logarithm probably work nice property probabilistic modeling following assumptions probability rules formula formula particular form like heuristically design formula necessary end having specific summarize talked need smoothing document language_model zero probability unseen words thats good scoring query unseen necessary general improve accuracy estimating model represents topic general idea smoothing retrieval use collection language_model clue unseen word higher probability unseen word assumed proportional probability assumption weve shown derive general ranking formula query likelihood effect tf_idf weighting document_length rewriting scoring ranking_function primarily based sum weights match query terms like vector_space actual ranking_function given automatically probability rules assumptions unlike vector_space model think form need address question exactly smooth document language_model exactly use reference language_model based collection adjust probability maximum_likelihood estimate topic
lecture specific smoothing_methods language models probabilistic retrieval lecture continue discussion language models information retrieval particularly query likelihood retrieval method going talk specifics smoothing_methods retrieval slide previous_lecture query likelihood ranking smoothing collection language_model end having retrieval function looks like retrieval function based assumptions discussed sum matched query inside sum count term query term tf_idf weight constant end clearly want implement function program language need figure particular going need know estimate probability word set alpha order answer questions think specifically smoothing_methods main topic gonna_talk smoothing_methods simple linear interpolation fixed called jelinekmercer idea actually picture_shows document language_model maximum_likelihood estimate gives word counts normalized total_number words idea maximize probability observed text result word like observed text going zero probability idea smoothing rely collection language_model word going zero probability help decide non zero probability assigned note network non zero approach linear interpolation maximum_likelihood estimate collection language_model controlled smoothing parameter smoothing larger lambda mixing achieve goal assigning non zero probabilities word lets works example compute smooth probability maximum_likelihood estimate gives 10 100 thats collection probability combine simple word network zero probability getting non zero value thats count going 0 non zero thats basically method_works think easily alpha_sub d smoothing method basically thats remember coefficient probability word given collection language_model right ok smoothing second similar dynamic coefficient linear called dirichlet prior bayesian face problem zero probability unseen word like use collection language_model case going combine somewhat different formula seen maximum_likelihood estimate collection language_model jm_smoothing coefficient lambda fixed number dynamic coefficient form mu nonnegative set mu effect long document actually smaller long document longer length coefficient actually long document smoothy sense fixed coefficient form coefficients way understand smoothing basically means dynamic coefficient interpolation way understand easier remember rewrite smoothing method form easily changes maximum_likelihood estimate right normalized count document_length form add count mean related probability word collection multiply parameter combine count essentially adding pseudo_counts observed word got pseudo total counts sum pseudo_counts actual word result total added pseudo_counts words probability words sum total_number pseudo count added probability case essentially pseudo count data pretend actually augment data including pseudo data defined collection language_model result total counts word like result word zero count lets says zero account non zero method_works lets look specific right text 10 original count actually observe add pseudo probability text form probability whats alpha_sub want think pause notice basically alpha_sub d alpha_sub d depend length depends document linear interpolation jm_smoothing
lets plug smoothing_methods ranking_function general sorry general ranking_function smoothing collection language_model specific smoothing method jm_smoothing lets whats value alpha_sub whats value p sub seen need decide order figure exact form ranking_function need figure course lets basically right probability seeing probability unseen word words lambda basically easy whats value alpha think lambda right happen plug value lambda depend document right end having ranking_function case easily precisely vector_space model sum matched query element query vector think element document vector thats vector lets examine whats inside plus going nonnegative going right lambda parameter lets look clearly tf larger count higher idf_weighting document_length heuristics captured whats_interesting kind got weighting function automatically making assumptions vector_space model heuristic design case note specific form form actually makes think denominator length document total_number words multiplied probability word given actually interpreted expected_count going draw word collection language_model want draw number words expected_count word w precisely given ratio basically comparing actual actual count word document expected_count given word fact following distribution counter larger expected_count ratio thats actually interesting interpretation right intuitively_makes lot advantage kind probabilistic explicit assumptions know precisely logarithm formula intuitively_makes lot tfidf_weighting document_length lets look dirichlet prior similar case jm_smoothing case smoothing parameter mu thats different lambda saw format looks form function looks linear compute ratio defined ratio whats_interesting comparing actual count expected_count word sample mu words according collection note interesting dont document_length unlike jm_smoothing course wonder document_length interestingly document_length alpha_sub d result following function sum matched query query term_frequency interpret element document longer simple dot_product note n length means score function sum query words adjustment score based clear document_length normalization lens denominator longer document lower tf_idf time form formula different previous jm_smoothing intuitively implements tf_idf weighting document_length form function dictated probabilistic reasoning disadvantages approach theres guarantee form formula actually look retrieval tf_idf weighting stopping length_normalization example unclear sublinear_transformation logarithm function right sublinear_transformation means theres guarantee end suppose dont logarithm theres sub_linear discussed formula going thats example gap formal model like relevance model subjective tight doesnt mean example imagine logarithm right heuristically add add double logarithm mean function longer probabilistic consequence modification longer thats example bm_25 remains competitive open challenge use probabilistic model derive better model particular use query likelihood derive model work consistently better bm25 interesting open summarize weve talked smoothing_methods jelinekmercer fixed coefficient linear dirichlet prior add pseudocounts word adaptive interpolation coefficient larger shorter cases smoothing_methods able reach retrieval function assumptions clearly articulated theyre experiment results retrieval_functions effective comparable bm_25 pivoted_length major advantage probabilistic model dont lot heuristic end naturally implemented tf_idf weighting document_length functions precisely smoothing case course need set smoothing parameter methods estimate overall shows probabilistic model follow different strategy vector_space end end retrieval_functions look similar vector_space model advantages having assumptions clearly form dictated probabilistic concludes discussion query likelihood problems lets recall assumptions order derive functions seen basically assumptions assumption relevance modeled query likelihood second assumption query words generated_independently allows decompose probability product probabilities words assumption word seen document going let probability proportional probability collection smoothing collection language_model finally weve assumptions use jm_smoothing dirichlet assumptions choice form retrieval function seen_earlier fortunately function nice property implements tf_idf weighting documents length_normalization functions work sense functions heuristic compared vector_space basic model find discussion reference end
lecture feedback text lecture going continue discussion text retrieval particular going talk feedback impacts diagram shows retrieval user typing query sent retrieval engine search_engine engine return results shown user seen user actually example user said good document good called relevant judgment relevance feedback weve_got feedback information user based useful system exactly interesting feedback module use document collection try improve typically involve updating query system rank results accurately relevance feedback based relevance_judgments judgments reliable users generally dont want extra downside involves extra effort form feedback called pseudo relevance feedback blind feedback called automatic user got fact dont involve users theres user simply assume ranked documents lets assume assumed documents learn improve wonder help simply assume ranked documents imagine ranked documents actually similar relevant_documents look like relevant_documents possible learn related terms query fact recall talked language_model analyze word association learn related words word computer right use computer retrieve documents contain imagine query computer right results documents contain computer n match computer going count terms going use background_language model choose terms frequent set frequent contrast find learn related terms word computer seen related words added original_query expand query help bring documents dont necessarily match computer match words like program effective improving search course pseudo relavance feedback completely arbitrary set cut theres called implicit_feedback case involve users dont asked users judgments instead observe user interacts search case going look clickthroughs user clicked user viewed user skipped user clue document useful assume going use snippet text thats actually seen user instead actual document link lets web_search broken doesnt matter user tried fetch document display assume text probably relevant interesting learn information called implicit_feedback use information update important technique modern_search think google bing collect lot user activities theyre serving right observe documents click documents skip information valuable use improve search_engine summarize talked kinds relevance feedback user makes explicit takes user effort judgment information talk pseudo feedback simply assume topranked documents dont involve user actually return results implicit_feedback use click dont involved users user doesnt explicit effort
lecture feedback vector_space lecture continue talking feedback text particularly going talk feedback vector_space discussed case task text retrieval system learn examples improve retrieval positive documents assumed relevant judgement document viewed negative documents known nonrelevant document escaped general method vector_space model modify query vector want place query vector better position mean exactly think query vector mean vector general mean add new adjust weights terms assign weights new result general query terms query effective method vector_space model feedback called walker feedback proposed decades idea illustrate idea 2 dimensional display documents collection query query vector use query vector use similarity function find similar documents basically drawing documents basically ranked pluses relevant_documents relevant_documents example relevant minuses negative documents goal trying query vector position improve retrieval looking think query improve retrieval accuracy intuitively want query vector want think pause think picture realize order work case want query close positive vectors means ideally want place query vector want query vector closer exactly point want relevant_documents ranked want center relevant_documents right draw circle relevant_documents means query vector centroid relevant locking basically idea course consider centroid negative documents want away negative geometrically talking movie vector closer bath away algebraically means original_query average basically centroid vector relevant_documents average vectors computing centroid vectors similarly average non_relevant document essentially non_relevant documents parameters alpha beta gamma theyre controlling add vectors moving query closer said add kind query vector away main_idea rocchio feedback new query vector store newer query vector reflect original_query vector relevant centroid vector away non_relevant centroid ok lets look example seen_earlier display actual showed vector representation 5 relevant_documents right displayed red term vectors assumed tf_idf lot zero weights course negative rocchio method compute centroid category look centroid vectors positive simply corresponding element thats average know added corresponding_elements average average thats look centroid negative gonna average corresponding_elements vectors rocchio feedback method going combine original_query lets thats saw parameter alpha controlling original period weight thats beta control influence positive centroid weight thats 5 negative weight controlled gamma weight course negative exactly new going use new query rent imagine happen right movement match red documents better vector closer going penalize black documents non_relevant precisely want course apply method potential original_query nonzero query expansion imagine terms nonzero calculation involve practice truncate vector retain terms highest lets talk use method mentioned truncated adapter small number words highest weights centroid efficiency negative examples non_relevant examples tend useful especially compared positive reason negative documents tend distract query average doesnt tell exactly positive documents tend clustered point consistent means dont use negative note cases difficult queries ranking results negative negative feedback factor thing avoid means relatively high weight original_query sample feedback relatively_small dont want overly trust small original_query terms terms typing user user decided terms order prevent overfitting drifting topic preventing topic drifting bias feedback examples generally pretty high weight original especially true pseudo relevance method relevance feedback pseudo relevance case pseudo feedback parameter beta set smaller value relevant examples assumed reliable relevance case relevance feedback obviously use larger value parameters set root method usually popular method
lecture feedback language modeling lecture continue discussion feedback text particular going talk feedback language modeling derive query likelihood ranking_function making basic retrieval function formula formulas worked think feedback information little bit awkward use query like_hold perform feedback lot times feedback information additional information assume query generated assembling words language_model query likelihood kind natural sample words form feedback documents result researchers proposed way generalize query like_hold function called callback labeler divergance retrieval model actually going query likelihood retrieval function closer vector_space form language_model regarded generalization query like_hold sense cover query likelihood special case feedback achieved simple query model estimation similar rock hill updates query care_divergent switchable model query like_hold retrieval function kill diversions called cross whichever model basically language_model basically given probabilistic model characterize user looking versus count query difference allows plug different ways estimate estimated different ways including feedback called care divergens interpreted measuring care_divergent query model denoted talking language_model smoothly collection language_model going talk detail find called cross entropy effect ignore terms care_divergent function end having actually cross entropy terms information purpose receive formulas look identical probability award given query language_model sum words document non zero probability query kind generalization overall match query easy recover query like_hold retrieval function simply setting query model relative frequency award easy eliminate query thats constant exactly thats care_divergent model regarded generalization query like cover query like rd special allow use care_divergent model feedback picture_shows estimate document language_model estimate query model compute kl diversions denoted basically means exactly like vector_space model cause computer vector document computer vector query compute distance vectors special forms probability got results find feedback lets assume sorry positive documents consider kinds like rock youll know computer language_model coder feedback language_model going vector like computing central rock model combined original_query linear update model like rock parameter alpha control feedback set 0 says theres feedback set got 4 ignore original_query generally desirable right absolutely sure seen lot relevant_documents query terms course main question compute single f big question rest talk approaches course approach based generated im going user generated picture_shows feedback model want basis feedback lets observing positive click documents users relevant_documents judged users simply ranked blocking assume imagine compute centroid documents language_model approach simply assume documents generated language_model normalize word frequency got world question distribution good ranked world think words common words right language_model ranked words actually common words like good feedback adding lot words query interpret original_query particular trying rid common words seen actually way background_language case learning associations words words related water way going talk approach principled case going state said common documents belong topic model right assume words generated background_language model generated words use maximum_likelihood estimator note words generated model forced assign_high probabilities award like occurs note order reduce probability model help explain case appropriate use background_language model achieve goal model assign_high probabilities common approach assume machine words work source imagine flip coin decide distribution use probability coin_shows head going use background_language model simple word model probability 1_minus decide use topic model like estimate going generate assumption thing model mixture_model cause distributions mixed actually dont know think thing ask words word random manner right course word depend distribution addition depend lambda lambda high going use background distribution youll different words lemmes small going right think way basically going use maximum_likelihood estimator adjust model estimate basically going adjust best explain difference asking model going ask model mixture_model explain data becauses got help background doesnt assign_high probabilities result assign higher probabilities words having high common high_probabilities according maximum_likelihood right dont help background result topic model assign_high probabilities high probability words according topic model common rare ok basically little bit idf allow achieve effect removing awards meaningless mathematically compute like_hold local like_hold feedback note parameter lambda assume lambda denotes noise feedback going lets set parameter 50 words noise 9 noise assumed fixed assume probabilities parameters like simplest unigram_language end parameters number likelihood_function look similar likelihood_function hold function inside logarithm theres sum consider depend lambda thats mathematically function theater unknown variables right function values known choose probability distribution maximize locali idea maximum like horace mathematical solve optimization_problem essentially try theater values find gives thing maximum defined math obtain serial f interpreted original_query model examples feedback model learned web document collection sudo use documents use mixture_model query airport security retrieve 10 documents web course pseudo going feed mixture_model document words learned probability award given feedback model cases highest probability words include relevant words query airport security query words high_probabilities case naturally becausw occur frequently ranked documents beverage alcohol bomb terrorists relevant topic combined original_query help match accurately documents help bring documents imagine maybe example airport bomb single feedback issues model works picks related words whats_interesting look tables compare case lambda set small value common dont use background remember lambda use probability background model generate dont rely background model use topic model account common words set lambda high value use background model explain theres burden explaining common words feedback documents topic result topic model discriminant contains relevant words common added original_query achieve summarize lecture talked feedback language_model general feedback learn examples assumed examples sued examples assume documents assumed random based fractions like feedback based pixels implicit_feedback talked major feedback scenarios relevance feedback sooner feedback principle talked use rock feedback vector_space model use query model missing feedback language_model briefly talked mixture_model basic_idea methods example relevance model effective model estimating query read methods references listed end additional_readings book systematic review discussion language models information retrieval important research paper thats relevance based language models effective way computing query
lecture web_search lecture going talk important applications text retrieval web_search lets look general challenges opportunities web_search information retrieval algorithms developed web born web born created best opportunity apply algorithms major application problem naturally extensions classical search address new challenges encountered web_search general firstly scalability handle size web ensure completeness coverage serve users quickly answering queries thats major challenge web born scale search relatively_small second problem low quality information challenge dynamics new pages constantly created pages updated quickly makes harder index fresh challenges solve order build high quality web_search hand interesting opportunities leverage improve search additional example links leverage improve_scoring algorithm talked vector_space model general applied search applications thats hand dont advantage special characteristics pages documents specific applications web_search web pages linked obviously link information challenges opportunities new techniques developed web_search need web_search parallel indexing searching address issue particular googless imagine mapreduce influential helpful second techniques developed addressing problem spam detection prevent spam pages ranked techniques achieve robust ranking going use lot signals rank pages easy spam search_engine particular line techniques link techniques allow improve search results leveraging extra general web_search going use multiple features ranking link analysis exploit kinds clues like layout web pages anchor_text describes link heres picture showing basic search_engine basically web left user right going help user access web information component crawl second component indexer pages create inverted_index component retriever use inverted_index answer users query talking users browser search results given user browser results allow user interact web gonna_talk going talk called spider software robot like crawling pages build toy crawler relatively easy cause need start set seed pages fetch pages web pause pages figure new links add priority queue explore additional build real crawler actually tricky complicated issues example server doesnt respond theres trap generates dynamically generated web pages attract crawler crawling site fetch dynamically generated pages results issue crawling courtesy dont want overload particular server crawling respect robot exclusion need handle different types images pdf files kinds formats ann consider ui extension cgi script internal references etc javascripts page create challenges ideally recognize redundant pages cause dont duplicate finally interested discover hidden urls linked page truncate url shorter path able additional major crawling strategies general breadth common becauses naturally balance balance server probing particular server parallel crawling natural task easy variations crawling task interesting variation called focused case going crawl pages particular example pages typically going start query use query results major search_engine start results gradually challenge crawling find new pages people created people probably creating new pages challenging new pages actually linked old probably find recrawling old interesting challenges finally face scenario incremental crawling repeated crawling right lets want build web_search engine youre crawl lot data collected data future need crawl updated general dont recrawl right case goal minimize resource overhead minimum resources crawl updates actually interesting research question open research question arent standard algorithms established general imagine learn past major factors consider page updated frequently crawl page page static page hasnt changed months probably dont recrawl unlikely changed hand sports score page gets updated frequently need recrawl maybe multiple_times day factor consider page frequently accessed means high utility page thats important ensure page compared page fetched users year page changed lot probably necessary crawl page urgent maintain freshness frequently accessed page summarize web_search important applications text retrieval new challenges particularly scalability efficiency quality new opportunities particularly rich link information layout crawler essential component web_search general classify initial crawling want complete general search_engine focused crawling want target certain type scenario thats incremental updating crawled data incremental case need optimize try use minimum resource needed fresh
lecture web lecture continue talking web_search going talk create web scale crawled web weve_got lot web step use indexer create inverted_index general use standard information retrieval techniques creating index talked previous_lecture new challenges solve web scale indexing main scalability index large actually fit single machine single disk store data multiple data large beneficial process data parallel produce index address challenges google number google_file system thats general distributed file_system help programmers manage files stored cluster second general software framework supporting parallel hadoop known open source implementation map_reduce architecture google_file uses simple centralized management mechanism manage specific locations files maintains file space look table know exactly file application client talk gfs master obtain specific locations files want gfs client specific information files application client talk specific servers data actually sit directly avoid involving nodes file_system stores files machines system create fixed size chunks data files separated chunk 64 mb pretty big thats property large data chunks replicated ensure reliability programmer doesnt taken care fire system application perspective programmer normal program doesnt know exactly stored invoke high level operators process feature data transfers directly application chunk servers efficient google_file system google proposed map_reduce general framework parallel useful support task like building inverted_index framework hiding lot low level features result programmer minimum effort create application run large cluster low level details hidden framework including specific network communications load balancing tasks details hidden nice feature builtin fault server broken lets service tasks finished map_reduce mechanism know task automatically dispatches task servers job program doesnt heres mapreduce input data separated number key_value exactly value depend data actually fairly general framework allow partition data different parts processed key_value pair send map programmer write map function map function process key_value pair generator number key_value course new key usually different old key thats given map key_value pairs output map function outputs map functions sorted based key result values associated key weve_got pair key set values attached sent reduce_function course reduce_function handle different key send output values multiple reduce functions handling unique reduce_function process key set values produce set key values output values collected form final right general framework programmer needs write map function reduce_function actually taken care mapreduce program needs minimum framework input data partitioned multiple parts processed parallel map process reach reduce stage multiple reduce functions process different keys associated values parallel achieves achieves purpose parallel_processing large data lets look simple example thats input files containing output want generate number occurrences word word know kind counting useful example assess popularity word large collection useful achieving effect idf solve problem natural task parallel simply counting different parts file parallel end combine counts thats precisely idea parallelize lines input specifically assume input map function key_value pair represents line number stream line example key 1 value hello world bye world 4 line key_value pair sent map map function count words line case course word gets count output map map function simple look pseudocode looks like right simply needs iterate words line collect function means send world counter collector try key_value pairs different map functions function simple programmer specifies function way process course second_line handled different map function produce similar ok output map functions send collector collector internal grouping stage collected multiple pairs pair word count pairs sort based key collect counts word like similarly words like hadoop hello world attached number values number counts represent occurrences word different got new pair key set values pair feeding reduce_function reduce_function finish job counting total occurrences got partial accounts needs similarly add reduce_function shown counter iterate words array accumulated finally output key total count thats precisely want output similar building inverted_index think output indexed world got basically got counts whats missing document ids specific frequency counts words documents modify slightly actually build inverted_index heres case assume input map function pair key denotes document id value denoting stream words document map function similar seen word count simply groups counts word document generate set key_value key value count orld document plus document easily need add document course later inverted_index like information map function track sent reduce_function similarly document d2 processed way end sorting mechanism group key like java associated documents match key documents java counts java collected fed reduce_function reduce_function got input looks like inverted_index entry right word documents contain word frequencies word needs simply concatenate continuous chunk data written file_system basically reduce_function going minimum pseudocode inverted_index procedure map procedure program specify functions program map_reduce basically case map going count occurrences word associative array output old accounts document reduce_function hand simply concatenates input given single entry simple mapreduce function allow construct inverted_index large_scale data processed different program doesnt care parallel index construction web_search summarize web scale indexing requires new techniques standard traditional indexing techniques mainly store index multiple machines usually file_system like google_file system distributed file_system secondly requires creating index parallel large takes long time create index parallel faster mapreduce note post gfs mapreduce frameworks general support
lecture link analysis web_search lecture going talk web_search particularly focusing link analysis use results improve main topic lecture look ranking algorithms web_search previous_lecture talked create index got want improve ranking standard ir models fact important building blocks improvement supporting web_search arent sufficient mainly following web tend different information example people search web page entry page different traditional library search people primarily interested collecting literature kind query called navigational purpose navigate particular target queries benefit link secondly documents additional information web web pages lot clues layout title link provided opportunity use extra context document improve_scoring finally information quality varies lot means consider factors improve ranking robust way rank pages making harder spammer manipulate signal improve ranking result people number major extensions ranking line exploit links improve_scoring thats main topic people proposed algorithms exploit large_scale implicit_feedback information form click throughs thats course category feedback machine_learning general web_search ranking algorithms based machine_learning algorithms combine kinds based standard visual models bm25 query likelihood score different parts documents provide additional features based content matching link information useful provide additional lets look links detail snapshot web links link different pages case look description link thats pointing document description text called anchor_text think text actually useful provides extra description page example wants bookmark com page biggest online bookstore link right description actually similar user type query box looking page thats useful ranking suppose types query like online bookstore fixed online query match anchor_text actually provides evidence matching page thats amazon entry match anchor_text describes link page actually provides good evidence relevance page pointed anchor_text look picture patterns links links indicate utility example right page received means pages pointing page shows page left page points pages directory page allow actually lot case authority page second case half means link information help provide extra text matching provide additional scores web pages characterize likely pages likely pages people course proposed ideas leverage link googles pagerank main technique early days good example algorithm capture page popularity basically score intuitions links like citations think page pointing similar paper citing course page cited assume page useful thats good pagerank essentially advantage intuition implement principled intuitively essentially citation counting link improves simple idea consider indirect means dont look look pages pages lot links means sense pages pointing pointed pages dont links dont thats idea getting indirected alright understand idea looking research_papers youre cited lets 10 papers 10 papers workshop papers papers influential right 10 links thats good cited 10 papers attracted lot case like consider indirect links idea going smooth citations assume basically page having non zero pseudo citation essentially trying imagine virtual links link pages actually pseudo reason want allow solve problem linear algebra think maybe best way understand page_rank think computer probability random surfer visiting web
lets look random surfing page assume random surfer choose page visit small thats course oversimplification complicated web lets documents d1 d2 d3 d4 lets assume random surfer random walker random surfer decide randomly_jump follow link visit random server probability random surfer follow pointing d3 pointing d4 random surfer pick reach d3 assumes random surfer bored random surfer decide ignore actual links simply randomly_jump page able reach pages theres link directly d1 assumed random surfing imagine random surfer surfing ask question likely average surfer actually reach particular page like d1 d2 d3 thats average probability visiting particular probability precisely pagerank pagerank_score document average probability surfer visits particular intuitively basically capture link page lot links higher chance visited opportunities having surfer follow link come random surfing model actually captures idea counting note considers indirect pages point lot mean random surfer likely reach increases chance nice way capture indirect direct mathematically compute probability order need look probability lets look transition_matrix metrics values indicating likely random surfer page row stands starting example row indicate probability going 4 pages d1 non zero entries 1 look graph d1 pointing d3 d4 link d1 d1 d2 weve_got zeros 2 5 d3 general element matrix m sub j probability going di dj obviously row values sum 1 surfer precisely pages right transition_matrix compute probability surfer visiting page look surf model basically compute probability reaching page left hand probability visiting page dj time t 1 time right hand equation involves probability page di time subscript index t indicates probability surfer document time equation basically captures possibilities reaching dj time t possibilities random surfing following link captures probability random surfer reach page following link random surfer chooses strategy probability 1_minus alpha assume factor 1_minus alpha main sum possible pages surfer time n pages sum possible n inside sum product probability surfer di time thats p sub t transition probability di order reach dj page surfer di time t follow link di probability probability di time t multiplied probability going page target second similar difference transition probability uniform transition probability 1 n captures probability reaching page random right form allows pagerank essentially assume smoothing transition_matrix think 1 n coming transition_matrix elements 1 n uniform matrix essentially merge form imagine theres different matrix thats combination m uniform matrix element 1 n sense pagerank uses idea smoothing ensuring theres zero entry transition_matrix course time dependent calculation imagine want compute average probabilities average probabilities probably satisfy equation considering time lets drop time index assume n equations page equation look variables equations precisely n right basically means system n equations n linear basically problem boils solve system showed equations matrix vector equals metrics transverse multiply remember knowledge youve learned linear algebra realize precisely equation item vector right multiply matrix vector value solved iterative equations basically taken previous slide pagerank scores different pages iterative approach power approach simply randomly initialized vector p repeatedly updated p multiplying matrix p concrete assume 2 example slide original transition_matrix right includes graph actual links smoothing transition_matrix uniform transition_matrix representing random jumping combine linear interpolation form essentially imagine web looks captured virtual links pagerank algorithm initialize p vector compute updating p vector matrix rewrite matrix model multiplication terms individual basically updating_formula particular pages pagerank_score want compute value updated score d1 basically multiply right dot_product value updated started initial values revise scores generate new set scores updating_formula repeatedly apply converges metrics like theres zero values guaranteed point pagerank scores typically set initial values 1 interestingly updating_formula interpreted propagating scores look formula compare graph imagine able interpret essentially propagating scores graph hope imagine values initialized pages lets thats 1 4 going use matrix update look basically going combine scores pages possibly lead reaching page look pages pointing page combine scores propagate sum scores document look scores represent probability random surfer visiting pages reached d1 propagation simulate probability reaching matrix multiplication repeatedly multiply vector matrix think propagating scores repeatedly practice computation pagerank_score actually efficient matrix sparse ways transform equation avoid actually literally computing values normalize equation somewhat different form equation ranking pages results potential problem zero link case page link probability pages sum basically probability reaching page page mainly lost probability_mass assume theres probability surfer try follow links theres link possible solution simply use page specific damping factor easily basically thats alpha 0 page case surfer randomly_jump page instead trying follow extensions page_rank extension topic specific noted pagerank doesnt use query pagerank query specific example topic specific pagerank simply assume surfer bored surfer going randomly_jump page instead going jump pages relevant example queries sports assume random jumping going randomly_jump sports bias pagerank topic like sports know current query sports use specialized pagerank_score rank documents better use generic pagerank_score pagerank general algorithm applications network analysis particularly example social imagine compute pagerank scores social network link indicate friendship relation youll meaningful scores
talked page_rank capture authorities looked examples hub interesting algorithm called hits thats going compute scores authorities intuitions pages sites good authorities pages cite pages good_hubs right think interesting idea algorithm going use reinforcement mechanism kind help improve_scoring hubs heres assume good authorities cited good_hubs means youre cited pages good hub scores increases authority score similarly good_hubs pointed good pointed lot good authority pages hub_score iterate reinforce cause point good_hubs point good authorities good hub_score authoritie improved pointed good hub algorithm applications graph network briefly heres construct matrix time going construct adjacency matrix going normalize theres theres link thats zero going define hub_score page sum authority scores pages hub depends youre pointing lot good authority thats says second equation define authorities score page sum hub scores pages good authoritie depend pages pointing good_hubs forms iterative reinforcement equations written matrix saw hub vector equal product edges adjacency matrix authority basically equation right similarly second equation returned authoritie vector equal product transpose multiplied hub vector different ways expressing whats_interesting look metrics form plug authority actually eliminate authoritie vector completely equation hub scores right hub_score vector equal transpose multiplied hub_score similarly transformation equation authority framed problem computing hubs authorities actually eliminate obtain difference page_rank matrix actually multiplication edges matrix transpose different page_rank mathematically computing hits typically initialize values said values iteratively apply equations essentially equivalent multiply matrix algorithm exactly similar page_rank adjacency matrix iteration going normalize allow control growth value grow larger basically hits algorithm compute hub scores authority scores scores ranking like page_rank summarize lecture seen link information particular anchor_text useful text representation page talk page_rank hits major link analysis generate scores web pages ranking_function note page_rank general algorithms applications analyzing graphs
lecture learning lecture going continue talking web_search particular going talk machine_learning combine different features improve ranking_function question address lecture combine features generate single ranking_function optimize search previous lectures talked number ways rank talked retrieval models like bm25 query like generate content based scores matching documents query talked link based_approaches like page_rank additional scores help improve question combine features potential features ranking useful ranking web improve accuracy improve robustness ranking_function easy spammer perturb features promote general idea learning rank use machine_learning combine features optimize weights different features generate optimal ranking_function assume given query document appear q define number features vary content based features score document respect query according retrieval function bm25 query likelihood pivot length_normalization pl2 linked based score like page_rank application retrieval models anchor_text page text descriptions links point clues document include feature url tilde indicator homepage engine features combined generate ranking_function question course combine approach simply hypothesize probability document relevant query function hypothesize probability relevance related features particular form function parameters control influence different features final course assumption assumption makes sense big question empirically evaluate hypothesising relevance related features particular way combine features generate potentially powerful ranking_function robust ranking_function naturally question estimate parameters know features higher weight features lower weight task training learning right approach use training_data data judged users know relevance_judgments know documents ranked high information based real judgments users approximated click information assume clicked documents better skiped documents clicked documents relevant skiped documents non_relevant general fit hypothesize ranking_function training_data meaning try optimize retrieval accuracy training_data adjust parameters optimize performance function training_data terms measures map training_data look like table tuple query document looks like relevance_judgments talked evaluation retrieval
lets look specific method thats based different fact simplest methods choose explain idea approach simply assume relevance document respect query related linear_combination xi denote feature xi q d features assume features combined linear feature controlled beta parameter thats weighting parameter larger value mean feature higher weight contribute scoring_function specific form function actually involves transformation probability probability know probability relevance range 0 assumed scoring_function related linear_combination right linear regression value linear_combination easily transformation map zero 1 range range real allows connect probability relevance zero linear_combination arbitrary rewrite probability function equation probability right hand form clearly non negative involves linear_combination clear value actually negative linear_combination equation value large mean value small probability probability large thats basically mean combination gives high value documents likely necessarily best hypothesis simple way connect features probability combination task estimate parameters function actually applied knowing beta_values harder apply function lets estimate beta_values lets look simple example 3 bm25 score document query page_rank score document depend topic sensitive pagerank depend general page_rank doesnt depend query bm25 score anchor_text feature_values particular doc document query case document d1 judgment says heres training instance feature_values case ok overly simplified case sufficient illustrate use maximum_likelihood estimator actually estimate basically going predict relevance status document based feature_values given observe feature_values predict relevance yeah course prediction hypothesize probability relevance related features way going values predict mean predicting relevance mean case expression right high fact hope value close relevant hand second case d2 hope value non_relevant lets mathematically similar expressing probability talking probability words talking probability relevance whats probability document relevant feature_values expression right need plug exactly seen replaced xis specific values right 7 different feature_values combine particular beta_values unknown gives probability document relevant assume ok want maximize probability relevant second document want compute probability prediction non_relevant mean compute 1_minus actually probability compute non relevance 1_minus probability expression probability relevance values 1 zero equation observing observing course probability depends beta_values right goal adjust beta_values thing reach large means going beta parameter_values maximize likelihood means look function going choose betas large large possible equivalent small precisely training know beta_values function defined beta_values completely specified new query new documents simply compute pair use formula generate ranking score scoring_function rank documents particular thats basic_idea learning
advanced learning algorithms regression based_approaches generally attempt direct optimizer retrieval like map note optimization objective_function seen previous slide directly related retrieval measure maximizing prediction zero dont necessarily optimize ranking imagine prediction 5 kinda middle zero ranking wrong got larger value d2 wont good retrieval perspective likelihood_function contrast case predicted_values 9 lets objective functioning error larger order documents correct thats actually better new advanced approaches try correct course challenge optimization_problem harder solve researchers proposed solutions problem read reference end know learning rank approaches actually general applied ranking problems retrieval list example recommender_systems computational advertising summarization probably encounter summarize lecture talked machine_learning combine multiple features improve ranking actually use machine_learning information retrieval started decades example rocchio feedback approaches talked earlier machine_learning approach applied relevance feedback recent use machine_learning driven changes environment applications retrieval systems driven availability lot training_data form click data wont available data provide lot useful knowledge relevance machine_learning methods applied secondly driven need combining features features available web naturally improve_scoring combining improve robustness ranking desired combating modern_search engines kind machine_learning techniques combined features optimize ranking major feature commercial engines google topic learning rank active_research topic community expect new results developed additional_readings information learning rank works advanced
lecture future web_search lecture going talk possible future trends web_search intelligent_information retrieval systems order improve accuracy search engines important consider special_cases information need particular trend specialized customized search engines called vertical search vertical search engines expected effective current general search engines assume users special group users common information need search_engine customized serve customization possible personalization search better understanding restriction domain advantages handling documents better understanding example particular words ambiguous domain bypass problem trend expect search_engine able learn like lifetime learning lifelong course attractive means search_engine self improve search engines better better happening search engines learn implicit_feedback users use quality search results popular queries typed users likely trend integration multi models information_access search navigation recommendation filtering combined form fledged information management beginning course talked push_versus different modes information_access modes similarly pull_mode querying browsing combined fact basically today current search engines browsing clicking weve_got information recommended cases information recommended future imagine seamlessly integrate system multi mode information_access convenient trend systems try search supports user reason people want search solve problem decision perform example consumers search opinions products order purchase product choose good product case beneficial support workflow purchasing product choosing area current search engines provided good support example look reviews want buy click button shopping site provide good task_support example researchers want find relevant literature site literature theres support finishing tasks writing general think opportunities innovate following slides talking little bit specific ideas thoughts hopefully help imagine new application relevant currently general think intelligent system especially intended information system specified nodes connect triangle able specify information system data user service basically questions ask serving kind data kind service provide right help basically specify system different ways connect depending connect different kind system let different kinds users left different types data information different service imagine connect different example connect web support search thats web_search right connect uiuc employees organization documents enterprise documents support search thats enterprise connect scientists literature information provide kinds service including search browsing alert new relevant_documents mining analyzing research trends provide task_support decision support able provide support automatically generating related work section research paper closer task_support right imagine literature assistant connect online shoppers blog articles product_reviews help people improve shopping experience provide example data mining capabilities analyze reviews compare products compare sentiment products provide task_support decision support help choose product connect customer service people emails imagine system provide analysis emails find major_complaints imagine system provide task_support automatically generating response customer email maybe intelligently attach message appropriate detector thats positive message complaint opportunity attach promotion complaint automatically generate generic response tell customer expect detailed response later trying help people improve shows opportunities lot restricted picture_shows trend technology characterizes intelligent_information system angles center triangle connects keyword_queries search bag words means current search engines basically provides search users model users based keyword_queries sees data bag words simple approximation actual information thats current connects nodes simple provides basic search function doesnt understand doesnt understand information showed trends push advanced function think user node keyword_queries look user search history model user completely understand users task environment task need context pushing personalization complete user modeling major direction order build intelligent_information bag words representation entity relation means recognize peoples names relations locations etc feasible todays natural_language processing technique googles recent initiative knowledge_graph heard good step direction level representation robust manner large_scale enable search_engine provide better future like knowledge representation add inference_rules search_engine calls large_scale semantic_analysis feasible vertical search easier progress particular service need search support information_access general search way access recommender_systems push pull different ways access relevant information going access need help people digest information found step analysis information data find patterns converted text information knowledge application actionable_knowledge decision_making furthermore knowledge help user improve productivity finishing example decision_making trend basically dimension anticipate intelligent_information systems provide intelligent interactive task_support emphasize interactive important optimize combined intelligence users system help users natural way dont assume system human user machine collaborate intelligent way efficient way combined intelligence high general minimize users overall effort solving big_picture future intelligent_information hopefully provide insights innovations
lecture recommender_systems far talked lot aspects search talked problem search ranking problem different methods ranking implementation altbrgt search_engine evaluate search_engine probably know web_search engines far important applications text retrieval useful tools help people convert big raw text data small set relevant_documents reason spend lectures search engines techniques search engines actually useful recommender_systems topic overall systems actually connected techniques slide seen talked different modes text access pull mentioned recommender_systems main systems serve users push mode systems initiative recommend information user push relevant information works user relatively stable information system good knowledge user recommender system called filtering system recommending useful items people like discarding filtering useless sense kind cases system binary decision usually theres dynamic source information knowledge users interest system delivery decision item interesting user hes interested system recommend article basic filtering question user like like item x ways answer think wanted look items x actually like look likes x user looks like like strategies combined follow strategy look item case recommending text talking content based filtering content based look second strategy compare users case exploit user similarity technique called collaborative_filtering lets look content based filtering system look inside system binary classifier knowledge users called user interest maintains profile track users utility function guide user decisions explained utility function helps system decide set accepted document passed threshold according initialization module users input maybe users specified keywords chosen category feed system initial user typically learning module learn users feedback note case typical users information need stable system lot opportunities observe users user taken recommended item viewed signal indicate recommended item relevant user discarded relevant feedback long term feedback long system clock collect lot information users interest improve whats criteria evaluating system know filtering system actually performs case use ranking evaluation measures like map afford waiting lot documents rank documents decision system decision real time general decide item words trying decide absolute_relevance case commonly strategies user utility function evaluate linear utility function thats defined example 3 multiplied number good items delivered minus 2 multiplied number bad items words treat gambling delete deliver good item lets win 3 gain deliver better lose 2 utility function basically kind measures money kind clear want maximize utility function strategy deliver good articles possible minimize delivery bad articles thats interesting question set coefficients showed 3 negative 2 possible ask question reasonable think think thats reasonable choice choices example 10 whats difference think utility function affect systems threshold decision think extreme cases 10ampnbsp 1 versus 1 think encourage system overdeliver encourage system conservative think big award delivering good document incur small penalty delivering intuitively encouraged deliver right try hopes getting good delivered youll big saw hand choose 1 10 dont big price deliver deliver good hand big loss deliver imagine system reluctant deliver lot absolutely sure utility function designed based specific basic problems content based filtering frst filtering decision binary decision maker binary classifier given text document profile description yes document thats decision module initialization seen_earlier system initialize system based limited text description examples component learning module able learn limited relevance_judgments count learn user preferences delivered documents dont deliver document user know able know user accumulate lot documents learn entire history modules optimized maximize build system different going talk extend retrieval search_engine information weve spent lot time talk search engines actually hard extend search_engine information heres basic_idea extending retrieval system information reuse lot retrieval techniques scoring right know score documents queries measure similarity profile text description document use score threshold filtering retrieval kind find scores documents apply threshold document passing threshold passing threshold going relevant going deliver component add course learn history use traditional feedback techniques learn improve_scoring know rocchio scoring develop new approaches learn set threshold need set initially learn update threshold heres system look like generalize vector_space model filtering right document vector fed scoring module exists search_engine implements vector_space model profile treated query essentially profile vector matched document vector generate score fed threshold module yes evaluation based utility filtering says yes documents sent user user feedback feedback information adjust threshold adjust vector representation vector learning essentially query modification case threshold learning new component need talk little
interesting challenges threshold learning filtering historical data collect filtering system scores status score 5 second nonrelevant course lot documents dont know status delivered judgments documents delivered user random sample censored kind creates difficulty learning secondly general little labeled data relevant data challenging machine_learning typically require training_data extreme case beginning dont label system decision thats difficult problem finally issue exploration versus exploitation means want explore document space little bit user interested documents havent words going explore space user interests testing user interested documents currently matching users lower threshold little bit deliver near misses user user respond user respond extra tradeoff hand want explore hand dont want explore cause overdeliver nonrelevant exploitation means exploit learned lets know user interested particular topic dont want dont deviate dont thats miss opportunity learn interest thats difficult problem solve problems general think use empirical utility optimization strategy strategy basically optimize threshold based historical data seen previous compute utility training_data candidate score pretend cut cut different scoring threshold point happen whats utility training_data kind compute utility right know relevance status assume know relevant status thats based approximation choose threshold gives maximum utility training_data course doesnt account exploration difficulty bias training sample general upper_bound true optimal threshold threshold actually possible discarded item actually interesting solve problem generate said lower threshold explore little bit heres particular approach called better gamma threshold idea ranked_list training documents seen far ranked yaxis course function depends specify coefficients utility function depending cut position utility suppose cut position example identify cutting cut optimal point theta optimal point achieve maximum utility chosen zero threshold zero utility threshold cut utility mean means lower threshold little bit reach threshold utility lower positive non high optimal_utility gives safe point explore explained desirable explore interest space desirable lower threshold based training_data means general want set threshold lets use alpha control deviation optimal_utility point formula threshold interpolation zero utility threshold optimal_utility question set alpha deviate optimal_utility point depend multiple factors way solve problem encourage threshold mechanism explore zero point thats safe point going necessarily reach way zero point going use parameters define alpha specifically beta parameter control deviation optimal threshold based example accounting overfitting training_data adjustment whats_interesting gamma parameter formula gamma controlling influence number examples training formula n denotes number training examples bigger actually encourage words n small try explore means seen examples sure exhausted space seen examples user data points feel probably dont gives dynamic strategy exploration right examples seen explosion going threshold closer optimal thats basic_idea approach actually working evaluation studies empirically work arbitrary utility proper lower_bound explicitly addresses exploration exploitation tradeoff kind uses zero utility threshold point safeguard exploration exploitation tradeoff going explore zero utility analogy gambling dont want risk losing money safe conservative strategy problem course approach purely zero utility lower_bound course advanced machine_learning approaches proposed solving problems active_research summarize strategies recommender_systems filtering content based looking item collaborative_filtering looking user lecture weve covered content based filtering approach lecture going talk collaborative_filtering contentbased filtering system generally solve problems related filtering decision learning system actually built based search_engine system adding threshold mechanism adding adaptive learning algorithm allow system learn longterm feedback
lecture collaborative_filtering lecture going continue discussion recommender_systems particular going look approach collaborative_filtering seen slide talked strategies answer basic question user u like item previous_lecture looked item thats contentbased lecture look user different strategy called collaborative_filtering collaborative_filtering filtering decisions individual user based judgments infer individuals interest preferences similar general idea given user u going 1st find similar users u1 going predict user preferences based preferences similar u1 user similarity judged based similarity preferences common set exact content item doesnt going look relation users means approach applied text options approach work following users interest similar second users similar preferences probably share interest user information retrieval infer user probably favor sigir_papers alright interested information retrieval research probably favor sigir_papers thats assumption assumption true help collaborative_filtering assume people favor sigir_papers infer interest probably information simple examples cases assumption actually assumption sufficiently large number user preferences example lot ratings users movies indicate preferences movies lot data collaborative_filtering problem thats called cold start means dont preferences available system afford advantage collaborative_filtering lets look collaborative_filtering problem formal way picture_shows general considering lot users showing showing m u1 um considering number objects lets n objects denoted o1 assume users able judge objects user example ratings items example items products users ratings 1 5 shown ratings available combinations users watched movies rated obviously wont able watch movies users actually watch general sparse items unknown whats_interesting potentially infer value element matrix based values thats actually central question collaborative_filtering assume theres unknown function f map pair user object observed values want infer value function pairs dont values similar machine_learning problems know values function training_data sets hope predict values function test data right function figure function based observed ratings approaches solving problem fact active_research area reason special conferences special conferences dedicated r major conference devotes
going talk basic strategy based similarity users predicting object active ratings similar users active user called memory based little similar storing user information considering particular user going try retrieve relevant users similar users user case try use user information users predict preference heres general idea use notations xij denotes rating object oj user ni average rating objects ni needed like normalize ratings objects normalization going subtract average rating normalize ratings ratings different users users generous generally given high critical ratings directly compared need prediction rating item user active based average ratings similar user ua user interested recommending items interested recommending oj interested knowing likely user like know idea look similar users user liked mathematically predicted rating user object user object oj basically combination normalized ratings different fact taking sum users contribute equally average controlled weight controls influence user course naturally way related similarity ua particular user similar contribution like user ui predicting preference ua formula extremely sum possible inside sum ratings normalized ratings explained ratings need normalized order ratings weighted imagine w similarity user whats k k simply normalizer sum means basically consider weight k coefficients weights sum normalization strategy predicted rating range ratings use right basically main_idea memory based_approaches collaborative_filtering like map rating user actually add mean rating average rating user ua predicted recover meaningful rating user generous average somewhat high add rating adjust relatively high item actually doesnt matter cause youre basically normalized rating thats meaningful evaluate collaborative_filtering typically assume actual_ratings user objects unknown prediction compare predicted ratings actual_ratings access actual_ratings pretend dont compare systems predictions actual_ratings case obviously systems prediction adjusted match actual_ratings user whats happening ok memory based course look formula want write program implement face problem determining w function right know w function formula easy different ways compute function weight w specific approaches generally differ possibilities popular approach use pearson_correlation sum commonly rated items formula standard pearson_correlation coefficient formula basically measures users tend higher ratings similar items lower ratings similar measure cosine measure treat rating vectors vectors vector_space going measure angle compute cosine angles vectors measure vector_space model imagine different cases note user similarity based preferences items actually use content information didnt matter movies book text didnt care allows approach applied wide range new approaches course like use information clearly know user preferences actual filtering system collaborative_filtering combine content based use context information interesting approaches people new approaches proposed memory based shown work reasonably easy implement practical application starting point strategy works obvious ways improve mainly like improve user similarity measure practical issues example lot missing set default values average ratings user simple solution advanced approaches actually try predict missing use predicted_values improve fact memory based approach predict missing values right imagine iterative approach preliminary prediction use predicted_values improve similarity way solve problem strategy obviously affect performance collaborative_filtering like heuristics improve similarity functions idea actually similar idea idf seen text research called inverse user iuf idea look users share similar item popular item viewed people seeing interested item interesting rare item viewed users users viewed item similar ratings says similarity right kind emphasize similarity items viewed
summarize discussion recommender_systems sense filtering task recommending task easy senses task actually difficult easy users expectations case system takes initiative push information user user effort recommendation better right recommend order noisy items useless documents recommend useful information users general appreciate thats sense thats filtering actually harder task retrieval binary decision cant afford waiting lot youre 1 item decision thing news filtering soon news decide news interesting wait accurate recommendation relevant news utility going significantly reason hard data think learning problem collaborative_filtering example purely based learning past ratings dont yeah mentioned cold start actually problem course strategies proposed solve problem different strategies use alleviate use example user information assess similarity instead preferences users items additional information available talked strategies filtering task content based look item collaborative_filtering look user similarity obviously combined practical imagine general combined hybrid strategy recall talked push_versus pull strategies getting access text data recommended system help users push mode search engines certain users pull_mode obviously tool combined combined system support user multiple mode information_access future anticipate system useful active_research area lot new algorithms proposed particular new algorithms tend use lot context context context user context documents items isolated connected users form social network theres rich context leverage order solve problem thats active_research area machine_learning algorithms additional_readings handbook called recommender_systems collection lot articles overview number specific approaches recommended
lecture summary map shows major topics covered key high level takeaway_messages talked natural_language content main takeaway message natural_language processing foundation text current nlp isnt robust bag words representation generally main method modern_search sufficient search tasks obviously complex tasks need deeper_natural language processing_techniques talked high level strategies text access talked push vs pull talked querying versus general future search engines integrate techniques provide multiple information_access talked number issues related search engines talked search problem framed ranking talked number retrieval started overview vector_space model probabilistic model talked vector_space model later talked language modeling approaches thats probabilistic model main takeaway_messages modern retrieval_functions tend look similar generally use important ones tfidf_weighting document_length normalization tf transformed sublinear_transformation talked implement retrieval main techniques talked construct inverted_index prepare system answer query talked perform search inverted_index talked evaluate text retrieval mainly introduced cranefield evaluation important evaluation methodology applied talked major evaluation measures important measures search enginemapmean average_precision ndcgnormalized discounted cumulative_gain precision_recall basic talked feedback techniques talked rocchio vector_space model mixture_model language modeling feedback important technique especially considering opportunity learning lot clickthroughs talked web_search talked use parallel indexing solve scalability indexing introduce map_reduce talked use linking information web improve talked page_rank hits major algorithms analyze links talked learning use machine_learning combine multiple features improving scoring effectiveness improved approach improve robustness ranking_function easy spam search_engine features promote finally talked future web_search talked major directions future improving current generation search finally talked recommender_systems systems implement push mode talked content based collaborative_filtering obvious missing piece picture user user interface important component search_engine current searching interface relatively simple actually lot studies user interface related visualization topic learn reading excellent book kinds studies search want know topics talked read additional_readings listed short managed cover basic topics text retrieval search resources provide additional information advanced topics gave thorough treatment topics talked main source synthesis digital lot short textbook textbooks long tutorials tend provide lot information explain topic multiple serieses related course information concepts retrieval services human language technology artificial intelligence machine_learning major journals conferences listed tend lot research_papers related topic course finally information resources including readings toolkits check taken text mining course data mining specialization series naturally step course picture_shows big text data generally need kinds techniques text retrieval covered course techniques help convert raw big text data small relevant text data actually needed specific human plays important_role mining text data becausw text data written humans consume involving humans process data mining course covered strategies help users access relevant techniques essential text mining system help provide provenance stand help users interpret patterns user find text data general user original data better understand text mining course text mining analytics course dealing user found second step picture convert text data actionable_knowledge helping users digest found information find patterns reveal knowledge buried text knowledge application system help decision_making help user finish taken course natural step natural step thank taking hope found course useful look forward interacting future
lecture overview text mining lets define term text mining term text title course called text mining analytics terms text mining text analytics actually going distinguish going use reason chosen use terms title subtle difference look phrases mining emphasizes process gives algorithmic view analytics hand emphasizes result having problem going look text data help solve said treat terms roughly think literature probably going distinguish text mining text analytics mean want turn text data high quality information actionable_knowledge cases problem dealing lot text data hope turn text data useful raw text distinguish different results high quality information actionable_knowledge boundary clear want little bit different angles result text case high quality information refer concise information topic easier humans digest raw text example face lot reviews concise form information concise summary major opinions features positive lets battery_life kind results useful help people digest text data minimize human_effort consuming text data kind output actionable_knowledge emphasize utility information knowledge discover text actionable_knowledge decision problem example able determine product appealing better choice shopping outcome called actionable_knowledge consumer knowledge decision case text mining supplies knowledge optimal decision_making clearly distinguished dont necessarily text mining related text retrieval essential component text mining text retrieval refers finding relevant information large text ive taught separate mooc text retrieval search engines discussed techniques text taken mooc find overlap useful know background text retrieval understanding topics text taken mooc fine context mining analytics going repeat key concepts relevant text high level let explain relation text retrieval text text retrieval useful text mining ways text retrieval preprocessor text mining meaning help turn big text data relatively_small relevant text data whats needed solving particular sense text retrieval helps minimize human_effort text retrieval needed knowledge provenance roughly corresponds interpretation text mining turning text data actionable_knowledge find patterns text data actionable_knowledge generally verify knowledge looking original text data users text retrieval support original text data interpret pattern better understand knowledge verify pattern high level introduction concept text mining relation text mining lets talk text data special kind interesting view text data data generated humans subjective_sensors slide_shows analogy text data non text data humans subjective_sensors physical sensors network sensor general sensor monitor real world way sense signal real world report signal data forms example thermometer watch temperature real world report temperature particular similarly geo sensor sense location report location specification example form longitude value lattitude network sensor monitor network traffic activities network report digital format similarly think humans subjective_sensors observe real world perspective humans express observed form text sense human actually subjective sensor sense whats happening world express whats observed form data case text looking text data way advantage able integrate kinds data thats needed data mining looking general problem data mining general dealing lot data world related general dealing non text data text data course non text data usually produced physical non text data different formats numerical data categorical relational data multimedia data like video non text data important text data important contain lot semantic content contain knowledge users especially preferences opinions treating text data data observed human sensors treat data data mining problem basically turn data turn data actionable_knowledge advantage change real world course means data mining problem basically taking lot data input giving actionable_knowledge inside data mining module number different kinds mining algorithms different kinds data generally need different algorithms mining example video data require computer vision understand video content facilitate effective mining lot general algorithms applicable kinds data algorithms course useful particular kind data generally want develop special course cover specialized algorithms particularly useful mining text
looking text mining problem closely problem similar general data mining focusing text going text mining algorithms help turn text data actionable_knowledge use real especially decision_making completing tasks require text data support general real world problems data mining tend kinds data non general picture include non text reason concerned joint mining text non text data course going focus text touch join analysis text data nontext_data problem definition look landscape topics text mining slide_shows process generating text data specifically human sensor human observer look world different people looking world different angles pay attention different person different time pay attention different_aspects observed human sensor perceive world sensor form view world called observed course different real world perspective person observable world represented example entity relation graphs general way knowledge representation general basically person mind world dont know exactly looks like human express person observed natural_language english result text course person different language express case text data mixed languages different main goal text mining actually revert process generating test hope able uncover aspect specifically think mining example knowledge means looking text data english able discover usage patterns 1 type mining problems result knowledge language useful look picture knowledge observed mining content text going look text data try extracting high quality information particular aspect world example said particular person particular entity regarded mining content describe observed world users mind persons look imagine knowledge text data infer properties properties include mood person sentiment note distinguish observed world person text data describe person observed objective way description subject sentiment general imagine text data contain factual descriptions world plus subjective comments thats possible text mining knowledge finally look picture left picture certainly real world right text mining infer real world variables called predictive want predict value certain interesting picture basically covered multiple types knowledge text infer real world variables use results mining text data intermediate results help example content text data generate summary content summary help predict variables real course generated original text data want emphasize processing text data generate features help prediction thats results mining tasks including mining content text data mining knowledge observer helpful fact nontext_data use nontext_data help course depends general nontext_data important prediction example want predict stock_prices changes stock_prices based discussion news_articles social_media example text data predict real world case obviously historical stock price data important prediction thats example nontext_data useful prediction combine kinds data nontext_data useful analyzing text supplying look text data looking content opinions expressed text data generally context example time location associated text data useful context context provide interesting angles analyzing text example partition text data different time periods availability analyze text data time_period similarly partition text data based locations metadata thats associated form interesting comparison sense nontext_data actually provide interesting angles perspectives text analysis help context sensitive analysis content language usage opinions observer authors text analyze sentiment different context fairly general landscape topics text mining course going selectively cover actually hope cover general going cover natural_language processing briefly understanding text data determines represent text text second going talk word_associations text data word_associations form useful lexical knowledge going talk topic mining analysis way analyze content text useful way analyzing useful techniques text going talk opinion_mining sentiment_analysis regarded example mining knowledge finally going cover text based prediction problems try predict real world variable based text slide serves road map use outline topics cover rest
lecture naturallanguage content natural_language content analysis foundation text going particular natural_language factor represent text data determines algorithms analyze text going look basic concepts natural_language im going explain concepts simple example dog chasing boy simple read sentence dont think computer understand sentence computer computer needs know words segment english easy look space computer need know categories words syntactical example dog noun chasing verb boy noun called lexical particular tagging words syntactic categories called speech_tagging computer needs figure relation dog form noun_phrase playground prepositional_phrase certain way connected order generate combinations called syntactic syntactical analysis parsing natural_language outcome parse_tree youre_seeing tells structure sentence know interpret order meeting map phrases structures real world entities dog concept know boy concept connecting phrases know computer formally represent entities dog d1 means d1 dog boy b1 means b1 refers boy represented chasing action chasing predic arguments d1 b1 p1 playground right formal representation semantics reach level understanding example assume theres rule says chased person scared infer boy inferred meaning based additional finally infer sentence requesting person said sentence saying understanding purpose saying sentence called speech act analysis pragmatic refers use case person saying reminding person bring means saying sentence person actually takes action slide clearly shows order understand sentence lot things general hard computer especially wanted main reason natural_language processing difficult designed human communications result example omit lot common_sense knowledge theres need encode makes communication lot ambiguities like ambiguities assume ability disambiguate word theres problem having word mean possibly different things different computer difficult computer common_sense knowledge computer confused makes hard natural_language makes hard step slide showed ambiguity main killer meaning step multiple choices computer decide whats right choice decision difficult general need common_sense order fully understand natural_language computers today dont thats hard computers precisely understanding natural_language specific examples think word level ambiguity word like design noun verb weve_got ambiguous speech root multiple mathematical sense like square root syntactic ambiguity refers different interpretations sentence terms example natural_language processing actually interpreted ordinary meaning talking topic processing natural_language possible interpretation language processing dont generally problem imagine computer determine structure computer actually classic example man saw boy ambiguity lies question called prepositional_phrase attachment ambiguity attach prepositional_phrase telescope modify boy modifying saw verb problem anaphora resolution john persuaded bill buy referred john bill pre supposition quit smoking implies smoked need knowledge order understand problems state art natural_language processing_techniques perfectly simplest speech_tagging solve accuracy listed 97 taken studies earlier studies obviously particular datasets numbers meaningful context data set evaluation numbers need sense accuracy things doesnt mean data set accuracy precisely general speech_tagging fairly parsing difficult partial_parsing meaning phrases correct probably achieve 90 better complete parse_tree correctly semantic_analysis aspects semantic_analysis particularly extraction entities example recognizing person thats location person person met place word sense_disambiguation figure occurrence root sentence refers mathematical sense sentiment_analysis aspect semantic_analysis means tag sentences general positive talking talking influence hard generally big domain feasible limited thats generally difficult problem artificial speech act analysis difficult properly specialized cases lot help annotate data computer slides shows computers far able understand natural_language precisely explains text mining problem difficult rely mechanical approaces computational methods understand language use today particular statistical machine_learning statistical analysis methods try meaning text later actually algorithms extract interesting knowledge text fully understand meaning natural_language sentences
specific examples cant today speech_tagging easy percent example turned highway versus turned fan offs actually somewhat different syntactic difficult complete parsing example man saw boy telescope actually difficult parse depending precise deep semantic_analysis example define meaning precisely difficult sentence like john owns state art summarized robust general nlp tends shallow deep understanding reason course techniques cover general shallow techniques analyzing text data text generally based statistical analysis robust general category shallow analysis techniques advantage able applied text data natural_language downside dont deeper understanding rely deeper_natural language analysis typically require human_effort annotate lot examples analysis wed like computers use machine_learning techniques learn training examples practical applications generally combine kinds techniques general statistical methods backbone basis applied text data going use humans annotate data use supervised_machine learning tasks especially important bring humans loop analyze fix analyze text data course cover general statistical approaches generally dont require human_effort practically useful deeper analysis techniques require lot human_effort annotate text summarize lecture main points away nlp foundation text obviously better understand text data better text computers today far able understand natural_language deeper nlp requires common_sense knowledge inferences working limited feasible large_scale text shallow nlp based statistical methods large_scale main topic course generally applicable lot sense useful practice use statistical nlp humans help needed
lecture text lecture going discuss text discuss natural_language processing allow represent text different lets look example represent sentence different represent sentence string true languages store store natural_language sentence string characters general way representing text use approach represent text unfortunately representation help semantic_analysis needed applications text reason recognizing string going spaces ascii whats frequent character english text correlation characters cant analyze general way representing text use represent natural_language try little bit natural_language processing word obtain representation text form sequence identify words like dog chasing level representation certainly lot things mainly words basic units human communication natural_language identifying words example easily count frequent words document collection words form combine related words words positive words negative sentiment_analysis representing text data sequence words opens lot interesting analysis level representation slightly general string characters languages chinese actually easy identify word boundaries language text sequence characters rely special techniques identify language course mistakes segmenting sequence words representation robust string english easy obtain level representation natural_language processing add speech count example frequent nouns kind nouns associated kind verbs opens little bit interesting opportunities note use plus sign representing text sequence speech dont necessarily replace original word sequence representation instead add additional way representing text data data represented sequence words sequence speech enriches representation text data enables interesting parsing sentence obtain syntactic course open interesting analysis example writing styles correcting grammar semantic_analysis able recognize dog animal recognize boy person playground analyze relations example dog chasing boy boy add entities relations entityrelation level interesting example count easily frequent person thats mentioned collection news_articles mention person tend mention person useful representation related knowledge_graph google semantic way representing text robust sequence words syntactic analysis easy identify entities right types mistakes relations harder find makes level representation robust logical representation predicates inference_rules inference_rules infer interesting derived facts thats useful unfortunately level representation robust mistakes cant time kinds finally speech acts added level representation intent saying case knowing allow analyze interesting things observer author sentence whats intention saying scenarios kind level analysis picture_shows generally sophisticated natural_language processing_techniques unfortunately techniques require human_effort means analyze text data levels represented deeper analysis language tolerate means necessary combine deep analysis shallow analysis based example sequence right arrow points indicate representation text closer knowledge representation mind need solving lot desirable represent text level knowledge easily extract thats purpose text trade deeper analysis errors direct knowledge extracted text shallow analysis wouldnt actually necessary deeper representation text data generated humans meant consumed humans result text data analysis text mining humans play important_role meaning optimize collaboration humans sense ok computers able completely accurate representation text data patterns extracted text data interpreted humans humans guide computers accurate analysis annotating data providing features guide machine_learning programs work
explained different textual representation tends enable different particular gradually add deeper analysis results represent text data open interesting representation opportunities analysis table summarizes column shows text recognition second visualizes generality representation meaning kind representation accurate text data column shows enabled analysis final column shows examples application achieved level lets string text processed stream processing algorithms robust interesting applications example compression text doesnt necessarily need know word knowing word boundaries actually word based representation important level general relatively enable lot analysis techniques word relation analysis topic analysis sentiment_analysis applications enabled kind example thesaurus discovery discovering related words topic opinion related applications abundant example people interested knowing major topics covered collection research literature scientist want know important research topics today customer service people want know major_complaints customers mining email_messages business intelligence people interested understanding consumers opinions products competitors products figure winning features general applications enabled representation moving gradually add additional adding syntactic_structures enable course syntactic graph use graph mining algorithms analyze syntactic applications related kind example stylistic analysis generally requires syntactical syntactical structure generate structure based feature features features help classify text objects different looking structures classification example want classify articles different categories corresponding different authors want figure k authors actually written generally need look syntactic_structures add entities relations enable lot techniques knowledge_graph analysis information network analysis general analysis enable applications entities example discovery knowledge opinions real world energy use level representation integrate entity scattered finally add logic predicates enable logic inference ofcourse useful integrative analysis scattered example add ontology extracted information text good example application enabled level representation intelligent knowledge assistant intended program help biologists manage relevant knowledge literature research problem understanding functions computer inferences hypothesis biologists interesting example gene certain function intelligent program read literature extract relevant information extraction logical system actually track thats answers researchers questioning genes related order support level application need far logical course covering techniques mainly based word based techniques general robust widely fact virtually text mining applications need level representation techniques support analysis texting obviously levels combined combined order support sophisticated summarize major takeaway text representation determines kind mining algorithms multiple ways represent text strings words syntactic_structures relation graphs logical predicates different representations general combined real applications example accurately application syntactic_structures stick partial structures extracted recognize entities general different levels combined enable richer powerful course focuses word based techniques general robust applicable natural_language thats big advantage approaches rely fragile natural_language processing_techniques secondly require manual effort require manual thats important benefit means apply directly techniques actually surprisingly powerful effective course effective partly words invented humans basic units actually sufficient representing kinds makes kind word based representation finally word based representation techniques enabled representation combined sophisticated theyre
lecture word association mining lecture going talk associations words example knowledge natural_language text heres gooing talk word association explain discovering relations useful finally going talk general ideas word_associations general word relations called paradigmatic_relation syntagmatic_relations aampb paradigmatic_relation means words paradigmatic_relation semantic class syntactic class general replace affecting understanding means valid example cat words paradigmatic_relation class general replace cat dog sentence sentence valid sentence similarly monday tuesday paradigmatic_relation second kind relation called syntagmatic case words relation aampb syntagmatic relation combined means words semantically_related example cat sit related cat similarly car drive related semantically combined convey general replace cat sit sentence car drive sentence valid meaning sentence somewhat different paradigmatic_relation relations fact fundamental generalized capture basic relations units arbitrary definitely generalized describe relations items aampb dont words phrases complex phrases noun_phrase think general problem sequence mining think units sequence data think paradigmatic_relation relations applied units tend occur similar locations sentence sequence data elements occur similar locations relative neighbors syntagmatic relation hand related cooccurring elements tend complementary basically relations words interested discovering automatically text discovering world relations relations directly useful improving accuracy nlp tasks knowledge know words synonyms example help lot grammar learning techniques learn paradigmatic relations form classes syntactic classes learn syntagmatic_relations able know rules putting larger expression based component learn word relations useful applications text retrieval example search text retrieval use word_associations modify introduce additional related words query query called query use related words suggest related queries user explore information application use word_associations automatically construct topic map browsing words nodes associations user navigate word find information information finally word_associations compare summarize example interested understanding positive negative opinions iphone_6 order look words strongly associated feature word like battery positive versus negative syntagmatic_relations help detailed opinions discover associations automatically lets look paradigmatic_relation essentially advantage similar simple sentences cat generally occur similar definition paradigmatic_relation right extracted explicitly context cat dog small sample text taken away cat dog corresponding sentences course different perspectives look example look words occur left left words occur cat cat case clearly dog cat similar left generally cat cat dog makes similar left similarly look words occur cat dog right context similar case course extreme case eats general course follow cat look general improve words sentence sentences general context similarity suggesting discover paradigmatic_relation looking similarity context example think following questions similar context cat context dog contrast similar context cat context computer intuitively imagine context cat context dog similar context cat context computer means case similarity value context cat dog second similarity contexts cat computer low having paradigmatic imagine words occur general different words occur basic_idea discovering paradigmatic_relation syntagmatic relation going explore correlated occurrences based definition syntagmatic sample interested knowing words correlated verb words eat look right slide ive taken away words ive taken away word left world right ask question words tend occur left eat words tend occur right eat thinking question help discover_syntagmatic syntagmatic relation essentially captures important question ask syntagmatic relation eats occurs words tend occur question words tend cooccur eats meaning eat tend dont eat probably dont intuition help discover_syntagmatic consider example helpful occurrence eats predicting occurrence meat knowing eats occurs sentence generally help predict meat_occurs eats occur sentence increase chance meat contrast look question helpful occurrence eats predicting occurrence text eats text related knowing eats occurred sentence doesnt help predict text occurs contrast question eats helps explain intuition methods discovering_syntagmatic mainly need capture correlation occurrences summarize general ideas discovering word_associations paradigmatically relation represent word context compute context gonna assume words high context similarity paradigmatic_relation syntagmatic relation count times words occur context sentence paragraph going compare co_occurrences individual going assume words high cooccurrences relatively low individual occurrences syntagmatic_relations tend occur dont usually note paradigmatic_relation syntagmatic relation actually closely paradigmatically_related words tend syntagmatic relation word tend associated word suggests join discovery general ideas implemented different ways course wont cover cover methods effective discovering
lecture paradigmatic_relation lecture going talk discover particular kind word association called paradigmatic definition 2 words paradigmatically_related share similar occur similar positions naturally idea discovering relation look context word try compute similarity heres example context word taken word cat seeing remaining words sentences contain thing word like general like capture context try assess similarity context cat context word like question formally represent context define similarity function note context actually contains lot regarded pseudo imaginary different ways looking example look word occurs word context left1 case words like big words occur left world cat cat big cat similarly collect words occur right word context words eats ate generally look words window text word lets window words world context window8 course words left right bag words general represent word based representation actually interesting way define perspective measuring look similarity left1 words share words left context kind ignore words general gives perspective measure similarly use right1 context capture similarity left1 right1 ofcourse allow capture similarity strict general context contain adjacent words like eats nonadjacent words like saturday tuesday words flexibility allows measure similarity similarity different useful want capture similarity based general content loosely related paradigmatic relations use words immediately left right world likely capture words related syntactical categories general idea discovering paradigmatic relations compute similarity context example measure similarity cat dog based similarity general combine kinds views context similarity function general combination similarities different course assign weights different similarities allow focus particular kind context naturally application specific main_idea discovering paradigmatically_related words compute similarity lets exactly compute similarity answer question useful think bag words representation vectors vector_space familiar information retrieval text retrieval techniques realize vector_space model frequently modeling documents queries find convenient model context word paradigmatically relation_discovery idea approach view word vocabulary defining dimension high dimensional_space n words total n_dimensions frequency vector representing eats occured times context ate occurred times vector placed vector_space general represent pseudo document context cat word dog different context measure similarity viewing context vector_space model convert problem paradigmatic relations discovery problem computing vectors questions address compute vector compute xi yi question compute similarity general approaches solve problem developed information shown work matching query vector document vector adapt ideas compute similarity context documents lets look possible approach try measure similarity context based expected overlap words idea represent context award vector word weight equal probability randomly picked word document vector xi defined normalized count word wi interpreted probability actually pick word d1 randomly pick course xis sum 1 normalized means vector actually probability distribution vector d2 computed probability distributions representing addresses problem compute vectors lets define similarity simply define similarity dot_product vectors defined sum products corresponding_elements interesting similarity function actually nice dot_product infact gives probability randomly picked words contexts identical means try pick word context try pick word context ask question identical contexts similar expect frequently words picked contexts different chance seeing identical words picked contexts intuitively_makes sense measuring similarity want look exact formulas interpreted probability randomly picked words stay formula check whats inside sum basically case gives probability overlap particular word wi xi gives probability pick particular word d1 yi gives probability picking word d2 pick word contexts identical alright thats possible eowc expected overlap words like assess approach course ultimately test approach real data gives semantically_related words paradigmatic analytically analyze formula little said sense right formula higher score overlap thats exactly analyze formula carefully potential specifically potential favor matching frequent_term matching distinct terms dot_product element high value element shared context contributes lot overall score higher case vectors actually lot overlap different terms term relatively low course desirable cases case intuitively prefer case match different terms context confidence saying words occur similar rely term thats little bit second problem treats word equally match word like match matching word like intuitively know matching isnt surprising occurs matching strong evidence matching word like eats doesnt_occur problem lecture going talk address
lecture continue_discussing paradigmatic_relation earlier introduced method called expected overlap words method represent context word vector represents probability word context measure similarity dot_product interpreted probability randomly pick words contexts identical discuss problems favors matching frequent_term matching distinct emphasis matching second treats word common word like contribute equally content word like going talk solve specifically going introduce retrieval heuristics text retrieval heuristics effectively solve problems problems occur text retrieval match query vector document address problem use sub_linear transformation term_frequency dont use raw frequency count term represent transform form wouldnt emphasize raw address second problem weight rare reward matching rare word heuristic called idf term weighting text idf stands inverse_document going talk heuristics lets talk tf convert raw_count word document weight reflects belief important word denoted tf wampd shown y general ways map lets look simple way case going non zero counts zero count mapped mapping frequencies mapped values zero mapping function shown flat naive ignored frequency actually advantage emphasizing matching words context allow frequent word dominate approach taken earlier expected overlap account approach linear basically y use raw_count created problem answers matching frequent_term matching frequent_term contribute lot interesting transformations generally form sub_linear example possibility logarithm raw_count curve looks like right youre_seeing case high frequency counts high counts penalized little bit right curve sub_linear curve brings weight high want prevents kind terms dominating scoring_function interesting transformation called bm25 transformation shown effective retrieval transformation looks saw k_1 x x k k x count raw_count transformation interesting actually kind extreme extreme varying interesting upper_bound k_1 puts strict constraint high frequency terms weight exceed vary k simulate case set roughly 01 set key large value behave like linear transformation function far effective transformation function text retrieval makes sense problem talk solve problem emphasizing frequently frequent_term lets look second problem penalize popular matching surprising occurs matching eats account address problem case use idf_weighting thats commonly idf stands inverse_document document frequency means count total_number documents contain particular idf measure defined logarithm function number documents match term document k number documents containing word document frequency m total_number documents idf function giving higher value lower k meaning rewards rare_term maximum value log m thats word occurs thats rare_term rarest term lowest value k reaches maximum low value close 0 course measure search naturally case collection use context collect words collection word thats popular collection general low depending data set construct context vectors different ways end term frequently original data set frequently collected context add heuristics similarity heres way ways reasonable way adapt bm25 retrieval model paradigmatic_relation define case define document containing elements representing normalized bm_25 normalization function sum words normalize weight word sum weights ensure xi sum similar vector actually similar word distribution exercise weight bm25 word compare old definition normalized right document_length total count words context bm_25 transformation course extra occurrence count achieve sub_linear introduce parameter parameter generally non negetive number zero controls upper_bound kinds controls choose extent simulates linear 1 parameter b parameter control length_normalization case normalizing formula average document_length computed taking average lengths documents case lengths context documents average documents constant given collection actually affecting effect parameter kept constant thats useful retrieval stabilized interpretation parameter purpose constant affecting length formalization parameter definition new way define document vectors compute vector d2 difference high frequency terms somewhat lower weights help control influence high frequency idf added scoring_function means introduce weight matching recall sum indicates possible words overlap xi yi probabilities picking word contexts indicates likely match idf importance matching common word worth rare word emphasize matching rare modification new function likely address interestingly use approach discover_syntagmatic general represent term vector represent sorry represent context term vector likely terms higher weights terms lower weights depending assign weights terms able use weights discover words strongly associated candidate word lets look term vector xi defined normalized weight bm_25 weight reflects frequently word occurs cant frequent_term context correlated candidate common words like occur frequently apply idf_weighting weight terms based idf means words common like highest weighted terms common terms lower instead terms terms frequent context frequently clearly words tend occur context candidate word example reason highly weighted terms idf weighted vector assumed candidate syntagmatic_relations course biproduct approach discovering paradigmatic lecture going talk discover_syntagmatic clearly shows relation discovering discussed discovered joint manner leveraging summarize main_idea discovering paradigmatic relations collect context candidate word form pseudo document typically represented bag compute similarity corresponding context documents candidate highly similar word pairs treat having paradigmatic words share similar different ways implement general idea talk specifically talked text retrieval models help design_effective similarity function compute paradigmatic specifically bm25 idf_weighting discover paradigmatic_relation approaches represent state art text retrieval finally syntagmatic_relations discovered biproduct discover paradigmatic
lecture syntagmatic relation_discovery lecture going continue talking word association particular talk discover_syntagmatic going start introduction entropy basis designing measures discovering definition syntagmatic_relations hold words correlated co_occurrences means word occurs context tend occurrence specific example ask question eats occurs words tend looking sentence words occur eats like cat dog fish look right eats question predict words occur left right force think words associated associated eats tend occur context specifically prediction problem text segment sentence paragraph document asked question particular word present absent right ask question world w present absent whats_interesting words actually easier look words shown meet think easier predict think moment easier predict tends occur unicorn relatively unicorn rare bet doesnt_occur meat terms frequency makes hard predict possible occurs sentence segment occur lets start problem alright problem formally defined predicting value binary random_variable denoted x sub w w denotes random_variable associated precisely value variable 1 means word zero means word absent naturally probabilities zero sum word present absent theres intuition discussed_earlier formally stated random random_variable difficult question quantitatively measure randomness random_variable like x sub w general quantify randomness variable thats need measure called measure introduced information theory measure randomness connection information thats scope purpose treat entropy function function defined random_variable case binary random_variable definition easily generalized random_variable multiple function form looks theres sum possible values random_variable inside sum value product probability random_variable equals value log note negative entropy general negative mathematically expand sum equation looks like second explicitly plugged values 0 log 0 generally find zero log 0 entropy function function different value different distributions random_variable clear clearly depends probability random_variable taking value plotted function probability random_variable equal 1 function looks ends means probability x 1 small large entropy function lower 5 middle reaches plot function probability x taking value 0 function exactly imagine thats probabilities symmetric completely interesting think general kind x entropy reached maximum minimum particular think special_cases example case random_variable takes value probability random_variable equally_likely taking value 1 case probability x higher entropy easier look problem thinking simple coin tossing think random experiment like tossing coin gives random_variable represent head tail define random_variable x sub coin coin_shows head zero coin_shows compute entropy random_variable entropy indicates difficult predict outcome coin coin think fair_coin completely coin_shows head hotel equally_likely probabilities 12 right equal extreme case completely_biased coin coin_shows head completely_biased lets think entropies cases plug values entropies follows fair_coin entropy reaches maximum completely_biased coin 0 intuitively_makes lot sense fair_coin difficult predict completely_biased coin easy predict head head time shown curve fair_coin corresponds middle point completely_biased coin corresponds end probability 0 entropy lets use entropy word problem lets think problem right predicted w present absolutely think particularly think assume high entropy words harder quantitative way tell word harder look words meat clearly expect meat high entropy fact look entropy close 0 like completed biased coin entropy
lecture syntagmatic relation_discovery conditional_entropy lecture going continue discussion word association mining going talk conditional_entropy useful discovering_syntagmatic earlier talked entropy capture easy predict presence absence address different scenario assume know text question suppose know eats occured segment help predict presence absence word like meat particular want know presence eats helped predict presence frame entropy mean interested knowing knowing presence eats reduce uncertainty meat reduce entropy random_variable corresponding presence absence ask question know absence eats help predict presence absence questions concept called conditional_entropy explain concept lets look scenario know probabilities indicating word like meat_occurs occur segment entropy function looks like suppose know eats present know value random_variable denotes change probabilities conditional probabilities look presence absence given know eats occured result replace probabilities corresponding conditional probabilities entropy function conditional_entropy conditional_entropy conditioned presence right essentially entropy function seen probabilities tells entropy meat known eats occurring course define conditional_entropy scenario dont know eats occur segment conditional_entropy capture uncertainty meat content putting different scenarios complete definition conditional_entropy going consider scenarios value eats zero gives probability eats equal 0 basically eats present absent course entropy conditional_entropy meat particular expand entropy following involvement conditional general discrete random variables conditional_entropy larger entropy variable x basically upper_bound conditional_entropy means knowing information segment wont able increase reduce uncertainty intuitively_makes sense know information prediction hurt prediction whats_interesting think whats minimum possible value conditional_entropy know maximum value entropy minimum think hope reach conclusion minimum possible value 0 interesting think situation lets use conditional_entropy capture syntagmatic_relations course conditional_entropy gives directly way measure association tells extent predict word given know presence absence look intuition conditional_entropy capturing syntagmatic_relations useful think special case listed conditional_entropy word listed conditional_entropy means know meat_occurs sentence hope predict meat_occurs course zero theres uncertain anymore know word occurs segment know answer thats conditional_entropy reaches lets look knowing trying predict meat case knowing eats trying predict think smaller note smaller entropy means easier think higher smaller look uncertainty case doesnt tell meat knowing occurrence doesnt help reduce entropy match stays fairly close original entropy case eats eats related meet knowing presence eats absence eats help predict wether meat_occurs help reduce entropy meat expect second term smaller means stronger association meat know w meat entropy conditional_entropy reach minimum 0 kind words reach maximum thats w related like example close maximum entropy suggests use conditional_entropy mining syntagmatic_relations algorithm look word w1 going enumerate overall words w2 compute conditional_entropy w1_given thought candidate words ascending order conditional_entropy want favor word small entropy meaning helps predict target word w1 ranked candidate words words potential syntagmatic_relations note need use threshold find threshold number candidates absolute value conditional_entropy allow strongly_correlated words particular word algorithm help strongest k syntagmatic_relations entire order ensure conditional entropies comparable different case discovering_syntagmatic relations target word like w1 need compare conditional entropies w1_given different case comparable right conditional_entropy w1_given w2 conditional_entropy w1_given w3 measure hard predict think pairs share w2 condition try predict w1ampw3 conditional entropies actually think question comparable different upper bounds right upper bounds precisely entropy w1 entropy different upper bounds compare address problem later discuss use mutual_information solve
lecture syntagmatic relation_discovery mutual_information lecture going continue_discussing syntagmatic relation_discovery particular going talk concept information theory called mutual_information discover_syntagmatic relations talked problem conditional_entropy conditional_entropy computed different pairs words comparable makes hard discover strong syntagmatic_relations globally going introduce mutual_information concept information theory allows sense normalize conditional_entropy comparable different particular mutual_information denoted ixy measures entropy reduction x obtained knowing specifically question interested reduction entropy x obtain knowing mathematically defined difference original entropy x conditional_entropy x given defined reduction entropy y knowing normally conditional entropies hxy hyx interestingly reduction entropy knowing actually equal quantity called mutual_information denoted function interesting non easy understand becausw original entropy going lower possibly reduced conditional_entropy words conditional_entropy exceed original knowing information help potentially wont hurt predicting second property symmetric conditional_entropy mutual_information property reaches minimum zero random variables completely means knowing doesnt property verified simply looking reaches 0 conditional_entropy x given y exactly original entropy means knowing help thats xampy completely fix x rank different ys conditional_entropy order ranking based mutual_information function h x fixed x ranking based mutual_information exactly ranking based conditional_entropy x given mutual_information allows compare different pairs xampy thats mutual_information general general lets examine intuition mutual_information syntagmatic relation question ask syntactic relation mining eats occurs words tend occur question framed mutual_information question higher mutual_information going compute mutual_information eats basically based intuition conditional_entropy words strongly associated tend high mutual_information words lower mutual_information mutual_information eats meats meats eats cause major information symmetric expected higher mutual_information knowing doesnt help predict similarly knowing eats doesnt help easily mutual_information word largest equal mutual entropy case reduction maximum knowing allow predict completely conditional_entropy mutual_information reaches going larger equal mutual_information eats words picking word computing mutual_information eats word wont mutual_information larger mutual_information lets think compute mutual_information use different form mutual_information mathematically write mutual_information form shown slide essentially formula computes whats called kldivergences callback labeler term information theory measures divergance look formula sum combinations different values random variables inside sum mainly comparison 2 joint numerator joint actual join distribution random denominator interpreted expected joint distribution random random variables independent joined distribution equal product comparison tell variables independent independent numerator different denominator mean variables independent helps measure sum simply consideration combinations values random case random_variable choose values 0 1 look form mutual_information shows mutual_information measures diversions actual joint distribution expected distribution independence_assumption larger divergence higher mutual_information lets look exactly probabilities involved formula mutual_information listed probabilities involved easy verify basically 2 probabilities corresponding presence absence w1 probabilities sum 1 word present absent similarly second word probabilities representing presence absence word finally lot joint probabilities represented scenarios cooccurrences right sums 1 words possible case variables value cases random variables equal 1 finally scenario variables taking value theyre summing 1 probabilities involved calculation mutual_information know calculate probabilities easily calculate mutual_information interesting note relations constraints probabilities saw previous slide seen marginal probabilities words sum seen constraint says words different scenarios co_occurrences additional constraints example means add probabilities observe words occur probabilities word word occurs second word doesnt_occur exactly probability word words word observed word observed scenarios depending weather second word probability captures scenario signal word actually captures second scenario seond word observed easy equations follow equations allow compute probabilities based simplify specifically know probability word present case right know presence probability presence second word easily compute absence probability right easy use care computation probabilities presence absence lets look joint distribution right lets assume available probability easy actually compute rest probabilities specifically example equation compute probability word occurred second word know probabilities similarly equation compute probability observe second probability calculated equation known known known right easier right slide_shows need know compute probabilities shown boxes presence word co occurrence words
general use empirical counts events observed data estimate commonly technique called maximum_likelihood estimate simply_normalize observed compute probabilities follows estimating probability word occurring segment simply_normalize counts segments contain lets look right listed hypothesizes data segments words indicator cases word occurs column column course cases words occur estimating probabilities simply need collect counts 1st count 1 thats total_number segments contain world ones column w count ones second counter word 2 count ones second total_number segments contain account words occurred time going count segments columns total_number segments seen w counts counts n total_number segments probabilities need compute mutual_information small zero counts case dont want zero probability data maybe small sample general believe potentially possible award occur address problem use technique called smoothing thats basically add small constant discounts dont zero probability best way understand smoothing imagine observed data pretend observe pseudo segments illustrated right slide pseudo segments contribute additional counts words event zero probability particular introduce pseudo weighted represent different combinations occurrences event combination count non zero pseudo actual segments observed ok havent observed specifically actually comes ones pseudo segments weighted 14 05 comes single pseudo segment indicates words course denominator add total_number pseudo segments case added 4th weighted 14 total sum thats denominator basically concludes discussion compute mutual_information use syntagmatic relation_discovery summarize select cinematic relation generally discovered measuring correlations occurrences introduce concepts information theory entropy meshes uncertainly random_variable x conditional_entropy measures entropy given mutual_information xampy matches entropy reduction knowing entropy reduction knowing eggs concepts actually useful thats spend time explain detail particular useful discovering_syntagmatic particular mutual_information principled way discovering allows values computer different pairs words comfortable rank pairs discover strongest cinematical relationship collection note relation syntactic medical relation_discovery paradigmatically relation_discovery discussed possibility bm_25 achieve waiting terms context potentially suggest candidates seen like medical relations candidate use mutual_information discover_syntagmatic relations represent context mutual_information way represent word like cat words cluster words computer similarity words based context provides way term waiting relation_discovery summarize word association mining introduce basic associations called paradigmatic syntagmatic_relations fairly applied items language units dont worse phrases introduced multiple statistical approaches discovering showing pure statistical approaches visible available discovering kinds relations combined join approaches applied text helmet human_effort based counting actually discover interesting relations use different ways define context segment lead interesting variations example context narrow like words word sentence maybe paragraphs different contexts allows discover different flavors paradigmatic similarly counting co_occurrences lets mutual_information discover_syntagmatic relations define segment segment defined arrow text window longer text article different kinds discovery associations applications information retrieval text data recommended want know topic 1st book chapter locations relevant topic second article statistical measures discover lexical phrases non composition compositional example hot dog dog thats blue chip chip thats blue paper discussion techniques discovering new paper unified way discover paradigmatic_relation select medical relations random walks world
lecture topic mining going talk motivation task lecture going talk different type mining roadmap covered mining knowledge covered mining knowledge language discovery word_associations paradigmatic relations relations syntagmatic_relations starting lecture going talk mining kind knowledge content mining trying discover main topic mining lecture going talk motivation task lets look concept topic understand think actually easy formally roughly speaking topic main_idea discussed text data think theme subject discussion different example talk topic topic article topic paragraph topics research articles digital different granularities topics obviously different applications require discovery topics text example interested knowing twitter users talking today talking nba sports talking international events interested knowing research example interested knowing current research topics data mining different years involves discovery topics data mining literatures want discover topics todays literature interested knowing people like product like iphone_6 dislike involves discovering topics positive opinions iphone_6 negative interested knowing major topics debated 2012 presidential election discovering topics texts analyzing going talk lot general view topic knowledge text expected discover number topics topic generally provide description world tells world product person nontext_data context analyzing example know time associated text data locations text data produced authors text sources text meta data context variables associated topics use context variables help analyze patterns example looking topics overtime able discover theres trending topic topics fading similar looking topics different locations know insights peoples_opinions different thats mining topics lets look tasks topic mining general involve discovering lot case k like know topics covered documents document topic 1 covered lot topic 2 topic k covered small topics document 2 hand covered topic 2 cover topic 1 covers topic k right generally different tasks discover k topics collection text k topics ok major topics text second task figure documents cover topics formally define problem input collection n text denote text denote text article di generally need input number topics techniques automatically suggest number topics techniques discuss useful techniques need specify number output k topics like discover denoted theater sub theta_sub want generate coverage topics document d sub denoted sub j sub j probability document d sub covering topic theta_sub obviously document set values extent document covers assume probabilities sum document wont able cover topics outside topics discussed question define theta_sub define topic problem completely defined define exactly lectures going talk different ways define
lecture topic mining going talk term slide seen_earlier lecture defined task mining raised question exactly define topic theta lecture going offer way define thats initial idea define topic simply term word general use terms describe topics thought define topic example terms like sports travel define topic way analyze coverage topics example want discover extent document 1 covers sports found 30 content document 1 12 travel discover document 2 cover sports coverage zero course task definition topic mining analysis tasks discover topics 2nd analyze lets think discover topics represent topic means need k topical terms course different going talk natural way likely going parse text data collection obtain candidate candidate terms words lets simplest solution word words candidate going design scoring_function measure good term design function things example use pure statistics design scoring_function intuitively like favor representative terms meaning terms represent lot content mean want favor frequent_term simply use frequency design scoring_function highest scored terms general terms functional terms like terms frequent want avoid having words want penalize words general like favor terms fairly frequently particular approach based tfidf_weighting tf stands term_frequency idf stands inverse_document frequency talked ideas lectures discovery word_associations statistical methods meaning function defined based scoring_function applied language apply approach particular problem able leverage domain specific example news favor title actually general want favor title words becauses authors tend use title describe topic dealing tweets favor hashtags invented denote naturally hashtags good candidates representing designed scoring_function discover k topical terms simply picking k terms highest course encounter situation highest scored terms semantically similar closely related thats desirable want coverage content like remove redundancy way greedy algorithm called maximal marginal relevance basically idea list based scoring_function gradually terms collect k topical term course picked pick going look terms picked try avoid picking term thats considering ranking term list consider redundancy candidate term respect terms thresholding balance redundancy removal high score ok k topical terms regarded topics discovered lets think compute topic coverage pi sub j looking picture sports travel science topics suppose given document figure coverage topic document approach simply count occurrences example sports occurred times document travel occurred twice etc counts estimate coverage probability general formula collect counts terms represented topics simply_normalize coverage topic document forms distribution topics document characterize coverage different topics think idea solving problem ask question good best way solving problem lets examine general empirical evaluation actual datasets case lets look simple text document nba basketball terms content simply count words represent topics find word sports actually occur article content count sports means coverage sports estimated term science occur document estimated thats ok sports certainly cause know content estimate whats worse term travel actually occurred document estimate coverage topic travel gotten nonzero count estimated coverage non obviously simple example illustrates problems count words belong topic need consider related cant simply count word case occur related words like basketball game need count related second problem word like star actually probably means basketball star imagine mean star case star actually suggest topic need finally main restriction approach term describe topic describe complicated example specialized topic hard describe word phrase need use words example illustrates general problems approach treating term lacks expressive power meaning represent symbol general represent complicated topics require words second incomplete vocabulary coverage meaning topic represented suggest terms related topic talking sports terms related allow easily count related terms contributing coverage finally theres problem word sense ambiguation topical term related term example basketball star versus star lecture going talk solve problem probabilistic modeling
lecture probabilistic topic models topic mining lecture going continue talking mining going introduce probabilistic topic slide seen_earlier discussed problems term solve problems intuitively need use words describe topic address problem lack expressive words use describe topic describe complicated topics address second problem need introduce weights allow distinguish subtle_differences topics introduce semantically_related words fuzzy finally solve problem word ambiguity need split ambiguous word disambiguate turns probabilistic topic model thats going spend lot lectures talk basic_idea improved representation topic word old representation represent topic word term going use word distribution describe sports going use word distribution theoretical speaking words example high probability words sports game basketball football play star sportsrelated terms course non zero probability words like travel related general related general imagine non zero probability words words relevant small probabilities probabilities forms distribution intuitively distribution represents topic sample words distribution tend words special case probability_mass concentrated entire lets sports basically degenerates simple representation topic distribution topic representation general involve words describe topic model subtle_differences semantics similarly model travel science respective distribution travel words like attraction trip flight hotel science scientist spaceship telescope genomics new sciencerelated terms doesnt mean sportsrelated terms necessary zero probabilities science general imagine non zero probabilities particular topic words small words shared shared means probability threshold word occur multiple case marked black travel example occured topics different highest probability travel topic smaller probabilities sports science makes similarly star occurred sports science reasonably high_probabilities actually related representation addresses problems mentioned uses multiple words describe topic allows describe fairly complicated second assigns weights terms model differences semantics bring related words model probabilities word different disambiguate sense word text decode underlying topic address problems new way representing course problem definition refined slide similar seen added refinement topic word word distribution know probabilities sum words constraint constraint topic coverage pis ijs sum solve problem lets look problem computation clearly specify input output input course text data c collection generally assume know number topics k hypothesize number try k topics dont know exact topics exist collection vocabulary set words determines units treated basic units cases use words analysis means word output consist set topics represented theta thetai word want know coverage topics document thats piijs given set text data like compute distributions coverages seen course different ways solving write heuristic program solve problem going introduce general way solving problem called generative_model fact general idea principle way statistical modeling solve text mining problems dim picture seen order generation_process idea approach actually 1st design model design probabilistic model model data course based actual data arent necessary generated way probability distribution data seeing slide given particular model parameters denoted capital lambda actually consists parameters parameters general control behavior probabilistic model meaning set parameters different values data points higher case course tax mining problem precisely topic mining problem following thetais word distribution set pis n documents n sets set pi values pretend word distributions coverage numbers going generate data model data way assume data actually samples drawn model depends interesting question think parameters obviously n k parameters k thetais thetai actually set probability right distribution leave exercise figure exactly set model fit model data meaning estimate parameters infer parameters based words like adjust parameter_values data set maximum depending parameter_values data points higher interested parameter_values data set highest illustrate problem x axis illustrate lambda parameters dimensional oversimplification obviously suffices idea y axis shows probability data probability obviously depends setting lambda thats varies change value interested find lambda star maximize probability observed estimate parameters parameters note precisely hope discover text data treat parameters actually outcome output data mining general idea generative_model text design model parameters interested model adjust parameters fit fitted data recover parameter_values specific parameter_values output algorithm treat actually discovered knowledge text varying model course discover different summarize introduced new way representing topic represented word distribution advantage multiple words describe complicated allows assign weights words model subtle variations talked task topic mining analysis define topic distribution input collection text number topics vocabulary set output set word coverage topics document formally represented thetais piis constraints constraint word world distribution probabilities words sum words second constraint topic coverage document allowed cover topic outside set topics coverage k topics sum introduce general idea generative_model text mining idea design model model generation simply assume generated way inside model embed parameters interested denoted infer likely parameter_values lambda star given particular data set lambda star knowledge discovered text problem adjust design model parameters discover kinds knowledge later
lecture overview statistical language models cover probabilistic topic models special_cases lecture going overview statistical language models general models cover probabilistic topic models special_cases statistical language_model statistical language_model basically probability distribution word example distribution gives today wednesday probability 001 today wednesday non grammatical sentence small probability similarly sentence eigenvalue positive probability 00001 distribution clearly context depends context word sequences higher sequence words different probability different suggests distribution actually characterize model regarded probabilistic mechanism generating means view text data data observed reason model generative_model given model sample sequences example based distribution shown slide lets sample sequence like today wednesday relatively high probability eigenvalue positive smaller occasionally today wednesday probability general order characterize distribution specify probability values different sequences obviously impossible specify impossible enumerate possible sequences practice simplify model simplest language_model called unigram_language case simply assume text generated generating word general words generated_independently assumption significantly simplify language_model basically probability sequence words w1 wn probability model parameters number words assume n words n probabilities word assume text sample drawn according word means gonna draw word time eventually try sample words according wednesday today words like eigenvalue small probability actually compute probability sequence model specifies probabilities independence_assumption specifically compute probability today product probability today probability probably example showed fake numbers multiply numbers probability today n probabilities word actually characterize probability distribution kinds sequences words simple ignore word order effective problems speech recognition care order turns sufficient tasks involve topic analysis thats model generally problems given likely observe certain kind data interested sampling estimation process figure parameters model given observed data going talk lets talk examples word distributions unigram_language higher probabilities words text mining association signals topic text mining sample words distribution tend words occur text mining case ask question probability generating particular document likely text looks like text mining paper text generated drawing words distribution unlikely coherent probability generating text mining paper publishing conference non assuming word zero probability distribution means essentially generate kinds text documents including meaningful text second distribution different words higher food nutrition healthy diet clearly indicates different topic case probably sample words distribution probability observing text mining paper hand probability observing text looks like food nutrition paper high relatively means given particular distribution different text different lets look estimation case going assume observed know exactly text data looks case lets assume text mining fact abstract paper total_number words 100 ive_shown counts individual ask question likely language_model generate text data assuming text observed language_model whats best_guess language_model ok problem estimated probabilities words ive_shown think guess guess text small probability relatively large probability query guess probably dependent times observed word text data right think moment like guessed text probability 10 ive observed text 10 times text total 100 similarly mining query relatively_small probability right intuitively reasonable guess question best_guess best estimate parameters course order answer question define mean case turns guesses best sense called maximum_likelihood best observed data maximum meaning change estimate slightly probability observed text data somewhat called maximum_likelihood
lets talk problem little bit specifically lets talk different ways estimating called maximum_likelihood estimate bayesian maximum_likelihood estimation define best meaning data likelihood reached maximum formally given define estimate arg max probability x given arg max means actually function return argument gives function maximum value value value arg max value function argument function reach case value argmax theta makes probability x given theta reach maximum estimate intuitively_makes sense useful seeks parameters best explain problem data small data points small data sample small trust data entirely try fit data case text data lets observed 100 words contain word related text mining maximum_likelihood estimator word zero giving non zero probability away probability_mass observed words obviously optimal terms maximizing likelihood observed zero probability unseen words reasonable especially want distribution characterize topic text way address problem actually use bayesian estimation actually look data prior knowledge assume prior belief case course going look data look prior prior defined p means impose preference certain bayes_rule shown combine likelihood_function prior posterior_probability explanation bayes_rule things related bayesian reasoning outside scope course brief introduction general knowledge useful bayes_rule basically allows write conditional probability x given y terms conditional probability y_given probabilities conditional probabilities different order variables rule making inferences lets look assume p x encodes prior belief means observe data thats belief x believe x values higher probability x given y conditional probability posterior belief x belief x values observed given observed y believe x believe values high_probabilities probabilities related regarded probability observed_evidence y_given particular think x prior belief hypothesis choose observed y update belief updating_formula based combination prior likelihood observing y x detour bayes_rule case interested inferring theta values includes prior knowledge data likelihood tell parameter value explain posterior_probability represents compromise case maximize posterior_probability find theta maximize posterior_probability estimator called maximum posteriori map estimate general estimate maximum_likelihood define prior noninformative prior meaning uniform theta values preference basically maximum_likelihood estimator case mainly going determined likelihood ok informative prior bias certain values map estimate allow incorporate problem course define theres free lunch want solve problem knowledge knowledge knowledge ideally estimate necessarily accurate maximum_likelihood lets look bayesian estimation ok theta values dimension value thats simplification interested value data prior tells theta values believe example values likely values like data case data tells values theta likely means theta values best explain combine posterior distribution thats look interesting point estimates point represents mode means likely parameter value according prior observe point maximum_likelihood estimate represents theta gives data maximum point posterior likely value theta given posterior distribution represents good compromise prior mode maximum likehood general bayesian_inference interested distribution parameter_values theres distribution theta values p theta given problem bayesian_inference infer posterior distribution infer interesting quantities depend showed f theta interesting variable want order compute value need know value bayesian_inference treat data uncertain think possible values estimate value function f expected value f according posterior distribution data given observed_evidence special case assume f theta equal case expected value thats basically posterior mean gives point posterior mode gives way estimate general illustration bayesian estimation bayesian_inference later useful topic mining want inject prior knowledge summarize introduced language_model basically probability distribution called generative_model text simplest language_model unigram_language basically word introduced concept likelihood_function probability data given function given particular set parameter_values function tell x data point higher likelihood higher given data point sorry given data sample x use function determine parameter_values maximize probability observed data maximum_likelihood talked bayesian estimation case define prior parameters p theta interested computing posterior distribution parameters proportional prior kind distribution allow infer derived values
lecture continued_discussion probabilistic topic lecture going continue_discussing probabilistic_models going talk simple case interested mining topic simple setup interested analyzing document trying discover simplest case topic input longer k number topics know collection output longer coverage assumed document covers topic main goal discover word probabilities single topic think generative_model solve problem start thinking kind data going model perspective going model data data going design specific model generation data perspective means want particular angle looking data model right parameters discovering knowledge want thinking likelihood_function write library function capture formally likely data point obtained likelihood_function parameters function usually interested estimating parameters example maximizing likelihood lead maximum_likelihood estimator estimated parameters output mining means estimated parameters knowledge discover lets look steps simple later look procedure complicated data case document sequence word denoted x model unigram_language model word distribution hope denote topic thats parameters words vocabulary case convenience going use theta_sub denote probability word w obviously thetas likelihood_function look like probability generating document given assume independence generating word probability word document product probability word repeated occurrences rewrite product different line rewritten formula product unique words vocabulary w sub w sub different previous line product different positions words transformation need introduce count denotes count word similarly count words m words repeated word occur document zero count corresponding term useful form writing likelihood_function use want pay familiar change product different words end course use theta_sub express likelihood_function look going find theta values probabilities words maximize likelihood_function lets look maximum_likelihood estimate problem line copied previous likelihood_function goal maximize likelihood_function find easy maximize log likelihood instead original likelihood purely mathematical convenience logarithm transformation function sum instead constraints sum makes easier derivative needed finding optimal solution look sum form function later general topic sum words vocabulary inside sum count words multiplied logarithm lets solve point problem purely mathematical problem going find optimal solution constrained maximization objective_function likelihood_function constraint probabilities way solve problem use lagrange multiplier content scope lagrange multiplier useful approach like brief introduction approach construct lagrange function combine objective_function term encodes introduce lagrange multiplier additional idea approach turn constrained optimization sense unconstrained optimizing interested optimizing lagrange recall calculus optimal point achieved derivative set necessary partial derivative respect theta comes derivative logarithm lambda simply set zero easily theta_sub related lambda know theta sum plug constraint allow solve negative sum counts allows solve optimization_problem eventually find optimal setting theta_sub look formula turns actually intuitive normalized count words document_length sum counts words math obtained thats intuitive intuition want maximize theta assigning probability_mass possible observed notice general result maximum_likelihood general estimate normalize count counts particular way basically analytical solution optimization_problem general likelihood_function complicated going able solve optimization_problem having closed form instead use numerical algorithms going cases imagine use maximum_likelihood estimator estimate topic single document d lets imagine document text mining looks high probability words tend common words functional words english followed content words characterized topic like text mining etc end probabilities words related topic externally mentioned topic representation ideal right high probability words functional words characterizing question rid common words topic going talk use probabilistic_models rid common
lecture mixture unigram_language lecture continue_discussing probabilistic topic particular going introduce mixture unigram_language slide seen_earlier talked rid background words estimated language_model want solve useful think end having obviously words frequent data maximum_likelihood estimate estimator obviously assign_high probabilities words order maximize order rid mean particular distribution doesnt explain words text data going common words explained natural way solve problem think distribution account common way distributions mixed generate text data let model called background topic model generate common way target topic theta generating content words characterize content work small modification previous set distributions decide distribution use generate word word sampled distributions right text data generating going generate word eventually generated lot generate word going 1st decide distributions use controlled probability probability theta_sub d probability theta_sub probability selecting topic word probability selecting background word distribution denoted theta_sub case example basically flip coin fair_coin decide general probabilities dont equal bias process generating word flip coin based probabilities choosing lets coin_shows head means going use topic word going use word distribution generate going going use background word distribution generate case model uncertainty associated use word think model generating text data model called mixture_model case whats probability observing word w showed words like text cases set model interested computing likelihood_function basic question whats probability observing specific word know word observed distributions consider 2 sum case use topic word distribution generate word case probability probability theta_sub d probability choosing model multiplied probability actually observing word events happen order chosen topic actually sampled word distribution similarly second accounts different way generating word obviously probability text similar right consider ways generating text case product probability choosing particular word distribution multiplied probability observing word later actually general form want sure understood convince probability observing summarize observe probability word mixture_model general sum different ways generating case product probability selecting component multiplied probability actually observing data point component model general occurring basic_idea mixture_model treated distributions use box bring view box model like generative_model probability way determines probability different basically complicated mixture_model sorry complicated model distribution called mixture_model said treat generative_model useful think likelihood_function illustration seen dimmer illustration generation mathematically define following generative_model probability word assumed sum 2 cases generating form youre_seeing general seen calculation simple w denote basically like sum fact word generating multiple ways inside sum term product terms probability selecting component like theta_sub second probability actually observing word component general description fact mixture want sure understand basis understanding kinds topic set model write likelihood_function question estimate parameter parameters given data general use observed text data estimate model parameters mission allow discover interesting knowledge text case discover represented parameters kinds word topics coverage coverage topic determined probability theta_sub probability theta_sub note whats_interesting think special_cases like happen 0 right look likelihood_function degenerate special case distribution right easily verify assuming 0 sense mixture_model general previous model distribution cover special summarize talked mixture unigram_language data consider 1 model mixture_model components unigram_language specifically theta_sub d intended denote topic document d theta_sub b representing background topic set attract common common words assigned high_probabilities parameters collectively called lambda think question parameters talking usually good exercise allows model index complete_understanding whats going model mixing weights likelihood_function look like looks similar document product words document difference inside sum instead sum mixture_model mixed model introduce probability choosing particular component way writing product unique words vocabulary instead having product positions document form look different unique words convenient form computing maximum_likelihood estimator maximum_likelihood estimator usual find parameters maximize likelihood_function constraints course word probabilities topic sum choice topic
lecture mixture_model lecture going continue_discussing probabilistic topic particular going talk estimate parameters mixture_model lets look motivation mixture_model hope factor background words topic word idea assume text data actually contain kinds kind away etc kind topic word distribution order solve problem factoring background words set mixture_model going assume know parameters values parameters mixture_model word distribution theta_sub d case customizing probalistic model embed unknown variables going simplify going assume powerful way customizing model particular imagine assumed dont know background word distribution case goal factor precisely high probability background assume background model problem adjust theta_sub d order maximize probability observed document assume parameters designed model heuristically try factor background unclear use maximum_likelihood estimator actually end having order distribution common words like having smaller case turns answer yes set probalistic model way use maximum_likelihood estimator end having word distribution common words factored use background understand useful examine behavior mixture_model going look simple case order understand interesting behaviors mixture_model observed patterns actually generalizable mixture_model general easier understand behavior use simple case like specifically lets assume probability choosing models exactly going flip fair_coin decide model furthermore going assume precisely words obviously naive oversimplification actual text useful examine behavior special assume background model gives probability point word text lets assume data extremely document words lets write likelihood_function whats probability text whats probability hope point able probability text basically sum 2 cases case corresponds word accounts ways generating inside case probability choosing 5 multiplied probability observing text similarly probability form different exact naturally likelihood_function product understand whats probability word important understand exactly probability observing word mixture_model interesting question optimize likelihood notice precisely probabilities words text given theta_sub assumed parameters question simple algebra question right simple expression variables hope choose values variables maximize exercise seen simple algebra problems note probabilities theres constraint course set probabilities maximum value cant text cant probability question allocate probability_mass words think useful look formula moment intuitively order set probabilities maximize value ok look interesting behavior component models collaborating maximize probability observed data dictated maximum_likelihood competing someway particular competing tend bet high_probabilities different words avoid competition gain advantage looking objective_function look formula intuitively feel want set probability text somewhat intuition supported mathematical fact sum variables product maximum equal fact know plug mean probabilities equal consider constraint easy solve problem solution probability text point probability probability text larger case distribution clearly use background model assigns high probability low probability look equation obviously interaction particular order equal probability assigned theta_sub d higher word smaller probability given obvious examining equation background weak text order compensate probability text given theta_sub d somewhat larger sides fact general behavior mixture_model distribution assigns high probability word tend basically discourage distributions balance account kinds means background model fixed assign_high probabilities background words encourage unknown topic world distribution assign smaller probabilities common words instead probability_mass content words explained background meaning small probability background model like
lets look behavior mixture_model case lets look response data ok youre_seeing basically likelihood_function word document know case solution text probability 9 probability interesting think scenario start adding words happen add thes document change game right picture likelihood_function look like started likelihood_function add words know multiply likelihood_function additional terms account additional case additional terms going multiply term occurrence multiply term forth add terms number thes added document d obviously changes likelihood_function whats_interesting think change whats optimal solution intuitively know original 9 1 longer optimal new function right question change general order change away probability mess added probability_mass question word reduced probability word larger probability particular lets think increased 1 decrease 1 think want pause video moment think question understanding important behavior mixture_model maximum_likelihood look formula objective_function influenced text contributed imagine sense actually assign smaller probability text room larger repeated times increase little bit positive impact slight decrease relatively_small impact right means behavior observe high frequency words generally high_probabilities surprise maximizing likelihood word occurs makes sense word high probability impact likelihood_function fact general phenomenon maximum_likelihood estimator case occurrences encourages unknown distribution theta_sub d assign somewhat higher probability interesting think impact probability theta_sub probability choosing component weve far assuming model equally_likely gives 5 look like function try picture happen increase probability choosing background terms different form probability larger background high probability word coefficient 9 5 larger overall result larger makes important theta_sub d increase probability large impact increasing probability somewhat regulated coefficient larger background important increase means behavior high frequency words tend higher probabilities affected regularised somewhat probability choosing likely component chosen important higher values frequent small probability chosen summarize discussed mixture_model discussed estimation problem mixture_model particular discussed general behavior estimate means expect estimator capture 1st component component model attempts assign_high probabilities high frequency words collaboratively maximize second different component models tend bet high_probabilities different words avoid competition waste probability allow collaborate efficiently maximize 3rd probability choosing component regulates collaboration competition component allow component models respond change example frequency data point talk special case fixing component background word distribution distribution estimated collection large collection english documents distribution normalized frequencies terms probabilities use specialized mixture_model effectively rid background words discovered topic example imposing prior model parameters prior basically means model exactly background_language model recall talked bayesian estimation prior allow favor model thats consistent fact consistent going model impossible zero prior probability effectively excludes issue talk
lecture expectation maximization algorithm called em_algorithm lecture going continue discussion probabilistic topic particular going introduce em_algorithm family useful algorithms computing maximum_likelihood estimate mixture familiar scenario component mixture_model try factor background words topic word interested computing going try adjust probability values maximize probability observed document know assume parameters thing unknown word probabilities given theta_sub d lecture going look compute maximum_likelihood lets start idea separating words text data group explained background model group explained unknown topic word distribution basic_idea mixture_model suppose actually know word distribution mean example words known background word hand words text mining clustering etc known topic word color shown blue words assumed topic word know separate words problem estimating world distribution extremely simple right think moment realize simply words known word distribution theta_sub d problem easy known words distribution fact making model longer mixture_model observe distribution generate data actually single word distribution problem case lets words known theta d pseudo document d prime need normalize word counts word w thats fairly straightforward dictated maximum_likelihood idea doesnt work practice dont know word gives idea guess specifically given parameters infer distribution word lets assume actually know tentative probabilities words theta_sub parameters known mixture_model lets consider word like question think text likely having generated theta_sub d theta_sub b words want infer distribution generate inference process typical bayesian_inference situation prior distributions prior prior probability distribution right prior given case prior saying model equally_likely imagine different prior called prior guess distribution generate world observe thats dont_observe word dont know word observed best_guess equally_likely alright flipping bayesian_inference typically update belief observed_evidence evidence evidence word interested word text text regarded use bayes_rule combine prior data likelihood end combine prior likelihood basically probability word text distribution cases text possible background small intuitively guess case youre like guess text probably theta_sub d likely theta_sub d text higher theta_sub d background model small going text likely theta_sub guess distribution generate text depend high probability data text word going tend guess distribution gives word higher probability likely maximize likelihood going choose word higher words going compare word given guess affected prior need compare priors imagine adjust probabilities going probability choosing background model kind strong prior affect think wait moment maybe text background probability prior end combine bayes formula provides provides solid principled way making kind guess specifically lets think probability word text fact theta_sub d order texture generated theta_sub d things theta_sub d selected selection probability secondly actually observed text multiply probability text fact generated theta_sub d similarly background probability generating text product similar introduced latent variable z denote word background z zero means topic theta_sub d means background theta_sub probability text simply simply_normalize estimate probability word text theta_sub d theta_sub equivalently probability z equal 0 given observed_evidence application bayes_rule step crucial understanding em_algorithm able 1st initialize parameter_values somewhat randomly going guess z_values distribution generate word initialized parameter_values allow complete specification mixture_model allows apply bayes_rule infer distribution likely generate word prediction essentially helped separate words distributions cant separate sure separate probabilistically
general idea expectation maximization em_algorithm em algorithms introduce hidden_variable help solve problem case hidden_variable binary variable occurrence binary variable indicate world generated theta sunday theater super possible values example background z value 1 text hand 0 z course dont_observe z_values imagine social values z attached thats hidden idea talked predicting word distribution general world itll value hidden_variable algorithm em_algorithm work initialize parameters random case parameters mainly probability word given status initialization initialized values allow use bayes_rule guess z_values guess values sure taxes background given called algorithm try use e_step 2 z_values invoke spec step called step simply advantage inferred values group words distribution like background normalize count estimate probabilities revise estimate let illustrate group words believed come cedar sub d text mining algorithm example help estimate interested help estimate note set parameter_values randomly guess somewhat improved course dont know exactly zero going split hardware soft split going adjust probability believe generated theta_sub come come right e_step em_algorithm iteratively improve initial estimate parameters estep m_step e_step augment data additional information like m_step advantage additional information separate data split data accounts collect right data estimate new generation parameters going going use estep improve estimate hidden variables lead generation estimate word distribution ok said bridge variable z hidden_variable indicates likely world topic word distributions theta_sub slide lot content need pause video digest basically captured essence em_algorithm start initial values randomly invoke e_step followed m_step improved setting parameters hill climbing algorithm gradually improve estimate parameters explain later theres guarantee reaching local_maximum likelihood_function lets look computation specific formulas em formulas superscripts n indicate generation example n means improved setting assumed models equal probabilities background model relevant statistics word assume 4 words counts like background model assigns high_probabilities common words iteration picture initialize probability interested normalized uniform distribution e_step distribution generate word different probabilities different thats cause words different probabilities distributions equally_likely initialization says uniform distribution difference background world distribution different guest words believed likely hand likely probably z_values know e_step probabilities adjust 4 multiplied point order allocated counts note guess says 0 council word general said going 0 going percentage counts topic simply_normalize new generation practice mate compare compare probability words believed come high probability like course new generation parameters allow adjust infer latent variable hidden_variable new generation values e_step based new generation new values generation estimate probabilities actually happen compute probabilities em_algorithm rule showed log like code likelihood increasing note log likelihood negative becausw probability zero logarithm negative whats_interesting column inferred word split probabilities word believed come case topic distribution wonder useful main goal estimate word distribution right primary hope discriminating world column product actually useful example extent document covered background add average kind know extent covered background versus content words explained
showed empirically likelihood converge theoretically proved em_algorithm converge local_maximum illustration happened detailed knowledge inequalities havent x set parameter left y likelihood_function curve reaching like roller function hope maximize hope find set value point case mixture_model easily find analytical solution resolve numerical em_algorithm hill climb algorithm mean start random lets thats starting point try improve moving point higher like thats idea hill mri way achieve fix lower_bound likelihood_function lower_bound fit lower_bound maximise lower_bound course reason works lower_bound easier optimize know current gas maximizing lower_bound map original like role find cause lower_bound guaranteed improve right improve lower_bound original lighter holder curve lower_bound definitely know improving lower_bound definitely improve original like record function lower_bound example current gas parameter value given current generation guest estimated parameter_values illustration gas better current gas reached maximum e_step basically compute lower_bound dont direct computed likely function computed latent variable basically lower_bound helps determine lower_bound m_step hand maximize lower_bound allows parameters new thats eml little converge local_maximum imagine local maxima repeat eml multiple_times order figure actual global actually general difficult problem numerical example start gradually climb thats optimal wed like climb way em_algorithm generally start different points way determine good initial starting summarize lecture introduce em_algorithm general algorithm maximum regular kinds mixture simple mixture_model climbing algorithm converge local_maximum depend initial general idea steps improve estimate parameters e_step roughly augmenting data predicting values useful hidden variables use simplify case distribution generate end step exploit augmented data easier estimate distribution improve estimate improve guaranteed terms likelihood_function note necessary stable converged parameter_values likelihood_function insured properties satisfied order convert stable thought data augmentation means going exactly whats value hidden_variable going probability distribution possible values hidden variables causes split counts events probabilistically case split world counts
lecture probabilistic latent semantic_analysis p lecture going introduce probabilistic latent semantic_analysis called basic topic useful topic kind models general multiple topics text documents plsa basic topic models lets examine problem little sample article blog article hurricane_katrina showed sample topics example government_response flooding city new_orleans donation article use words theres criticism government_response followed discussion flooding city donation background words mixed goal topic analysis try decode topics segment topics figure words distribution figure know theres topic government_response public flooding tasks topical discover topics color words separate different topics lot things summarization segmentation topics clustering sentences formal definition problem mining multiple topics text shown actually slide seen_earlier lecture input collection number topics vocabulary course text data right output topic category characterization seedies hci water distribution 2nd topic coverage pie ideas tell document covers topic hope generate output useful idea plsa actually similar component mixture_model difference going illustrate generate text multiple naturally cases probabilistic modeling want figure likelihood_function ask question whats probability observing world w mixture_model look picture compare picture seen_earlier difference added topic background topical specifically k topics assume exist text data consequences switch choosing topic multiway switch way going think flipping flip coin decide talk lambda sub b versus non minus lambda b gives probability actually choosing background decision decision choose k theres key switch characterized pies different design switches little bit complicated decide distribution use going generate world distributions ok lets look question like_hold whats probability observing word distribution think weve seen problem times recall generally sum different possibilities generating lets look world generated background probability world generated background model lambda multiplied probability world background model right things chosen background thats probability lambda sub b second actually obtained world w background thats probability w given sit ok similarly figure probability observing world topical theta_sub notice heres product terms thats choice topic theta_sub k happens things decided talk background thats probability 1_minus lambda sub second actually k k thats probability cake similarly probability generating water second topic topic popular like youre_seeing end probability observing world sum stress important formula key know understanding topic models lot mixture models sure understand w likelihood_function interested knowing parameters right estimate lets complete likelihood_function line shows probability word illustrated previous slide important formula lets closer contains important lambda sub represents percentage background believe exist text data unknown value set second background_language model typically assume use large collection text use tests available estimate water rest excuse interesting kinds important parameters asked pies coverage topic word distributions characterize line simply plug calculate probability familiar form account world document log little bit complicated component sum involves terms line like holder collection accounting documents unknown primers said kinds awarded useful exercise figure exactly unknown parameters trying figure question help understand model detail allow understand output generate use plsa analyze text data precisely unknown obtained likelihood_function shown worry parameter usual maximum_likelihood constrained optimization_problem like seen collection text parameters estimate constraints different constraint kinds awarded words probabilities sum 141 topic coverage anna document cover precisely k topics probability covering topical point basically find applied math need figure solutions optimization_problem theres function variables need figure values variables function
compute maximum regular estimated em_algorithm estep introduce hidden variables hidden_variable z topic indicator specifically k plus values b denoting background k denote k e_step recall augmented data predicting values hidden_variable going predict word word come k1 equation allows predict probability word w document d generated topic theta_sub j predicted probability word generated note use document d index word particular topic actually depends pis tied document potentially different pis right pis affect prediction pis depends different guess word word different documents thats cases bayes_rule explained basically assessing likelihood generating word distribution mstep recall m_step advantage inferred z_values split counts collect right counts estimate case estimate coverage probability estimated based collecting words thats count word document sum going look extent word belongs topics theta subj guess tells likely word actually theta subj multiply discounted count thats allocated topic theta subj normalize topics distribution topics indicate similarly reestimate probability word case exactly discounted count tells extent allocate word topic theta normalization different case interested word simply_normalize contrast normalized useful gives different distributions tells improve parameters explained e_step formulas maximum_likelihood estimator based allocated word counts topic theta phenomena actually general phenomenon em algorithms m_step generate computed expected_count event based e_step result collect relevant counts particular reestimate terms computation em_algorithm actually counting events think way concise way presenting em_algorithm actually helps better understand im going algorithm initialize unknown parameters case interested coverage parameters pisand word distributions randomly initialization step repeat likelihood know likelihood converges going compute likelihood step compare current likelihood previous likelihood doesnt change going stop right step e_step m_step e_step going augment data predicting hidden_variable case hidden_variable z sub dw indicates word w d topic background topic topic look e_step formulas essentially actually normalizing sorry probabilities observing word distribution basically prediction word topic theta subj based probability selecting theta subj word distribution begin generate world multiplied probability observing word said proportional completing implementation em_algorithm count counter quantity end normalization topics m_step going allocated counts split words going normalize different ways obtain example normalize topics estimate pi renormalize words word useful think algorithm way implement variables track quantities normalize variables constraint intentionally leave exercise whats slightly different form essentially general implementation em_algorithm accumulated counts counts summarize introduced plsa model mixture_model k unigram_language models representing k added predetermined background_language model help discover discriminating background_language model help attract common maximum_likelihood estimator discover topical knowledge text case plsa allows discover kword distributions representing topic proportion topic detailed characterization coverage topics documents enable lot example aggregate documents particular time_period assess coverage particular topic time_period allow generate temporal chains aggregate topics covered documents associated particular author characterize topics written author addition cluster terms cluster fact topic regarded cluster term higher probability words regarded belonging represented similarly documents clustered assign document topic cluster thats covered remember pis indicate extent topic covered assign document topic cluster highest general useful applications
lecture latent dirichlet allocation lecture going continue talking topic particular going talk extensions plsa lda latent dirichlet plan lecture cover extend plsa prior knowledge allow sense user controlled plsa doesnt blindly listen data listen second extend plsa generative_model fully generated led development latent dirichlet allocation lets talk plsa prior practice apply plsa analyze text data additional knowledge want inject guide standard plsa going blindly listen data maximum_likelihood going fit data insight useful user expectations topics example expect retrieval models topic information interested certain aspects battery memory looking opinions laptop user particularly interested user knowledge topic know topic definitely covered document covered example seen tags topic tags assigned tag treated topics document generated topics corresponding tags assigned document assigned tag going theres way topic generate document generated topics corresponding assigned question incorporate knowledge plsa turns elegant way thats incorporated knowledge priors recall bayesian_inference use prior data estimate parameters precisely case use maximum posteriori estimate called map estimate formula basically maximize posterior distribution probability combination likelihood data happen going estimate listens data listens prior use prior denoted p lambda kinds preferences example use encode need having precisely 1 background encoded prior prior parameters non zero plan contain topic thats equivalent background_language words cases like going supplier says probability kind model setting 0 according example use prior force particular choice topic probability certain example force document d choose topic probability prevent topic generated topic user document d set pi value 0 use prior favor set parameters topics assign_high probabilities particular case going impossible going strongly favor certain kind example map computed similar em_algorithm maximum_likelihood estimator modification smallest parameters reflect prior estimate use special form prior called conjugate prior functional form prior similar result combine consequences basically convert influence prior influence having additional pseudo data functional forms effect convenient doesnt mean conjugate prior best way define lets look specific suppose user particularly interested battery_life laptop analyzing prior says distribution contain distribution assign_high probabilities battery_life theres distribution thats entirely concentrated battery_life priors distributions use map estimator conjugated prior dirichlet prior dirichlet_distribution based preference difference em_algorithm m_step estimate word distributions going additional counts reflect prior right pseudocounts defined based probability words battery obviously high pseudocounts similar life high pseudocounts 0 pseudocounts probability zero prior controlled parameter mu going add mu multiplied probability w given prior distribution connected estimate estimate world distribution right step changed changes happened collect counts words believe generated force probabilities words adding pseudocounts artificially effect artificially inflated probabilities distribution need add pseudocounts total sum pseudocounts added intuitively reasonable way modifying em_algorithm theoretically speaking deal works computes map useful think specific extreme cases think happen set mu thats essentially remove prior mu sense indicates strength happen set mu positive infinity thats price strong going listen end case distribution fixed mu infinity basically let fact going precise distribution case distribution thats said background_language model fact way enforce prior force distribution exactly thats background case force distribution entirely focused battery_life course wont work cause attract words affect accuracy topics battery_life practice mu set way impose impose example set parameters constraints including zero example want set pis mean dont allow topic participate generating reasonable course prior knowledge strongly
lets talk extension plsa derive lda motivate need talk deficiency generating model compute probability new thats pies needed generate document pis tied document training_data compute pis future secondly parameters ive asked compute parameters exactly plsa means model complex means local_maximum prone overfitting means hard find good local_maximum represents global terms explaining future data find overfit training_data complexity model flexible fit precisely training_data looks like doesnt allow generalize model necessary problem text mining interested fitting training interested modeling future data cases care generality worry lda proposed improve basically plsa generative_model imposing dirichlet prior model dirichlet special distribution use specify sense lda bayesian version plsa parameters fewer_parameters achieve goal plsa text means compute topic coverage topic word distributions free launch parameters plsa fewer fewer_parameters order compute topic coverage word distributions face problem influence variables theyre parameters face local maxima essentially similar theoretically lda elegant way looking topic modeling lets generalize plsa lda extend plsa lda treatment lda scope course dont time depth want brief idea whats extension picture remove background model model parameters free change impose prior word distributions represented theta word set parameters pis present convenience introduce lda vector case theta vector difference lda plsa lda going allow free instead going force drawn specifically drawn 2 dirichlet distributions dirichlet_distribution distribution vectors gives probability particular choice example pis right dirichlet_distribution tell vector pis likely distribution controlled vector parameters depending alphas characterize distribution different ways force certain choices example favor choice relatively uniform distribution topics favor generating skewed coverage topics controlled topic word distributions drawn dirichlet_distribution beta parameters note alpha k parameters corresponding inference k values pis document beta n values corresponding controlling n words impose price generation_process different start drawing pis dirichlet_distribution pi tell going use pi choose topic use course similar plsa similar going distributions instead draw dirichlet_distribution going sample word rest similar likelihood_function complicated lda theres close connection likelihood_function lda plsa im going illustrate likelihood_function seen copied previous slide dropped background lda formulas similar equation essentially probability generating word multiple word formula sum possibilities generating word inside sum product probability choosing topic multiplied probability observing world important formula stressed multiple_times actually core assumption topic models topic models extensions lda plsa important gives probability getting word mixture_model probability document plsa component lda lda formula add integral thats explain account fact pis fixed drawn dirichlet_distribution thats thats integral consider possible pis possibly draw dirichlet_distribution similarly likelihood collection components right basically lda added integrals account uncertainties added course dirichlet distributions govern choice parameters pis likelihood_function lets lets talk parameter making inference parameters estimated exactly approach maximum_likelihood estimator think parameters lda versus fewer_parameters lda case parameters alphas use maximum_likelihood estimated course complicated form likelihood functions whats important parameters interested topics coverage longer parameters case use bayesian_inference posterior inference compute based parameters alpha unfortunately computation intractable generally resort methods use different toolkits lda read papers different extensions course cant depth introduction know computed based bayesian_inference parameters alphas algorithmically actually end algorithm similar plsa especially use algorithm called collapsed gibbs algorithm looks similar em_algorithm end theyre summarize discussion probabilistic topic models models provide general principal way mining analyzing topics texts best basis test setup tax data input going output key topic characterized word distribution going output proportions topics covered plsa basic topic model fact basic topic adequate thats spend lot time explain plsa lda improves plsa imposing led theoretically appealing practice lda plsa intended similar performance practice plsa lda work equally suggested_readings want know nice review probabilistic topic 2nd paper discussion automatically label topic ive_shown distributions intuitively suggest topic exactly topic use phrases label topic easy understand paper empirical comparison lda plsa conclusion tend perform
lecture text important technique topic mining particular lecture organ start basic questions clustering text clustering interested text clustering following_lectures going talk text clustering evaluate clustering text clustering clustering actually general technique data learned idea discover natural structures words want group similar case objects course texture example documents turns passages sentences goal group similar texture lets dont text objects use shapes denote objects ask natural structures natural groups look agree group objects based shapes locations 2 dimensional_space got clusters disagreement clusters depends perspective look maybe seen different way different example ambiguity clearly main point problem actually problem lies define mean similar objects clearly defined order defined clustering problem general objects similar depending lets look words like car words similar depends look physical properties car look functionally car horse transportation tool sense depends perspective look objects order clustering problem defined user define assessing perspective clustering_bias define clustering problem important specify perspective similarity defining similarity group similar objects similarity different ways group lets look concrete seeing objects shapes similar seen 1st ask group feel theres uncertainty previous think group shapes cluster looks maybe objects grouped based sizes different way cluster look size look similarity clearly depending perspective different clustering results clearly tells order evaluate clustering result use perspective hard define best clustering examples text example cluster documents text case documents units able cluster terms terms cluster terms define concept theme fact topic models seen previous cluster terms terms high_probabilities world example cluster texts segments example passages sentences segments extract large text example extract text segments topic lets topic weve_got text objects segments weve_got discover interesting clusters represent case combining text clustering techniques general lot text mining algorithms actually combined flexible way goal sophisticated mining analysis text cluster fairly large text law gets mean text objects contain lot example cluster website actually composed multiple similarly cluster articles written author treat articles published author unit way group authors based published papers furthermore text clusters regenerate hierarchy thats cause general cluster text object different generally text clustering interesting brcause useful technique text mining particularly exploratory text typical scenario getting lot text lets email_messages customers time_period literature articles hope sense overall content example interested sense major topics typical representative document collection clustering help achieve want link similar text objects duplicated content example case technique help remove redundancy removing duplicated topic linking complete coverage use text clustering create structure text data create hierarchy structures useful use text clustering induce additional features represent text data cluster documents treat cluster feature document cluster feature value document cluster future value zero helps provide additional discrimination texture classification discuss general applications text saw specific cluster search results example imagine search_engine cluster search results user overall results returned query ambiguous particularly becausw clusters likely represent different senses ambiguous application understand major_complaints customers based emails right case cluster email_messages find major understand major_complaints
lecture generative probabilistic_models text lecture continue_discussing text clustering going introduce generative probabilistic_models way text clustering overall plan covering text clustering previous_lecture talked text clustering text clustering lecture going talk text clustering general slide kinds generating probabilistic_models topic lecture later discuss similarity based_approaches talk generative models text clustering useful revisit topic mining problem topic problems similar slide seen_earlier lecture topic input text collection c number topics k vocabulary v hope generate output set topics denoted word distribution pi ijs probabilities document covers topic coverage visualized slide topic main difference text clustering problem document assumed possibly cover multiple topics general document covering topic non zero text clustering allow document cover assume topic means change topic definition slightly assuming document generated precisely definition clustering output changed longer detailed coverage distributions pi ijs instead cluster assignment ci ci decision c sub going value k indicate k basically tells document di illustrated longer multiple topics covered document precisely topic topic problem topic discussed_earlier slide hope estimate topic model word distribution based precisely document thats assume document covers precisely consider variations example consider n documents covers different thats n documents course case documents independent topics allow documents share assume going assume fewer number document share n documents share k topics precisely document clustering connections naturally think use probabilistic generating model solve problem text question generating model cases designing generative_model hope generative_model adopt output hope generate structure hope case clustering topics document covers topic hope embed preferences generative_model think main difference problem topic model talked earlier main requirement force document generated precisely topic instead k topics topic lets revisit topic model detailed view component mixture_model k components looks generate generated word generated word choice distributions decided use p theta probability choosing decision distribution generate world going use distribution sample notice generative_model decision distribution use word independent means example generated second theta text likely means words document generated general multiple want text document clustering hope document generated precisely means need modify model lets think model clustering allowed multiple topics contribute words causes confusion going know cluster document importantly violating assumption partitioning documents topic correspond cluster documents document generated precisely means words document generated precisely distribution true topic model seeing thats clustering ensure distribution words realize problem naturally design alternative mixture_model youre_seeing decision distributing use generate document document potentially generated k word time decision choose topics going stay distribution generate words means choice distribution generating going stay decision generating words words basically decision document stay generate similarly chosen second distribution theta_sub stay generate entire document compare picture previous particular distribution case document case topic model decisions number words document word potential different decision thats key difference obviously mixture_model group model probability inside model theres choosing different distribution dont_observe thats mixture_model course main problem document clustering distribution generator document allow recover cluster identity document useful think difference topic model mentioned multiple_times particular distribution document clustering model topic model multiple_times different second word distribution going generate words case topic modeling distribution doesnt generate words multiple distribution generate words think special case probability choosing particular distribution equal means stick particular case clearly longer mixture_model cause theres certainty going use precise distributions generating document going case estimating word distribution based thats connection discussed_earlier cases generative_model solve problem look theta think design design model step write likelihood_function look estimate case whats likelihood_function going similar seen topic models recall likelihood_function looks like plsa realize general probability observing data point mixture_model going sum possibilities generating case going k topics generate document inside sum recall formula looks like product probabilities probability choosing probability observing particular data point map formula kind formula probability observing document d basically sum case different simplified situation case sum case probability choosing world theta theta right probability multiplied probability observing document particular expand probability observing document product observing word x assumption word generated_independently probability document product probability word form similar topic model useful think difference purpose copying topic model formula looks similar ways theres particular differences mixture_model document clustering product thats corresponding assumption 1st choice choosing distribution stay distribution generate thats product inside sum corresponds topic model sum actually inside product thats cause generated word thats product generate word decision distribution sum general ideas mixture models estimate models em_algorithm discuss
lecture continued_discussion generative probabilistic_models text lecture going continue talking tax capture text clustering particularly generative probabilistic_models slide seen_earlier written likelihood_function distributions component mixture_model document lecture going generalize include k look formula think question generalize realize need add terms like add thetas probabilities thetas probabilities generating d precisely going general presentation mixture_model document cases follow steps generated think data right case data collection documents n documents denoted talk think case design mixture k unigram_language little bit different topic similar set theta denote word distributions corresponding k unigram_language p theta probability selecting k distributions generate note goal find clusters actually general notion probability later allow assign cluster highest probability able generate result recover model basically following assumption generation choose theta according probability theta generate words document note important use distributed words different topic model likelihood_function like look notation second_line notation changed use unique word vocabulary product instead particular position x sub j w change notation change allows estimation formulas easily seen change topic model presentation basically product probabilities lack talk parameter simply use maximum_likelihood estimator thats standard way things familiar different estimate parameters allocate clusters documents lets look situation closely repeated mixture_model think estimate model actually information need clustering right example represents content actually helps summarize cluster look terms cluster word tell p theta indicating size cluster tells likely cluster generate likely cluster generate document assume larger cluster note unlike plsa probability theta dependent recall topic choice document actually depends means document potentially different choice topics generic choice probability course given particular document infer topic generate document sense document dependent probability lets look key problem assigning document clusters assigning clusters documents lets compute c sub d values range k indicate cluster assigned lets think way use likelihood assign d cluster corresponding topic likely generate means going choose distributions gives d highest words distribution content matches d intuitively_makes approach consider size clusters better way use likelihood case prior p going use base formula compute posterior_probability theta given choose theta based posterior_probability following slide case going choose theta large p means large cluster high probability generating going favor cluster thats large consistent intuitively_makes sense chance document large cluster generally higher small means estimate parameters model easily solve problem document discuss actually compute estimate
lecture continued_discussion generative probabilistic_models text lecture going finish discussion generative probabilistic_models text slide seen define mixture_model text clustering likelihood_function looks like compute maximum liklihood estimate estimate lecture going talk exactly going compute maximum_likelihood cases em_algorithm solve problem mixture heres detail em_algorithm document understood eml works topic models plsa think similar need adapt little bit new mixture_model recall em_algorithm starts initialization happened topic going repeat likelihood step e_step m_step m_step going infer distribution generate introduce hidden_variable zd document value variable value range k representing k different specifically basically going apply bayes_rule infer distribution likely generated document computing posterior_probability given know proportional probability selecting distribution p theta probability generating document distribution product probabilities words cases useful kind remember normalizer constraint case know constraint probability e_step probabilities z equals sum cause document generated precise k probability generator constraint easy compute distribution proportional right compute product simply_normalize probabilities 1 thats e_step e_step know distribution likely generated document d m_step going relist parameters based infer z_values knowledge district generate estimation involves kinds p theta probability selecting particular observe dont knowledge cluster likely observed documents collect infer cluster likely proportional sum probability z sub dj gives evidence said generate document normalize p theta_sub kind parameters probabilities words distribution cluster similar case pulled counts words documents inverted generated particular topic theta allow estimate words actually generated counts probabilities probabilities note important understand constraints precisely normalizers formulas important know distribution example probability theta overall key topics thats k probabilities sum probability word given theta probability distribution probabilities lets look look simple example ive_shown initializer values lets assume randomly initialized probabilities selecting equally_likely lets consider document words sorry occurrences text occurrences medical health occur document thing hidden document use hidden_variable plsa 1 hidden_variable thats output mixture_model case output mixture_model observation mixture_model document 1 hidden_variable attached hidden_variable tell distribution generate document going values indicate infer distribution generate d use bayes_rule looks like order topic setup want generate things theater subway selected given p 01 generating words document occurrences text occurrences thats numerator product probability selecting theta probability generating document theta denominator sum possibilities generating document plug numerical values case document likely generated theta 1 likely theta problem easily compute probability z 2 given document going use constraint right going 1 100 101 important note computation potential problem underflow look numerator original numerator denominator involves computation product small imagine document words going small value cause problem solve use average solutions compute average district called theater average distribution comperable terms quantities divide numerator denominator basically normalizes probability generating document average word exact normalizer numerator denominator value expression normalization numerators denominators manageable overall value going small avoid underflow times use logarithm product convert sum log help preserve precision case use logarithms solve problem theres sum denominator kind normalizes effective solving problem technique thats useful lets look m_step e_step estimate distribution likely generated document d1 likely d2 like second topic lets think need compute m_step basically need estimate lets look p theta 1 p theta estimate intuitively pull z probability z probabilities e steps right documents theyre likely silouan intuitively high probability right case average probabilities 6 theta 1 theta 1 likely theta probability theta 2 world probabilities intuition going order estimate probabilities words theta going look documents generated scylla going pull words documents basically specifically going use counts text documents estimate probability tax given awhile use raw counts total discount probabilities document likely generated theta gives fractional counts council normalized order normalize probabilities words summarize discussion generating models showed slight variation model clustering documents shows power generating models general changing generation assumption changing model slightly achieve different goals capture different patterns text case class represented unigram_language model word distribution thats similar topic word distribution actually generates term cluster document generated choosing unigram_language model generating words document single language_model different topic model generate words document multiple unigram_language estimated model pamateter topic capitalization cluster probabilistic assignment document probabilistic assignment useful want achieve harder clusters mainly partition documents disjoint force document cluster corresponding water thats likely generated weve shown em_algorithm maximum case need use special normalization technique avoid
lecture similarity based_approaches text lecture going continue discussion text particular going cover different kind approaches generative similarity based_approaches general idea similarity based clustering explicitly specify similarity function measure similarity 200 text contrast generative_model implicitly define clustering_bias particular objective_function like likelihood_function process driven optimizing likeable explicitly provide review think similar useful allows inject particular view similarity clustering similarity function aim optimally partitioning partitioning data clusters different anne try maximize intragroup similarity minimize intergroup ensure objects group similar objects different groups similar general goals theres tradeoff achieving different methods similarity based general think distinguish strategies high progressively construct hierarchy leads hierarchical clustering distinguishes ways construct hierarchy depending started collection divide collection start individual objects gradually_group called agglomerative gradually_group similar object larger larger clusters case gradually partitioning data set smaller smaller general strategy start initial tentative_clustering iteratively improve leads flat example k said different clustering methods coverage custom methods scope talk representative hierarchical agglomerative clustering agency lets look agglomerative hierarchical case giving similarity function calls measure similarity objects gradually_group similar objects profession form larger larger groups form hierarchy stop stopping number classes achieved threshold similarity different variations mainly differ ways computer group similarity based individual object lets illustrate induce structure based start text objects measure course based provider similarity function pair highest similarity going maybe highest gradually_group time going pick highest similarity similarity pairs binary tree eventually depending applications use hierarchy structure browsing example choose cut come use threshold cut cut high level general think implement algorithm realize specified compute group given similarity function objects group groups need assess similarity different ways theres popular methods single link complete link average link given groups singling algorithm going define group similarity similarity closest repair complete link defines similarity groups similarity father sister average link defines similarity average similarity pairs easier understand methods groups g1 g2 objects group know compute similarity question compute similarity groups general basis similarities objects terms single link looking closest case pairs objects define similarity long close orders close optimistic view complete link hand sense pessimistic taking similarity farthest appear similarity going sure groups having high similarity pair objects group insured high link takes average different ways computing group similarities need different clustering algorithms generally different useful look differences single expected generate loose reason long objects similar groups bring think similar having parties people means groups groups people putting long group person connected leaders groups good relationship bring case cluster rules theres guarantee members groups actually far case based individual decision sensitive complete linker opposite situation expect clusters anne based individual decision sensitive continue analogy having party people complete link mean groups come want people unlikely talk comfortable talking ensure class average link course group decision going insensitive practice best depend application need loose classes aggressively cluster maybe simple english times need tight clusters completely completely better general empirically evaluate methods application know lets look example method similarity based classroom called k means clustering represent text object term vector assuming similarity function defined going start tentative_clustering result selecting kate randomly selected vectors centroids k clusters treat sentence represent gives initial tentative going iteratively improve process goes central eastside going assign vector cluster hosts entry closest current basically going measure distance vector centroids closest class object assignment objects clusters going partition objects k clusters based tentative_clustering going recovery compute centroid based allocated objects adjust centroid repeated process similarity based objective_function case cluster sum squares converges theoretically process actually going minimize cluster sum squares define objective_function given k shown process converge local think process remind em_algorithm mixture_model algorithm similar em_algorithm mixture_model specifically predators em_algorithm random inner inner initialization eml recall going repeat eastep m_step improved primary case going improve clustering result iteratively 2 steps fact steps similar em_algorithm allocate vector clusters based tentative_clustering similar inferring distribution generally document mixture_model essentially similar whats difference differences dont probabilistic location case going data point closest cluster going theres choice going 70 belonging going probability going object precisely e_step probabilistic location split going exactly distribution generate data going adjust centroid similar m_step estimate thats better estimate better clustering result adjusting note central adjusted based average cluster similar m_step counts pull counter normalize difference course difference instep going consider probabilities count points case k means going count objects allocated cluster subset data em_algorithm principle consider data based probabilistic nature similar thats maximizing defined objective_function guaranteed convert converted local summarize discussion clustering methods discussed model based_approaches mainly mixture_model use implicitly similarity define clustering_bias theres explicit definer similarity model defines clustering_bias clustering structure built generated thats use potentially different model recover different complex generative models discover complex clustering talk easily design generated model generate hierarchical use prior customize clustering algorithm example control topic 1 cluster multiple disadvantage approach easy way direct control similarity want hard inject explicit definition similarity talked similarity based_approaches approaches directly specify similarity potential disadvantage object function k means algorithm clearly defined objective_function similar model based hierarchical clustering algorithm specify objective_function clear exactly approaches generate term clusters document term clusters general generated representing term text example context term representation term paradigmatic_relation certainly cluster terms based actually tax course term clusters generated generative models
lecture evaluation text far talked multiple ways text clustering know method_works best talk evaluation clustering_bias introduced objects similar depending look clearly specify perspective problem clustering perspective important look slide different ways cluster ask question best better actually theres way answer question knowing wed like cluster based shapes cluster based thats precisely perspective clustering_bias crucial general evaluate text clusters direct evaluation indirect directl valuation want answer following question close system generated clusters ideal clusters generated humans closeness assessed assessed multiple perspectives help characterize quality clustering results multiple want quantify closeness allow easily compare different methods based performance finally case essentially inject clustering_bias basically humans bring needed desired clustering_bias exactly general procedure look given test set consists lot text objects humans create ideal clustering going ask humans partition objects create gold_standard use judgments based need particular application generate think best clustering compare system generated clusters test ideally want system results human generated results general going like qualify similarity system generated clusters gold_standard clusters similarity measured multiple perspectives measures quantitatively evaluate cluster clustering result commonly measures include purity measures cluster similar objects cluster gold_standard normalized mutual_information commonly measure basically measures based identity cluster object systemgenerated predict cluster object gold_standard vice mutual_information captures correlation cluster labels normalized mutual_information quantifying similarity evaluation f_measure possible thorough discussion evaluation evaluations scope ive suggested reading end look want discuss high level ideas allow think evaluation 2nd way evaluate text clusters indirect case question answer useful clustering results intended applications course application specific question usefulness going depend specific case clustering_bias imposed intended counts best clustering result dependent procedure wise create test set text objects intended application quantify performance case care contribution clustering baseline_system current system hope add clustering improve baseline_system different clustering method trying experiment hope better idea case baseline_system work add clustering algorithm baseline_system produce clustering going compare performance clustering system baseline_system terms performance measure particular case indirect evaluation clusters theres explicit assessment quality clusters assess contribution clusters particular summarize text clustering useful unsupervised general text mining technique particularly useful obtaining overall picture text needed explore text step deal lot text second application second kind application discover interesting clustering structures text data structures approaches text clustering discussed model based_approaches similarity based_approaches general strong clusters tend matter effectiveness method highly depends desired clustering_bias captured appropriately right generative_model model design appropriate clustering right similarity function explicitly define deciding optimal number clusters difficult problem classroom methods thats unsupervised algorithm theres training_data guide select best number methods automatically determine number general implied application clustering_bias thats clearly defining clustering_bias impossible optimal number cluster important use application determine number example clustering search results obviously dont want generate 100 clusters right number dictated interface situations able use fitness data assess weve_got good number clusters explain data vary number clusters watch fit general add components mixture_model fit data better set probability new component 0 cant general fit data worse question add components able significantly improve fitness data determine right number finally evaluation clustering results directly like order good sense method_works heres suggested reading particularly useful better understand measures calculated clustering
lecture text lecture going talk text important technique text data mining relevant discovery different kinds knowledge related topic mining thats analyzing text data based predefined secondly related opinion_mining sentiment_analysis discovering knowledge observer human categorize authors example based content articles general categorize observer based finally related text based use text categorization techniques predict variables real world remotely related text important technique text data overall plan covering going talk text categorization interested going talk text categorisation followed evaluate categorisation_results problem texture categorisation defined given set predefined_categories possibly forming set training examples training set labeled text means text objects labeled known categories task classify tax object predefined_categories picture slide_shows text categorization lot text objects processed categorisation system general assign categories documents shown categorisation_results assume availability training examples documents tagged known categories examples important helping system learn patterns different categories help system learn categories new tax objects specific examples text categorization fact text objects vary categorize passage sentence collections text case clustering units analyzed vary lot creates lot secondly categories vary generally distinguish kinds internal categories characterize content text example topic sentiment categories generally content tax objects direct characterization kind external categories characterize entity associated text example authors entities associated content use content determine author written example thats called author meaningful categories associated text data theres meaningful connection entity text example collect lot reviews lot reviews text data help infer properties product case treat categorization categorize restaurants categorize products based corresponding example external specific examples news categorization common news agencies like assign predefined_categories categorize news generated literature article categorizations important task example biomedical domain mesh annotations mesh stands medical subject ontology terms characterize content literature articles example application spam email detection filtering right spam filter help distinguish spam legitimate emails clearly binary classification sentiment categorization product_reviews tweets kind applications categorize content positive negative positive negative sentiment categories text application automatically email routing sorting want automatically sort emails different folders thats application text categorization folder important kind applications routing emails right person helpdesk email_messages generally routed particular person handle different people attempt handle different kinds requests cases person manually assign messages right imagine build automatic text categorization system help routing classify incoming request categories category actually corresponds person handle finally author mentioned application example text actually infer properties variants problem formulation simplest case binary_categorization categories examples like information retrieval search_engine applications distinguish relevant_documents non_relevant documents particular spam filter distinguishing spams non classification opinions categories positive general case kcategory categorization applications categories topical categorisation example multiple email routing example multiple folders route email right person handle multiple people clasify cases kinds variation hierarchical categorization categories form hierarchy topical hierarchy variation joint thats multiple categorization tasks hope kind joint try leverage dependents tasks improve accuracy individual binary_categorization fundamental partly simple partly cause actually perform categorization example k category categorisation task actually performed binary_categorization basically look category separately binary_categorization problem object meaning hierarchical category categorisation progressively flat categorisation categorize objects small number high level categories inside categorize sub categories text categories important showed applications general text categorization helps enrich text representation thats achieve understanding text data thats useful text categorisation text represented multiple levels meaning keyword bag words representation lot text processing add categories provide 2 levels semantic categories assigned directly indirectly useful example sentiment categories useful author attribution directly example semantic categories facilitate aggregation tax content applications text example want know overall opinions product categorize opinions individual review positive negative allow easily aggregate sentiments tell 70 views positive 30 negative categorization harder aggregate provides concise way coding text sense based miss seeing applications text categorization called text coding encoding controller second kind reasons use text categorization infer properties text categorisation allows infer properties entities associated text means use text categorization discover knowledge world general long associate entity text data use text data help categorize corresponding useful think information network connect entities text obvious entities directly connected authors imagine authors affiliations authors ages things actually connected text data connection predictions general way allow use text mining sorry text categorization discover knowledge useful especially big text analytics interested text data extra sensor data collected humans infer certain desicion non text data specifically example think examples inferring properties example discovery non native speakers language categorizing speakers example predict party affiliation politician based political speech example text data infer knowledge real nature problems thats defined text categorization
lecture methods text lecture going discuss text methods text categorization method idea determine category based rules design carefully reflect domain_knowledge categorization example want topical categorisation news_articles news article mentions word like game sports times going things like allow deterministically decide category strategy work following conditions categories defined allows person clearly decide category based clear secondly categories easy distinguish based surface features text means superficial features like keywords easily identify text example special vocabulary known occur particular category effective easily use vocabulary pattern vocabulary recognize sufficient designing rules thats case method effective provisions general problems course labor requires lot manual obviously cant kinds categorization scratch different problem becauses different rules needed doesnt secondly handle uncertainties rules arent 100 reliable example looking occurrences words text try decide actually hard 1 correct example games sports basketball sure imagine text articles mention exactly sports marginally touching main topic topic different topic thats disadvantage approach finally rules inconsistent need concern robustness specifically results categorization different depending rule case face uncertainty decide order applying rules combination results problems approach turns problems solved alleviated machine_learning machine_learning methods automatic automatic quotation marks cause theyre completely automatic require manual specifically use human experts help human experts annotate datasets category labels tell computer documents receive called training_data secondly human experts need provide set features represent text object potentially provide clue need provide basic features computers case text natural choice word feature common choice course sophisticated features like phrases policy feature tags syntactic_structures human experts provide use machine_learning learn soft rules categorization training_data soft rules means going decide category assigned going rule deterministic use similar saying matches game sports times likely going exactly sure instead going use probabilities weights combine multiple evidences learning process basically going figure features useful separating different going figure optimally combine features minimize errors categorisation training_data training_data basis train classifier applied new text object predict likely category thats simulate prediction human assign text human use machine_learning text categorization talk problem general setting supervised learn classifier map value x map x text y categories set categories classifier value x input generate value y output hope output y right category x correct course judged based training_data thats general goal like machine_learning problems supervised learning problems given examples input output function computer going figure function behaves like based examples try able compute values future access general methods rely discriminating features text objects distinguish different categories thats features important provided combine multiple features weighted matter weights optimized minimize errors training_data ultimately learning processes optimization_problem objective_function tide errors training_data different methods tend vary ways measuring errors training_data optimize different object function called loss function cost tend vary ways combining features linear_combination example theyre powerful non linear_combination nonlinear models complex tradeoffs lead different variations learning general distinguish kinds classifiers high level going generative called discriminative_classifiers generative classifiers try learn data looks like attempts model join distribution data label factored product distribution labels join probability sorry conditional probability x given y model distribution labels model data generated given particular estimate models compute conditional probability label_given data probability data given label distribution base important thing cause conditional probability label directly decide label approaches objective_function actually likelihood model data generated indirectly captures training model data category accurately classify example naive_bayes kind approaches called discriminative_classifiers classifiers try learn features separate categories directly tackle problem categorisation separation sorry discriminative_classifiers attempted probability label_given data point objective_function tends directly measure errors categorisation training_data examples include logistical_regression support vector machines k nearest cover classifiers detail
lecture use generative probabilistic_models text general kinds approaches text categorization machine_learning generative probabilistic_models discriminative lecture going talk generative lecture going talk discriminative problem text categorization actually similar document clustering assume document belongs category main difference clustering dont know predefined_categories fact thats goal text want find clusters case categorization given kind predefined_categories based categories training_data like allocate document categories multiple similarity problems actually adapt document clustering models text understand use generative models text categorization perspective slide weve talked text clustering assume multiple topics represented word topic 1 estimate model faced problem deciding cluster document d belong question boils decide theta generate suppose d l words represent represent compute probability particular topic word distributions theta generate document general use bayes_rule prior need consider topic cluster higher prior likely document cluster favor topic word distribution explain content want pick topic thats high specifically multiply choose topic highest rigorously going choose topic maximize posterior_probability topic given posterior becausw p theta prior thats belief topic observe conditional probability posterior_probability topic observed document bayes_rule allows update probability based prior shown prior related posterior left related word distribution explains document related find topic highest posterior_probability equivalent maximize product seen multiple_times change probability document product probability word thats weve assumption independence generating word seen document clearly assign documentary category based information word distributions categories prior idea directly adapted categorization precisely naive_bayes classifier information looking categorization problem assume theta represents category accurately means word distribution characterizes content documents category precisely like text going assign document d category highest probability generating words going maximize posterior_probability related prior likelihood seen previous naturally decompose likelihood changed notation write product product words vocabulary document doesnt contain words product accurately representing product words word doesnt_occur count 0 count effectively product words basically naive_bayes classifier going score category document notice involves product lot small probabilities cause underflow way solve problem logarithm function doesnt change order categories help preserve function actually use score category going choose category highest_score called naiyes bayes keyword bayes understandable applying bayes_rule posterior_probability topic product likelihood called naive weve assumption word document generated_independently naive assumption reality generated_independently word words likely example seen word like text makes categorization clustering likely appear seen assumption allows simplify problem actually effective text categorization know kind model doesnt example assume words dependent bigram language_model trigram language_model course use mixture_model model document looks like nature bayes_rule classification actual generative_model documents vary talk simple simplest question sure theta actually represents category accurate clustering learned category word distributions category case sure theta represents category think question youre likely come idea training_data text categorization typically assume training_data available documents known generated words documents known categories assigned course human t1 represents set documents known generated category t2 represents documents known generated category look picture model simplified unigram_language longer mixture_model know distribution generate theres theres mixing different estimation problem course simplified general imagine want estimate probabilities marked probabilities estimate order categorization probability theta indicates popular category likely observed document kind word distributions want know words high_probabilities idea use observed training_data estimate general separately different thats documents known generated specific category know sense irrelevant categories statistical estimation observed data model want guess parameters want best_guess problem times havent thought problem havent seen naive_bayes classifier useful pause video moment think solve let state problem lets think know word distribution generate generated word document independently know observed set n sub documents set documents generated category generated word question guess estimate probability word distribution guess prior probability category course second probability depends likely documents right think moment use training_data including documents known k estimate spend time think help understand following spend time sure try solve problem best solve thought realize following whats basis estimating prior probability category observed lot documents intuitively seen lot documents sports medical science guess probability sports category larger prior category basis estimating probability word category youll assuming words observed frequently documents known generated likely higher probability thats maximum_likelihood estimator estimate probability answer question category popular simply_normalize count documents n sub denotes number documents simply_normalize count words probability proportional size training dataset thats size set t word time lets considering category word higher probability simply count word occurrences documents known generated counts word normalize counts distribution words probabilities words case proportional count word collection training t sub thats denoted c w t notice write probability estimate form proportional certain number becausw constraints distributions normalizer dictated case useful think constraints kinds figure answer question know normalize counts good exercise work issue naive_bayes fact smoothing general problem estimate language models happen observed small smoothing important technique address data case training_data set small data set use maximum_likelihood estimator face problem zero means event estimated probability 0 case seen word training documents lets category estimate 0 probability word generally smoothing sure zero reason smoothing way bring prior knowledge generally true lot situations data set small tend rely prior knowledge solve case prior knowledge says words zero probability smoothing allows inject prior sure word zero reason obvious explain moment help achieve discriminative weighting called idf_weighting inverse_document frequency weighting seen mining word smoothing general added pseudo_counts sure event zero possible way smoothing probability category simply add small nonnegative constant delta pretend category actually extra number documents represented denominator add k multiplied delta want probability total weve added delta k times k sum add k multiplied delta total pseudo_counts add interesting think influence obvious delta smoothing parameter meaning larger delta smoothing means rely pseudo_counts ignore actual counts delta set imagine happen delta approaches positive infinity going word infinity sorry word infinity documents theres distinction delta zero original estimate based observed training_data estimate probability word distribution case find useful use nonuniform pseudo_counts add pseudocounts word thats mu multiplied probability world given background_language theta_sub b background model general estimated large collection text case use set training_data estimate background_language dont use use larger text data use background_language model add pseudocounts find words receive words common higher probability background_language model pseudocounts added words higher rare words hand smaller addition background model cause nonuniform smoothing word distributions going bring probability common words higher level background helps difference probability words smaller category help background words like high_probabilities longer important category documents contain lot occurrences word estimate influenced background model consequences categorization words tend influence decision words small background_language model words dont help background_language model difference primarily differences occurrences training documents different smoothing parameter mu controls smoothing like delta easily understand add mu denominator represents sum pseudo_counts add mu nonnegative constant empirically set control interesting special_cases lets think mu approaches happen case estimate approach background_language model tend background_language model bring word distribution background_language essentially removes difference obviously dont special_cases think background model suppose actually set uniform distribution lets size word smoothing formula going add delta going add constant pseudo count general naiyes bayes categorization smoothing probabilities compute score category document choose category highest_score discussed_earlier useful understand naive_bayes scoring_function actually makes sense understand adding background_language model actually achieve effect idea idf_weighting penalize common right suppose categories going score based ratio probability ann lets scoring_function score document going score based probability ratio larger means likely category larger score likely document bayes_rule write ratio follows generally logarithm ratio avoid small probabilities formula second_line interesting scoring_function deciding look function actually log prior probability ratio category doesnt depend document says category favor category second sum right words observed document general consider words going collect evidence category inside sum product count count word serves feature represent collect second weight weight word extent observing word helps contributing decision document remember higher scoring_function likely look ratio basically sorry weight basically based ratio probability word essentially comparing probability word distributions higher according theta according theta 2 weight positive means observe likely category observe word likely document classified hand probability word theta smaller probability word theta 2 weight negative evidence supporting means observe word likely document actually theta formula makes lot sense going aggregate evidence sum words collect document help decision feature weight tells feature support category support support category estimated log probability naive_bayes finally constant bias formula actually formula generalized accommodate thats ive introduced introduce beta zero denote bias fi denote feature beta sub denote weight generalization general represent document feature vector f course case fi count word general features think relevant example document_length font size counts patterns scoring_function defined sum constant beta zero sum feature weights hf sub feature value multiply value corresponding weight beta sub sum evidence collect course parameters betas weights appropriate settings weights expect scoring_function work classify like case naive_bayes clearly naive_bayes classifier special case general actually general form close classifier called logistical_regression actually conditional approaches discriminative approaches going talk approaches later want know theres strong connection close connection kinds approaches slide_shows naive_bayes classifier connected logistic_regression discriminative_classifiers tend use general form accommodate features solve
lecture discriminative_classifiers text lecture going continue talking text categorization cover discriminative slide seen discussion naive_bayes classifier shown naive_bayes classifier tries model generation text data categories actually use bayes_rule eventually rewrite scoring_function slide scoring_function basically weighted combination lot word features feature_values word count feature weights log probability ratios word given kind scoring_function actually general scoring_function general represent text data feature course features dont words features signals want mentioned precisely similar logistic_regression lecture going introduce discriminative_classifiers try model conditional distribution labels given data directly bayes_rule compute seen naive_bayes general idea logistical_regression model dependency binary response variable y denoted changed notation x feature_values recall previous slide fi represent feature_values use notation x vector common introduce machine_learning algorithms x input m feature value x sub goal model dependency binary response variable categorization problem categories lets theta 1 theta 2 use y value denote y 1 means category documents class theta 1 goal model conditional probability y_given x directly opposed model generation xampy case naive_bayes advantage kind approach allow features words modeling generation vector plug signals want potentially advantages text specifically logistic_regression assumed functional form y depending x following closed closely related log log odds introduced naive_bayes log probability ratio categories seen previous meant right case naive_bayes compute bayes_rule eventually reached formula look looks actually assume explicitly model probability y_given directly function specifically assume log ratio probability y 1 probability y function function x linear_combination feature_values controlled beta_values know probability y 0 1_minus probability y 1 written log odds logistic_regression basically assume probability y 1 given x dependent linear_combination possible ways assuming dependency particular form useful nice rewrite question actually express probability y_given x terms x taking getting rid logarithm functional form called logistical function transformation x xs mapped range values zero thats precisely function form looks basic_idea logistic_regression useful classifier lot classification tasks including text cases model interested estimating parameters fact machine_learning set model set objective_function model classifier step compute parameter_values general going adjust parameter_values optimize performance classifier training_data case lets assume training_data training_data x y pair basically feature vector x known label x y case interested maximizing conditional condition likelihood basically model y_given observed like modeling x going note conditional probability y_given precisely want likelihood_function product training case modeled probability observing particular training given particular xi likely going observe corresponding y course y zero fact function form vary depending y sub taking thats basically logistical_regression 0 zero use different form thats minus probability y 1 right key point function form depends y different form think want maximize probability basically going want probability high possible means document document going maximize value whats going happen actually value small equivalent basically maximize conditional likelihood going basically try prediction training_data accurate cases compute maximum_likelihood estimator basically lets find beta value set beta_values maximize conditional gives standard optimization_problem case solved newtons method popular way solve methods end going set beta_values beta_values defined scoring_function help classify document right whats betavalues known need compute xis plugging values probability document ok logistical_regression lets introduce discriminative classifier called k nearest general thorough introduction clearly scope course machine_learning course read machine_learning want include basic introduction commonly classifiers use text second classifier called k nearest approach going estimate conditional probability given data different idea training examples text object want classify going find k examples training set similar text basically find neighbors text object training_data found found neighborhood found objects object interested classifying found k nearest thats method called k nearest going assign category thats common basically going allow neighbors vote category object interested means particular category lets category 1 going current object approach improved considering distance neighbor current basically assume close neighbor saying category object neighbor influence vote weighted sum votes based general idea look neighborhood try assess category based categories intuitively_makes lot mathematically regarded way directly estimate conditional probability label_given data p y_given im going explain intuition moment proceed let emphasize need similarity function order note naive base classifier need similarity logistical_regression talk similarity explicitly requires similarity similarity actually good opportunity inject insights basically effective features objects category look similar distinguishing objects different design similarity function closely tied design features logistic_regression classifiers lets illustrate knn suppose lot training ive colored differently different suppose new object center want according approach going find lets think special case finding neighbor closest case lets assume closest neighbor box filled diamonds object category lets going going assign category text lets look possibility finding larger lets think case going include lot solid field boxes red case going notice neighbors actually neighbors different vote conclude object actually different illustrates k nearest neighbor works illustrates potential problems basically results depend k k important parameter intuitively imagine lot neighbors object ok lot neighbors help decide decision hand want find neighbors right votes hand try find neighbors actually risk getting neighbors similar instance actually far away try neighbors neighbors vote neighbors arent necessary helpful similar parameter set empirically typically optimize parameter cross basically youre going separate training_data parts youre going use actually help parameter k parameters classifiers youre going assume number works training set actually best future mentioned knn actually regarded estimate conditional probability y_given x thats category discriminative key assumption approach distribution label_given document probability category given example probability theta given document d locally smoothed means going assume probability documents suppose draw neighborhood going assume neighborhood data instances similar going assume conditional distribution label_given data d different different going assume probability theta given d similar thats key assumption thats actually important assumption allow lot machine_learning reality true course depend define similarity neighborhood largely determined similarity similarity function captures objects follow similar distributions assumption similarity function obviously assumption problem classifier lets proceed saying order estimate probability category given document try estimate probability category given entire benefit course bringing additional data points help estimate precise idea basically use known categories documents region estimate given formula count topics region normalize total_number documents numerator c theta r count documents region r category training documents know theyre simply count times seen sports times seen science denominator total_number documents training documents region gives rough estimate category popular neighborhood going assign popular category data objective falls
lecture continued_discussion discriminative_classifiers text lecture introduce discriminative classifier called support vector machine vm popular classification method shown effective text introduce classifier lets think simple case categories public categories season season want classify documents categories going represent document feature vector idea classifier linear similar seen logistic_regression going sign function value positive going object category going category 2 makes 0 decision boundary general high dimensional_space zero point corresponds simple case dimensional_space x1 case corresponds line defined parameters beta0 beta 1 beta heading direction shows increase x1 x2 know beta1 beta2 different signs negative lets assume beta negative beta interesting examine data instances sides line incidences visualized circles class diamonds question point like ask question whats value expression classifier data think basically working evaluate value said value positive gonna category negative going intuitively line separates categories expect points positive points question assumption mentioned lets examine particular point think sign expression examine sign simply look compare lets value lets compare identical x higher lets look sign coefficient x2 know means f value point higher f value point means positive right know general functions verify points negative kind linear classifier linear separator separate points natural question linear separate best ive want lying separate line course determined vector beta coefficients different coefficient different imagine lines gamma example line separate course lines wont separate bad question multiple lines separate clauses line best fact imagine different ways choosing logistical_regression classifier seen_earlier actually uses criteria determine line linear separate uses conditional likelihood training_data determine line vm going look criteria determining lines best time criteria tide classification basic_idea choose maximize margin ive_shown daughter lines indicate boundaries data class margin simply distance line separator closest points margin ive_shown define order separate maximizing margin kind middle boundaries dont want separator inducing intuitively_makes lot basic_idea going choose linear separator maximize slide ive changed notation im going use didnt know parameters instead im going use w w denote dont w actually wait set im locates denote beta zero bias instances represented use vector form transpose w vector multiplied feature p biased constant w set weights wait feature m features aim weights represented similarly data text object represented feature vector number xi future example word verify multiply vectors dot_product form nia separate different way use way consistent notations people usually use talk better connected slides maximize margins separate means separate determined data points data points support illustrated support vectors class porters define margin imagine know support vectors center separate line data points actually dont change data points wont affect margin separate stay mainly affected support vector sorry mainly affected support vectors thats called support vector question course set optimize line actually find line equivalent finding values wampb determine exactly simplest case linear osfm simple optimization_problem lets recall classifier linear separator weights features main goal learn weights classifier x category going assumption linear uvm going seek parameter_values optimize margins training training laid basically like classifiers set training points know x vector corresponding label define values values 01 seen negative positive corresponding categories ive_shown wonder dont define zero instead having negative 11 purely mathematical convenience goal optimization sure labeling training_data means yi known label instance xi like classify value choose use threshold easily affect constant parameter_values bampw right hand negative means different class want classifier small fact negative want value equal different instances different kinds cases convenient chosen negative category cause turns easily combine multiplied classifier value larger equal 1 constraint left yi negative equivalent inequality actually captures constraints unified way thats convenient way capturing whats second goal thats maximizing margin right want ensure separate training_data cases separate data like choose separate largest margin shown related magnitude sum squares small value means eyes weve assume constraint getting data training set classified objective thats tide maximization margin simply maximize sorry minimize w transpose multiplied w denote file basically optimization_problem right variables optimize weights b linear constraints objective_function quadratic function quadratic program linear constraints standard algorithms available solving solve problem obtain weights wampb defined classifier use classifier classify new texture previous formulation allow error classification data linearly means look nice seen previous slide align allow principle stay right want minimize training error try maximize case soft margin data points completely separate turns easily modify vm similar seen introduced extra cassie fact data instance going model error allow optimization_problem specifically added optimization_problem error constraint allow classifier mistakes kci allowed error set kci 0 original want instance classified accurately zero allow fact ci error large naturally dont want want minimize cassie needs minimized order control result objective_function add original 1 basically ensuring going minimize weights minimize errors simply sum ci model error allowed instance combine basically want minimize theres thats constant control tradeoff minimizing errors maximizing region margin c set zero original object function maximize dont optimize training errors set large value constraints easy thats good course set non 0 value positive settled large value objective_function dominated training errors optimization margin play secondary happens happen happen try best minimize training going care margin affects generalization capacity classifier future apparently parameter c actually carefully like case nearest neighbor way need optimize number need optimize c general achievable cross basically look empirical data values set order optimize modification problem quadratic program linear constraints optimization algorithm actually applied solve different version program obtained weights bias thats ready classifying new thats basic_idea summarize text categorisation methods introduced methods generative models discriminative methods tend perform similarly optimized theres clear winner pros cons performance different data sets different ann reason feature representation critical methods require effective feature representation design_effective feature set need domain_knowledge humans definitely play important_role new machine_learning methods like representation learning help learning common performing similarly data set different mistakes performance similar mistakes different means useful compare different methods particular problem maybe combine multiple methods cause improve robustness want symbol approaches combine different methods tend robust useful techniques introduce use supervised_machine learning general means methods actually applied text categorization problem long humans help annotate training_data set design features supervised_machine learning classifiers easily problems solve categorization allow characterize content text concisely categories predictor properties real world variables associated text computers course trying optimize combinations features provided different ways combining optimize different objects order achieve good performance require effective features plenty training_data general rule improve feature representation provide training_data generate performance affected effectiveness features choice specific feature design tends important choice specific design_effective features unfortunately application specific theres general analysis categorization problem try understand kind features help distinguish categories general use lot domain_knowledge help design way figure effective features error analysis categorisation_results example look category tends confused categories use confusion matrix examine errors systematically categories look specific instances mistake features allow insights design new error analysis important general thats insights specific finally leverage machine_learning example feature selection technique havent talked important trying select useful features actually trainer classifier training classifier help identify features high ways ensure sparsity meaning recognize example svm actually tries minimize weights features features falsely use small number techniques dimension reduction thats reduce high dimensional feature space lower dimensional_space typical biclustering features ways metrics factorization job techniques similar topic models discussed topic lda actually help reduce dimension imagine words original feature representation representation mapped topic space lets k topics document represented vector justice k values corresponding let topic define k dimensional_space instead original high dimensional_space corresponding way learn factor features especially use categories supervise learning low dimensional original word features combined latent dimension features low dimensional_space features provide multiresolution representation deep learning new technique developed machine_learning particularly useful learning representations different learning refers deep neural kind classifier intermediate features embedded model highly non linear reason advance allowed train complex network ann technique shown effective speech recognition computer vision recently applied shown promise important advantage approach relationship feature design learn intermediate representations compound features automatically valuable learning effective representation text texas domain cause words excellent representation text humans invention communication generous sufficient representing content theres need new representation people invented new words new reason value deep learning text processing tends lower computer vision speech recognition arent corresponding wedding deep learning promising learning effective features especially complicated tasks like sentiment_analysis shown effective provide replenishing goes bag training examples generally hard lot training examples involves human ways help assume low quality training examples called pseudo training example reviews internet overall train sentiment categorizer meaning want distinguish positive negative opinions categorize reviews assume star reviews positive training onstar negative course star mention negative opinions rain example high quality idea exploit unable data techniques called semi supervised_machine learning techniques allow combine label data unlabeled case actually easy mixture_model text clustering categorisation imagine lot unable text data categorization actually clustering text data learn try align categories categories defined training_data know documents fact use em_algorithm actually allow essentially pick useful words unlabeled think basically use lets naive_bayes classifier classify unlabeled text going assume high confidence classification results actually certainly training_data cause unlabeled data labeled category ones labeled label completely lets assume actually training label examples combine true training improve categorization method idea powerful enable data training_data different need use advanced machine_learning techniques called domain adaptation transfer learning borrow training examples related problem different categorisation involves data follow different distributions basically domains different need careful overfit training domain want use signals related training_data example training categorisation news immediately effective classifier classifying topics tweets learn news help categorizing tweets machine_learning techniques heres suggestion reading find details methods
lecture evaluation taxable weve talked different methods taxi categorisation method_works better particular application best way solving know evaluate categorisation_results general thoughts evaluation general evaluation kind empirical tasks categorisation use methodology developed 1960s information retrieval researchers called cranfield_evaluation basic_idea help humans create test_collection document tagged desired categories case search query documents retrieved called ground_truth ground_truth test_collection reduce collection test different systems compare different turn component system whats going basically way controlled experiments compare different methodology virtually tasks involve empirically_defined case going compare systems categorization results categorisation ground_truth created going compare systems decisions documents categories assigned documents humans want quantify similarity equivalently measure difference system output desired ideal output generated humans obviously higher similarity better similarity measured different lead different measures desirable measure similarity different perspectives better understanding results example interested knowing category performs better category easy categorize general different categorization mistakes different costs specific application ideally like model read papers texture catalyzation dont generally instead use simplified thats ok consider cost variation compare different interested knowing relative difference ok introduce bias long bias correlated particular expect effective method perform better effective measure measure introduce called classification_accuracy basically measure percentage corrective k categories denoted c1 ck n documents order d1 dn pair category document look system said yes basically assigned category document denoted y thats system similarly look humans human assigned category document plus thats means human think assignment correct incorrect theres combinations ends yes nos minus combinations total correct y plus minus kinds measure classification_accuracy similar count decisions correct normalize total_number know total_number multiplied number characters decisions obviously basically pluses n minus convenient measure number characterize performance method higher better method treated decisions equally reality theres decision example important decisions right documents maybe important divisions right categories detailed evaluation results strengths weaknesses different understand performance methods apa category document basis example shows clearly desicion errors having different causes spam filtering retrieved category categorization missing legitimate email 1 type letting maam come folder type types errors clearly different important miss legitimate ok occasionally let spam email come inbox error missing legitimate email high classification error classification_accuracy address theres problem imbalanced tests imagine theres test set instances 98 instances category 2 case simple baseline actually performs baseline simply instances major 98 case going appearing effective reality obviously good general use classification_accuracy measure want ensure classes wonder equal number example class minority categories classes tend overlooked evaluation classification_accuracy address problems course like evaluate results ways different said beneficial look actual multiple example look perspective document perspective based question divisions document general cases decisions think combinations depending system said yes depending human said correctly incorrectly yes human system said yes thats true positives system says yes actually system says yes human confirmed correct true system says yes human says thats thats false positive system says human says yes false missed system human said thats corrected thats true alright meshes better characterize performance phone numbers 2 popular measures precision_recall proposed information retrieval researchers 19 days evaluating searching standard system says yes ask question correct whats percentage correct decisions system says yes thats called true positive divided cases system says yes recall meshes called recall document called case divided true positive true positives false cases human says document represents old categories recall tells system actually assigned categories gives detailed view decision aggregate youre interested documents tell documents subset example allows analyze errors separate documents certain characteristic look pattern kind documents documents short gives insight improving similarly look popular category case going look good decision particular previous case define precision_recall basically answer questions different saw system says yes corrected means looking category documents assigned category recall tell category actually assigned documents useful combine precision_recall measure harmonic mean precision_recall defined ann controlled parameter beta indicate weather precision important recall important beta set measure called f1 case equal weight precision_recall measure cases combine results think best way case dont know thought combining arithmetic_mean right range obviously theres reason popular actually useful think think difference undesirable property arithmetic_mean basically obvious think case system says yes category tried compute precision_recall case basically kind measure arithmetic_mean going reasonable ff1 tends prefer tradeoff precision_recall values equal theres extreme case 041 value f1 low arithmetic_mean reasonably
lecture continued_discussion evaluation textual earlier introduced measures compute precision_recall category lecture going examine combine performance different categories different aggregate average title indicated called macro average contrast micro average talk category compute precision_recall f1 example category precision p1 recall r1 f value f1 similarly category 2 compute example aggregate precision values categories compute overall precision summarize seen data set aggregation different said case need aggregate different good think whats best way example consider arithmetic_mean use geometric_mean different behavior depending way got different terms method_works better important consider differences choosing right suitable difference example arithmetic_mean geometric_mean arithmetic_mean dominated high values geometric_mean affected low values want emphasize low values high values question related similar recall f score thats generate overall precision_recall f aggregation documents right exactly situation document computer recall completed computations documents going aggregate generate overall precision overall recall overall f examining results different angles useful depend general beneficial look results perspectives especially compare different methods different reveal method better measure situations provides insight understanding strength method weakness provides insight mentioned micro averaging contrast macro average talked case pull compute precision_recall compute overall precision_recall counting cases true positive cases false positive basically computing values fill contingency table compute precision_recall contrast macro averaging going category 1st aggregate document aggregate similar classification_accuracy introduced earlier problem course treat instances decisions appropriate applications especially associate example cost actually compute example weighted classification_accuracy associate different cost utility specific variations methods useful general macro average tends informative micro averaging reflect need understanding performance category performance document needed macro averaging micro averaging theyre common reported research_papers text categorisation_results actually evaluated ranking categorisation_results passed human example passed humans example news_articles tentatively categorized system human editors email_messages routed right person handling help desk case categorizations help prioritizing task particular customer service case results system score categorisation decision confidence use scores rank decisions evaluate results ranked_list search_engine evaluation rank documents response example discovery spam emails evaluated based ranking emails spam category useful want people verify spam right person ranked_list check verify reflect utility humans task better evaluate ranking accuracy basically similar case problem better formulated ranking problem instead categorization example ranking documents search_engine framed binary_categorization problem distinguishing relevant_documents useful users typically frame ranking problem evaluated ranked_list thats cause people tend examine results sequentially ranking evaluation reflects utility users_perspective summarize categorization evaluation evaluation important tasks dont right misleading results misled believe method better fact important measures reflect intended use results particular example spam filtering news categorization results maybe different need consider difference design measures generally need consider results processed user think users_perspective quality aspect quality tradeoffs multiple aspects like precision_recall need know application high recall important high precision ideally associate different cost different decision error course designed application specific commonly measures relative comparison different methods following classification_accuracy commonly especially balanced tester precision_recall f scores commonly reported characterize performances different angles variations like document based evaluation category evaluation average different micro versus macro general want look results multiple perspectives particular application perspectives important diagnosis analysis categorization methods generally useful look perspectives possible subtle_differences methods method weak obtain insights improving finally ranking appropriate categorisation task maybe better frame ranking task machine_learning methods optimizing ranking suggested_readings chapters book find discussion evaluation second paper comparison different approaches text categorization excellent discussion evaluate text
lecture opinion_mining sentiment_analysis covering lecture going start talking mining different kind knowledge knowledge observer humans generated text particular going talk opinion_mining sentiment_analysis discussed_earlier text data regarded data generated humans subjective_sensors contrast devices video recorder report whats happening real world objectively generate video data main difference text data data like video data rich rich opinions content tends subjective generated actually unique advantage text data compared data offers great opportunity understand text data understand opinions understand peoples preferences people lecture following_lectures mainly analyze opinions buried lot text lets start concept opinion easy formally define opinion define opinion subjective statement describing person believes highlighted words thats thinking little words help better understand whats opinion helps define opinion formally needed computationally solve problem opinion_mining lets look keyword contrast objective statement factual statements proved right key differentiating factor opinion tends easy prove wrong right reflects person contrast objective statement usually proved wrong example computer screen thats having contrast think sentence laptop best laptop nice screen statements subjective hard prove wrong opinion subjective lets look keyword person indicates opinion holder cause talk opinion opinion held thats target opinions course believes thinks implies opinion depend culture background context general person think differently different people different background think different analysis shows multiple elements need include order characterize whats basic opinion representation like include measurements right specify whats opinion opinion second specify whats opinion 3rd course want opinion content exactly opinion identify basic understanding opinion want understand want enrich opinion means want understand example context opinion situation opinion example time expressed like deeply understand opinion sentiment understand opinion tells opinion holders feeling example opinion positive negative opinion holder happy understanding obviously goes extracting opinion content needs lets simple example product case actually explicit opinion holder explicit target obviously whats opinion holder thats reviewer clear whats opinion target thats product example iphone_6 review posted usually extract information content course review text thats general easy product_reviews fairly easy analyze terms obtaining basic opinion course want information want know example review written want know sentiment review positive additional understanding course adds value mining case task relatively easy opinion holder opinion target lets look sentence case implicit holder implicit task general harder identify opinion holder thats governor identify target hurricane target hurricane whats opinion negative sentiment thats indicated words like bad identify new england unlike product review elements extracted natural_language processing_techniques task harder need deeper_natural language examples suggest lot work easily product_reviews thats analyzing sentiment news difficult analysis opinions product_reviews interesting fact going examine variations opinions lets think opinion holder individual group people opinion committee country opinion target vary 1 entity particular person particular product particular policy group product company specific attribute attribute entity battery opinion person comment persons opinion lot variation cause problem vary opinion content course vary lot identify sentence opinion phrase opinion longer text express opinion like furthermore identify variation sentiment emotion thats feeling opinion distinguish positive versus negative neutral happy versus sad finally opinion context simple context like different time different locations complex text background topic opinion expressed particular discourse context interpreted different ways expressed context context rich improve entire discourse context computational perspective interested opinions extracted text data turns differentiate distinguish different kinds opinions text data computation observer comment opinion target observed case authors example dont like phone thats opinion contrast text report opinions person observation persons opinion report example believe loves painting opinion expressed doesnt mean author loves clearly kinds opinions need analyzed different ways product_reviews opinions reviewer mention opinions friend friend right complication indirect opinions inferred opinions obtained making inferences whats expressed text necessarily look like example statement phone ran battery way factual statement cause know true false right statement infer negative opinions quality battery phone feeling opinion holder opinion holder clearly wish battery interesting variations need pay attention extract reason indirect useful extract person said product factual sentences like practical viewpoint dont necessarily extract subjective instead sentences opinions useful understanding person understanding product task opinion_mining defined taking text data input generate set opinion representation identify opinion holder target content ideally infer opinion sentiment content context better understand elements representation gave good example case product_reviews opinion holder opinion target explicitly identified thats turns simplest opinion_mining interesting think tasks simple cases easily build applications opinion_mining talked opinion_mining defined task lets talk little bit opinion_mining important identify major reasons 3 broad help decision help optimize look peoples_opinions look reader reviews order decision like buying buying product interested decide vote policymakers want know peoples_opinions designing new thats general kind broad second application understand people example help understand peoples help better serve example optimize product search_engine optimize recommender system know people interested people think help advertising course targeted advertising know kind people tend know like kind kind applications called voluntary support research surveys manual surveys questioning people need fill forms answer directly related humans sensors usually aggregate opinions lot humans kind assess general useful business intelligence product manufacturers want know products winning features product winning features competitive products market research understanding consumers opinions clearly useful data driven social science research benefit text mining understand peoples_opinions aggregate lot opinions social_media lot public information actually study example study behavior people social_media social networks regarded voluntary survey general gain lot advantage prediction task leverage text data extra data problem use text based prediction techniques help prediction improve accuracy
lecture sentiment assume elements opinion representation known task maybe sentiment classification shown suppose know opinion holder whats opinion target know content context mainly need decide opinion sentiment case sentiment classification understanding sentiment classification defined specifically follows input opinionated text output typically sentiment label sentiment tag designed polarity analysis categories positive negative emotion polarity characterize feeling opinion case polarity analysis numerical ratings reviews denote positive maybe negative general discrete categories characterize emotion analysis course different ways design frequently categories happy sad fearful angry surpised task essentially classification task categorisation weve seen special case text means text categorization method sentiment course accuracy good sentiment classification require improvement regular text categorization technique simple text categorization particular needs kinds use sophisticated features appropriate sentiment tagging discuss consider order especially polarity analysis clear order categories order useful consider example use ordinal regression thats talk lets talk features useful text categorization text mining general especially needed sentiment_analysis lets start simplest character sequence characters unit mixed different ns different general way robust way represent text language robust spelling errors recognition errors right misspelled word 1 character representation actually allow match word occurs text misspelled word correct form matched contain common ngrams course representation discriminative word ngrams sequence words mix different uni grams actually effective lot text processing tasks thats words designed features humans communication good tasks good sufficient sentiment_analysis example sentence like good case good suggest positive good accurate bigram good accurate longer ngrams generally discriminative match says lot unlikely cause_overfitting unique features machine_learning program easily pick features training set rely unique features distinguish obviously kind classifier wont generalize future data discriminating features necessarily thats problem thats consider speech tag ngrams speech_tagging example adjective noun form mix n grams words n grams speech example word great followed noun feature hybrid useful sentiment_analysis word classes classes syntactic like speech semantic represent concepts thethesaurus ontology like word recognized named entities like people place categories enrich representation additional learn word clusters empirically example talked mining associations words cluster paradigmatically_related words sementically related clusters features supplement word based furthermore frequent pattern syntax frequent word words formed pattern necessarily locations words occur patterns provide discriminative features words obviously generalize better regular ngrams frequent expect occur test data lot advantages face problem overfitting features problem general true parse_tree based features use parse_tree derive features frequent subtrees paths discriminating likely cause_overfitting general patton discovery algorithms useful feature construction allow search larger space possible features complex words general natural_language processing important derive complex enrich text example simple sentence showed long time ago words derive simple world ngrams representations character nlp enrich representation lot information speech tags parse trees entities speech enriched information course generate lot features complex features like mixed grams word speech parse_tree general feature design actually affects categorization accuracy significantly important machine_learning general think effective combine machine_learning error analysis domain_knowledge designing want use domain_knowledge understanding problem design seed define basic feature space lot possible features machine_learning program machine_learning applied select effective features construct new features feature features analyzed humans error look categorization errors analyze features help recover errors features cause_overfitting cause errors lead feature validation revise feature set iterate consider different feature nlp enriches text said enriches feature allows larger search space meaningful features useful lot careful use lot complicated features cause_overfitting training carefully let overfitting main challenge designing features common challenge optimize tradeoff exhaustivity trade turns exhaustivity means want features actually high coverage lot sense wanted features specificity requires feature discriminative naturally infrequent features tend discriminating caused tradeoff frequent versus infrequent features thats feature design generally thats important applying machine_learning problem case text categorization specifically sentiment
lecture ordinal_logistic regression sentiment_analysis problem set typical sentiment classification problem specifically rating opinionated text document d input want generate output range k discrete rating categorization k use regular text categorization technique solve problem solution consider order dependency intuitively features distinguish category 2 1 rating 2 1 similar distinguish k k_1 example positive words generally suggest higher train categorisation program treating categories independent whats solution general add order classify different approaches going talk called ordinal_logistic lets think use logistic_regression binary setting categorization suppose want distinguish positive negative category categorization predictors represented x features m features altogether feature value real number representation text y values binary response variable 1 means x positive 0 means x course standard category categorization apply logistical_regression recall logistic_regression assume log probability y equal 1 assumed linear function features allow write probability y 1 given x equation seeing thats logistical function relates probability probability y 1 feature_values course bi direct application logistical_regression binary_categorization multiple categories multiple levels actually use binary logistic_regression program solve multi level rating idea introduce multiple binary classifiers case ask classifier predict rating j ratings lower yj equal 1 means rating zero means rating lower basically want predict rating range k classifier distinguish k thats classifier going classifier distinguish k_1 thats classifier end need classifier distinguish altogether k_1 course solve problem logistical_regression program straightforward seen previous parameters classify need different set logistic_regression classifiers indexed j corresponds reading offer subject replace beta notation consistent ordinal_logistic basically k_1 regular logistic_regression set approach rating prediction trained k_1 logistic_regression classifiers separately course new instance invoke classifier sequentially lets look classifier corresponds level rating classifier tell object rating probability according logistical_regression classifier 5 going yes rating 5 means reading k right need invoke class file tells k_1 k_1 probability 5 k_1 says means rating k minus going invoking classifiers hit need decide help solve problem right classifier actually prediction rating range k unfortunately strategy optimal way solving problem specifically problems equations problem count parameters exactly interesting want pause video try figure solution premises classifier classifiers answer classifier n 1 k_1 classifiers altogether total_number premises k_1 m thats alot alot classifier lot parameters general need lot data actually help training_data help decide optimal parameters complex model thats second problem problems k_1 classifiers problems actually general words positive rating higher classifiers able advantage idea ordinal_logistic regression precisely key idea improvement k_1 independent logistical_regression classifiers idea tie beta parameters means going assume beta parameters parameters indicate influence going assume better values k_1 premise encodes intuition positive words general higher rating intuitively appealing reasonable problem set order fact allow positive benefit going reduce number parameters allow share training_data parameters assumed training_data different shared help set optimal value data help choose good beta whats consequence formula look similar seen beta parameter index correspond feature longer index corresponds level means tie theres set beta_values classifiers distinct alpha value alpha parameter different course needed predict different levels apha subject depends different j different alpha rest parameters ask question parameters thats interesting question think moment plan far fewer_parameters specifically n k_1 m beta_values plus k minus alpha thats basically thats basically main_idea ordinal_logistic lets use method actually assign idea tying parameters beta_values end having simpler way decisions specifically criteria predicted 5 equivalent score larger equal negative alphaj scoring_function taking linear_combination features weighted beta_values means simply desicion rating looking value scoring_function bracket general decision rule score particular range values assign corresponding rating text sum approach going score features parameter_values beta_values score compared set training values range score range decide rating object getting ranges values correspond different levels ratings thats way train tied level
lecture latent_aspect rating analysis opinion_mining sentiment_analysis lecture going continue_discussing opinion_mining sentiment_analysis particular going late aspect rating analysis allows perform detailed analysis reviews overall reviews internet hotel overall case reviewers given course reviews look reviews clear hotel good location service like want decompose overall_rating ratings different_aspects value rooms location decompose overrating ratings different_aspects obtain detailed_understanding reviewers opinions allow rank hotels different dimensions valuable rooms general detailed_understanding reveal information users preferences reviews preferences understand better reviewers view hotel different infer aspect_ratings want infer aspect weights reviewers care values opposed service case like whats shown left weight distribution lot weight placed care service place weight service reason important cause think star value expensive reviewer cares lot service right kind service price good reviewer reviewer cares value hotel star likely mean cheaper order interpret ratings different_aspects accurately need know aspect combined detailed_understanding task reviews overall ratings input generate aspect_ratings decomposed aspect_ratings aspect weights problem called latent_aspect rating task general given set review articles topic overall hope generate major aspects comment second ratings aspect value room 3rd relative weights placed different_aspects reviewers task lot enable lot applications listed example opinion based generate aspect level opinion analyze reviewers preferences compare compare preferences different personalized recommendation course question solve problem cases advanced topics wont time cover technique detail im going press basic introduction technique developed going talk solve problem later going mention unified review overall reading want going segment going figure words talking location words talking room conditioning able obtain aspect particular going obtain counts words segment denoted c supply seed words like location price retrieve relevant segments segments correlated seed words allow segment text discussing different_aspects course later use topic models segmentation thats stage obtain counts words segmentation stage called latent rating regression going use words frequencies different_aspects predict overall_rating prediction happens stage going use sentiment weights words aspect predict aspect example discussion location word like amazing mentioned times high example increase aspect rating word like far negative weight mentioned times decrease aspect rating assumed weighted combination word frequencies weights sentiment weights course sentiment weights different different_aspects aspect set sentiment shown thats denoted beta sub second stage second step going assume overall_rating simply weighted combination aspect_ratings going assume aspect weights order r_sub weighted average aspect_ratings denoted assume overall_rating simply weighted average aspect_ratings setup allows predict overall_rating based observed word left observed information arts right information interested actually hope typical case generating model embed interesting variables generating going set generation probability overall_rating given observed course adjust parameter_values including betas rs order maximize probability data case conditional probability observed rating given seen cases example plsa predict text predicting rating parameters course uncover parameters nice r d precisely aspect_ratings want decomposer ratings different_aspects sub id precisely aspect weights bi product beta vector aspects specifica sentiment weights words thought set review documents overall review documents denoted overall_rating denoted r_sub d pre segmented k segments going use c sub w d denote count world w aspect course zero world doesnt_occur model going predict rating interested conditional probability r_sub t given model set assumed follow normal distribution mean denotes actually await average aspect_ratings r_sub d shown normal distribution variance course assumption actual reading necessary generating assumption formal way model problem allows compute interesting case aspect_ratings aspect aspect rating second_line assumed weighted sum weights weight sentiment said overall_rating assumed weighted average aspect_ratings alpha values alpha_sub d vector depends d document specific weights assume factor drawn multivariate gaussian distribution mean denoted mule vector covariance matrix sigma means generate overall_rating going set values multivariate gaussian prior distribution alpha values going use weighted average aspect_ratings mean use normal generate overall_rating aspect rating said sum sentiment weights words note sentiment weights specifically aspects beta gives way model different segment word positive sentiment negative sentiment premise said beta sub w gives aspect specific sentiment obviously thats important parameters general beta_values delta mu question estimate parameters collectively denote parameters usual use maximum_likelihood settings premise maximizer observer ratings condition respective course useful variables interest specifically estimate parameters easily compute abstract rating aspect sub d thats simply words occurred segment accounts multiply sentiment weight word course counter 04 words occurring aspect thats words aspect weights alpha_sub d parameter right use bayesian_inference case use maximum 2 computer alpha basically going maximize product prior according assumed market valued gaussian distribution likelihood case likely probability generating observed overall_rating given particular alpha value details model read paper
lecture continued_discussion latent_aspect rating earlier talked solve problem lara stages segmentation different_aspects use little regression model learn aspect_ratings letting possible develop unified generative_model solving problem modeling model generation overrating based text model generation text natural solution use topic given entity assume aspects described word topics use topic model model generation review assumed words review text drawn way assumed generative_model like plug latent regression model use text predict overall_rating means predict aspect rating combine aspect weights predict overall_rating unified generative_model model generation text overall_rating condition dont time discuss model detail cases course discuss cutting edge reference site find im going simple results kind generative rating decomposed ratings hotels overall_rating look overall_rating cant tell difference hotels decomposing ratings aspect_ratings hotels higher dimensions like value score better dimensions like location reveal detailed opinions aspect ground_truth shown plans allows prediction accurate reflecting 2nd result compare different reviewers hotel table shows decompose ratings reviewers hotel high level overall look overall ratings dont information difference decompose ratings clearly high scores different shows model reveal opinions different reviewers detailed_understanding help understand better reviews better feedback interesting sense byproduct problem design generative_model component sentiment waits words different_aspects highly weighted words versus negatively lower weighted words value rooms location added words cleared makes sense words makes shows apology learn sentiment information directly kind laxing useful becausw general word like long lets different sentiment polarities different battery_life laptop long thats rebooting time laptop long thats bad right reviews product laptop word long ambiguous mean positive negative kind lexicon learn kind generative models word positive particular aspect clearly useful fact lexicon directly tag reviews hotels tag comments hotels social_media like whats_interesting computer supervised assuming reviews overall ratings available allow learn potentially large data internet reach sentiment results validate preference remember model infer reviewer cares service know inferred_weights correct poses difficult challenge interesting way evaluating prices hotels different cities prices hotels favored different groups reviewers highest inferred value aspect example value versus location value versus room reviewers highest ratios means reviewers tend lot weight value compared means emphasize hand reviews lowest mean means reviewers higher weights aspects value people care dimension didnt care value sense compared ratios computer based inferred_weights average prices hotels favored toptenreviews cheaper favored provides indirect way validating infer means weights random actually meaningful comparison average price cities actually tends average price time care lot things like service room condition tend hotels higher prices results build lot interesting example direct application generator rated aspect decomposition generate summaries positive sentence negative sentences informative original review overall_rating review mother results aspects discovered reviews low mp3 reviews results model discover interesting aspects commented low overall ratings versus high overall ratings care different_aspects comment different_aspects help discover example consumers trained appreciating different features example discovered trend people tend like large screens cell phones lightweight laptop knowledge useful manufacturers design generation interesting results analyzing users rating average weights different dimensions different groups left weights reviews like expensive_hotels expensive_hotels stars average weights tend focused service suggests people expensive_hotels good thats surprising way validate inferred_weights look right look column stars reviewers like cheaper_hotels cheaper_hotels stars expected weight value thats like cheaper_hotels look didnt like expensive_hotels cheaper_hotels seal tended weights condition room shows model infer information thats hard obtain read read reviews hard infer preferences case text mining algorithms humans review interesting patterns data course compare different hotels compare opinions different consumer groups different locations course model applied reviews overall ratings useful technique support lot text mining finally result applying model personalized ranking recommendation infer reviewers weights different dimensions allow user actually example query shows 90 way value means dont care aspects care getting cheap emphasis value query use reviewers believe similar preference recommend know infer weights reviewers different_aspects find reviewers weights precise inferred_weights similar use reviews recommend personalized query specific non personalized recommendation results results generally higher price low group thats reviewers cared value dictated query tend favor low price application shows text mining understand users end users better serve users summarize discussion opinion_mining general important topic lot task sentiment_analysis usually text categorization standard techniques tend need enriched feature need consider order categories talk ordinal solving shown generative models powerful mining latent user preferences particular generating model letting rating regression embed interesting preference information sentiment weights words result learn useful information fitting model approaches proposed evaluated product_reviews cause context opinion holder opinion target clear easy analyze course lot practical applications opinion_mining news social_media important thats difficult analyzing review data mainly opinion holders opinion implicit calls natural_language processing_techniques uncover suggested_readings small books excellent reviews topic find lot discussion variations problem techniques proposal solving papers generative models letting aspect rating solving problem stages second unified model topic model integrated regression solve problem unified
lecture text based lecture going start talking mining different kind knowledge seehere going use text data infer values variables real directly related text remotely related text different content analysis topic mining directly characterize content different opinion_mining sentiment_analysis characterizing content focus subjectivecontent reflects know opinion provides limited view lecture following_lectures going talk predict information sophisticated patterns text kinds ofdata useful look big_picture prediction data mining general thisdata mining picture youre_seeing right multiple sensors including human sensors report seen real world theform course data form non text data text goal predict values important real world variables example someones health condition weather variables important want want decisions data predicted_values general data mining analysis general treat data prediction problem set interested joint mining non text text analysis generally generate multiple predictors interesting variable features predictive model actually predict value interesting allows change world basically general process making prediction based data including text important emphasize human actually plays important_role especially involvement text human involved mining control generation help understand text data text data created consumed humans best consuming interpreting text course lot text data machines help thats need text data machines patterns lot data humans general human play important_role analyzing text data human involved predictive model building adjusting particular lot domain_knowledge problem prediction build predictive model course predicted_values variables humans involved taking actions change world decisions based predictive finally interesting human involved controlling adjust sensors collect useful data thats called data mining loop perturb sensors collect new data useful data obtain data data generally help improve prediction accuracy loop humans recognize additional data needs collected machines course help humans identify data general want collect data useful actually subarea machine_learning called active identify data points helpful machine_learning programs label general theres loop data acquisition data analysis data mining prediction values actions change world observe decide additional collected adjusting prediction errors know additional data need acquire order improve accuracy big_picture actually general reflecting lot important applications big useful mind looking text mining text mining perspective interested text based prediction course text useful prediction human behavior human preferences general text data non text interesting questions design_effective predictors generate effective_predictors text question addressed extent previous lectures talked kind features design text addressed extent talking knowledge example topic mining useful generate patterns topic based indicators predictors fed predictive topics intermediate representation allow design high level features predictors useful prediction maybe generated original text data provides better representation problem serves effective_predictors similarly sentiment_analysis lead data mining text mining algorithms generate question join text non text data question lecture following_lectures going address problem generate enriched features prediction allows review lot interesting knowledge patterns generated text non text data useful prediction predictors help improving accuracy basically text based prediction character serve unified framework combine text mining analysis techniques including topic mining content content mining techniques sentiment_analysis goal mainly infer values real world order achieve goal preparations sub sub task content text data like topic knowledge observer sentiment_analysis opinion help provide predictors prediction course add non text data directly predictive model non text data helps provide context text analysis improves topic mining opinion improvement leads effective_predictors problems enlarge space patterns opinions topics discuss later join analysis text non text data actually understood 2 perspective non text data help text non text data provide context mining text provide way partition text data different ways leads number techniques contextual_text thats text context defined non text reference large body work direction going highlight perspective text data help non text data text data help interpret patterns discovered non text helps discover frequent patterns non text use text data associated instances pattern occurs text data associated instances pattern doesnt_occur gives sets text data whats difference difference text data interpretable text content easy digest difference suggest meaning pattern weve found non text data helps interpret technique called pattern reference listed reference reference second qiaozhu mei dissertation contextual_text contains large body work contextual_text
lecture contextual_text contextual_text mining related multiple kinds knowledge text im showing related topic mining topics associated context like time location similarly opinion_mining contextualized making opinions connected related text based prediction allows combine non text data text data derive sophisticated predictors prediction specifically interested contextual_text mining thats text rich context information include direct context meta indirect context direct context include metadata time location authors source text indirect text context refers additional data related meta example authors obtain additional context social network author authors information general directly related text authors text data source context data connected general related data regarded context remotely related whats use text context useful context partition text data interesting allows partition text data arbitrary ways important allows interesting comparative general provides meaning discovery topics gonna associate text heres illustration context regarded interesting ways partitioning text research_papers published different different venues different conference names listed like sigir acl text data partitioning interesting ways context includes time conference include lets partition data interesting treat paper separate case paper id paper context treat papers written 1998 group possible availability time partition data allow compare topics example different similarly partition data based sigir_papers compare papers rest compare sigir_papers kdd papers acl partition data obtain papers written authors course uses additional authors allow compare subset set papers written authors obtain set papers text mining compared papers note partitioning intersect generate complicated general enables discovery knowledge associated different context particular compare different contexts gives lot useful example comparing topics overtime trends topics comparing topics different context reveal differences interesting questions require contextual_text mining list specific example topics gaining increasing attention recently data mining research answer question obviously need analyze text context time context difference responses people different regions event event broad analysis question case course location common research interests researchers case authors difference research topics published authors usa outside case context include authors affiliation goes need look additional information connected difference opinions topic expressed social network case social network authors topic topics news data correlated sudden changes stock_prices case use time series stock_prices issues mattered 2012 presidential_campaign presidential election case time series df list basically contextual_text mining
lecture specific technique contextual_text mining called contextual probabilistic latent semantic_analysis lecture going continue_discussing contextual_text going introduce contextual probabilistic latent semantic_analysis extension plsa contextual_text recall contextual_text mining hope analyze topics consideration context associate topics appropriate context approach contextual probabilistic latent semantic_analysis cplsa main_idea explicitly add interesting context variables generated recall generate text generally assume start topics sample words going add context variables coverage topics content topics tight little words let context influence coverage content consequences enable discover contextualized topics topics interesting meaningful topics interpreted specific particular context example particular time_period extension plsa model cplsa mainly following firstly model conditional likelihood text given clearly suggests generation text depend context allows bring context generative_model secondly makes 2 specific assumptions dependency topics assume depending context depending different time periods different locations assume different views topic different versions word distributions characterize topic assumption allows discover different variations topic different topic coverage depends means depending time location cover topics dependency allow capture association topics specific use em_algorithm solve problem parameter case estimate premise naturally contain context variables particular lot conditional probabilities topics given certain allow contextual_text basic_idea dont time introduce model detail references look know want explain high level ideas detail particularly willing explain generation_process text data context associated assume multiple example topics represent themes like government_response donation city new_orleans example context hurricane_katrina hit new_orleans assume different views associated shown view view view view different version word views tide context example type location texas time july 2005 occupation right assume document contact information time known july 2005 location texas context information hope going model idea model variations topic content different context gives different views world theme coverage topic coverage vary according case location like texas people want cover red topics new audience certain time_period maybe particular topic like donation covered variation considered generate document context choose view course lets taken depends time specific version word probabilities words chosen view situation similar happened standard assume got word distribution associated topic right view choose going choose particular coverage fixed plsa hard particular document coverage consider context distribution topics coverage topics vary depending context influenced example pick particular coverage lets pick weve picked document specifically coverage coverage word distributions generate document exactly way means going use coverage choose topic choose lets picked lets yellow topic withdraw word particular word like time choose different topic donate etc right generate words basically process main difference obtain coverage word distributions let context influence words extra switches tied context control choices different views topics choices naturally model parameters estimate estimate parameters involve context able understand context specific views topics context specific coverages precisely want contextual_text sample results necessary exactly model similar slide sample results comparing news_articles iraq war afghanistan 30 iraq war 26 articles afghanistan case review common topics covered sets articles differences variations topic case context explicitly specified topical common theme thats corresponding cluster common theme indicating united_nations involved wars common topic covered sets articles thats indicated high probability words shown united_nations background course topic relevant look column whats_interesting cells word distributions actually tell collection specific variations topic united_nations indicates iraq war united_nations involved weapon inspections afghanistan war involved maybe aid northern alliance different variation topic united_nations shows bringing context case different wars different collections topic variations tied contexts review differences coverage united_nations similarly look second cluster 2 killing surprising know background wars wars involved killing imagine familiar text collections lot text articles technique review common topics covered sets review common topics multiple sets look course column cluster 2 variations killing people correspond different different example obtain block articles hurricane_katrina case trends topics shows temporal chains oil flooding new_orleans topics obtained block articles hurricane_katrina people talked addition visualization shows technique conditional distribution time given allows plot conditional general curves like youre_seeing initially curves later topic new_orleans mentioned oil price turns time_period hurricane hurricane rita hit region apparently tricked discussion flooding curve shows coverage topic flooding city block articles different locations shows shift related peoples migrating state louisiana texas case time context reveal trends additional result special case topic government_response criticism slow response government case hurricane_katrina discussion covered different locations visualizations coverage different weeks event initially covered victim states south gradually locations week shown left pattern thats similar week left thats hurricane rita hit technique allow use location context examine variations course model completely general apply collections text reveal spatial temporal application kind model look use model event impact looking research articles information retrieval ir particularly sigir_papers topic focus retrieval models word words high probability model hope examine impact start trec text retrieval major evaluation effort sponsored government launched 1992 time known impact topics research information publication seminal paper croft ponte language modeling approach information known high impact information retrieval research hope use kind model understand impact idea simply use time context use events divide time periods period event event compare topics coverage variations case results ive seen trec study retrieval models vector_space model boolean model apparently study retrieval models involved lot words suggest different retrieval example email enterprise search tasks subtropical retrieval task introduced later variations correlated publication language_model classical probabilistic model logic model boolean model 1998 clear dominance language_model probabilistic_models words like language_model estimation parameters technique use event understand impact event technique general use analyze impact suggested_readings paper simple extension plsa enable cross collection perform comparative text mining allow extract common topics shared multiple collections variations second main paper cplsa model discussion lot lot details special temporal patterns hurricane_katrina
lecture text data social network lecture going continue_discussing contextual_text particular going look social network authors text motivation network context analysis context text article form example authors research articles form collaboration_network authors social_media content form social example people follow people claim friends context connects similarly locations associated text connected form geographical network general imagine meta data text data form kind network benefit jointly analyzing text social network context network context thats use network impose constraints topics example reasonable assume authors connected collaboration_network tend write similar heuristic guide analyzing text help characterize content associated subnetwork kinds data network text example difference opinions expressed subnetworks lets social networks revealed kind joint going briefly model called network supervised topic slide going general ideas slide general course dont time cover frontier topics detail provide references read know useful know general ideas know know able general idea network supervised topic model modeling lets viewing regular topic models like plsa lda solving optimization_problem course case optimization objective_function likelihood_function use maximum_likelihood estimator obtain parameters parameters useful information want obtained text example want maximize probability text data given parameters generated denoted main_idea incorporating network think constraints imposed based general idea use network impose constraints model parameters example text adjacent nodes network assumed cover similar cases tend cover similar able smooth topic distributions graph network adjacent nodes similar topic share common distribution topics slight variations topic distributions topic technically simply add network induced regularizers likelihood objective_function instead optimizing probability text data given parameters going optimize function function combines likelyhood regularizer function called r regularizer defined parameters lambda network tells basically kind parameters preferred network constraint perspective easy effect implemented idea imposing prior model parameters necessarily having probabilistic going combine single objective_function advantage idea general topic model generative_model right doesnt plsa lda current topic similarly network graph connects text regularizer flexible capturing different heuristics want finally function f vary different general idea actually office general approach combining different types data single optimization general idea clearly applied problems paper particular instantiation called netplsa started case extension plsa incorporate simple constraints imposed prior neighbors network similar topic cover similar topics similar ways thats basically says technically modified object function defined text collection c network graph look formula actually recognize fairly familiar fairly recognize likelihood text data given topic model look precisely plsa log likelihood want maximize estimate parameters second equation shows additional constraints measure difference topic coverage node u adjacent nodes want distributions similar computing square differences want minimize note negative sign makes possible find parameters maximize plsa log means parameters fit data respect constraint active sign mentioned theres negative sign maximize objective_function actually minimize second look picture weight edge u v thats based weight says nodes strong collaborators researchers connections people social network high weight means important sure topic coverages similar thats basically finally use parameter new parameter control influence network easily lambda set zero standard lambda set larger value let network influence estimate models effect basically plsa going try topic coverages strongly connected similar ensure coverages sample results paper slide_shows regular results plsa data dblp bibliographic data research experiments communities ir information means dm stand data mining ml machine_learning communities hoping topic mining help uncover communities sample topics seeing generated plsa plsa unable generate communities correspond intuition reason mixed words shared communities easy use use topics coherent whats_interesting use netplsa network collaboration_network case impose case use topics netplsa meaningful topics correspond information retrieval second data machine_learning fourth influence network leverage collaboration_network essentially people form collaboration_network kind assumed write similar topics thats coherent listen text data based co_occurrences wont coherent topics topic model plsa able pick co occurring words general topics generate represent words co generate coherent results netplsa showing network context similar model characterize content associated subnetwork general view text mining context network treat text living rich information network means connect related data big network text data associated lot structures network example associated nodes network thats basically discussed netplsa text data associated edges paths sub networks way represent taxes big environment information powerful allows analyze data general analysis text entire network information thats related text heres suggested reading paper netplsa find details model estimate
lecture time series context potentially discover causal_topics lecture going continue_discussing contextual_text particular going look time series context analyzing text potentially discover causal_topics usual lets start case hope use text mining understand time youre_seeing dow jones industrial average stock price curves sudden right interested knowing caused stock market know background able figure look time stamp data help question clues companion news stream lot news data generated actually discover crash actually happened time september 11 thats time sudden rise topic september 11 attack news_articles heres scenario want analyze presidential time series data presidential prediction example iowa electronic market stocks candidate believe candidate win tend buy stock candi date causing price candidate thats nice way actually survey peoples_opinions suppose sudden drop price want know caused sudden social science study interested knowing mattered election issues mattered case look companion news stream ask clues news stream provide example discover mention tax cut increasing maybe thats related drop cases special_cases general problem joint analysis text time series data discover causal_topics input case time series plus text data produced time_period companion text different standard talking models text thats set time series serve output want generate topics coverage text stream strong correlations time example topic mentioned price tends topics causal_topics course theyre strictly speaking causal_topics going able verify causal theres true causal thats causal quotation correlated topics potentially explain cause humans certainly analyze topics understand issue output contain topics like topic hope topics regular topics certainly dont explain data best text explain data text meaning represent meaningful topics texts semantically coherent topics important correlated external_time series given understand solve problem lets solve problem regular topic example plsa apply text extension like cplsa contextual plsa discover topics collection discover coverage simple solution choose topics set strongest correlation external_time approach going restricted topics discovered psa lda means choice topics limited know models try maximize light role text data topics tend major topics explain text data theyre necessarily correlated time best correlated topics interesting causal work site better approach proposed approach called iterative causal topic idea iterative adjustment topics discovered topic models time series induce heres illustration text stream input apply regular topic modeling generate number said topics going use external_time series assess topic causally related correlated external_time series certainly figure topic topic correlated topic stopped like simple approaches talked earlier right topics causal_topics explained topics likely good general topics explained text collection theyre necessarily best topics correlated time approach zoom word going look word ranked word list lets topic target know topic correlated time best set topics going look words topic topic correlated time series words highly correlated time example discover w1 w3 positively correlated time w2 w4 negatively topic good mix words different correlations separate words going red words indicate positive correlation w1and w3 going subtopic want represents negatively correlated words w2 subtopics variations topics based correlation analysis topics related original topic topic deviating use time series information bias selection sense expect sense correlated time series original topic original topic mixed words subtopics expected better correlated time coherent idea topic model prior guide topic modeling thats ask topic models discover topics similar subtopics cause bias correlated topics time course apply topic models generation topics ranked based time series select highly correlated analyze component words topic try analyze word level correlated subtopics fed process prior drive topic model process heuristic way optimizing causality thats ultimate goal right pure topic models good maximizing topical topicals use causality test correlation measure set words strongly_correlated time series necessarily semantically connected ideal causal topic thats scored high topical coherence causal approach regarded alternate way maximize apply topic models maximizing decompose topic model words sets words strongly strongly_correlated time series select strongly_correlated words time series pushing model causal dimension better causal apply selected words prior guide topic modeling optimize coherence topic models ensure generation topics coherent iterate iterate optimize way shown component havent seen framework measure causality rest topic lets little bit lets topic government_response topic model coverage topic time series given time series represents external non text time series yt stock_prices question xt cause yt words want match causality maybe measure correlation measures use example pearson_correlation commonly measure consider time lag try capture causal relation somewhat past data data past try correlate data points represents future example introducing lag hopefully captures causal relation correlation measures like pearson_correlation commonly measure causality granger causality idea test actually basically youre going auto regressive model use history information y best going able use going add history information x model improve prediction statistically significant difference x causal influence y wouldnt caused improvement prediction hand difference insignificant mean x causal relation y thats basic_idea dont time explain detail read read cited reference know frequently measure lets look sample results generated data new york times time_period june 2000 december time series stock_prices companies american airlines apple goal inject time series bias time series context actually topics biased time imagine dont use input dont use context topics new york times discovered plsa general topics people talk major topics news topics biased time particular look underlined words american airlines result airlines airport air united trade terrorism clearly topics correlated external_time right topics clearly related computer technology software internet com web means time series effectively served context bias discovery perspective result help people talked case people people talked topics correlated stock_prices topics serve starting point people look issues find true causal results analyzing presidential election time time series data iowa electronic thats prediction market new york times 2000 october 2000 2000 presidential_campaign 3 words insignificant topics new york look topics related actually issues related important issues presidential mention text data filtered articles mention candidate subset news_articles different previous results clearly approach uncover important issues presidential tax cut oil energy abortion gun control known important issues presidential election supported literature political discussed basically results approach effectively discover possibly causal_topics based time series suggested_readings paper iterative topic modeling time series feedback find details approach second reading granger causality end lets summarize discussion text based text based prediction generally useful big data applications involve text help infer new knowledge word knowledge whats discussed result support optimizig decision_making widespread text data combined non text data prediction purpose prediction purpose generally like combine non text data text data clues possible result joined analysis text non text useful analyze text data non text data non text data provide context mining text data discussed number techniques contextual_text hand text data help interpret patterns discovered non text data called pattern general active_research topic new papers published open challenges
lecture summary lets revisit topics covered beginning talked natural_language processing enrich text talked knowledge language natural_language express whats observed world text particular talked word_associations talked analyze topic syntax discover topics regarded knowledge oberved world talked knowledge observer particularly talk opinions sentiment_analysis finally talked text based prediction predicting values real world variables based text discussing discussed rule nontext_data contribute additional predictors prediction problem provide context analyzing text particular talked use context analyze key highlevel takeaway_messages im gonna major topics point key takeaway_messages nlp text representation realize nlp important text applications enriches text representation nlp better text representation enables accurate knowledge discovery discover deeper knowledge buried current state art natural_language processing robust result robust text mining technologies today tend based word representation tend rely lot statistical analysis discussed recall word based representations weve relied lot statistical techniques statistical learning techniques word association mining analysis important points introduced concepts basic plan complementary relations words paradigmatic syntagmatic_relations actually general relations elements meaning elements occur similar context sequence elements tend cooccur relations meaningful sequences talked lot text similarity discuss discover paradigmatically relations compare context words discover words share similar point talked representing text data vector_space model talked retrieval techniques bm25 measuring similarity text assigning weights terms tfidf_weighting connected text techniques point co occurrence analysis text introduced information theory concepts entropy conditional_entropy mutual_information useful measuring cooccurrences words theyre useful analyzing kind data theyre useful example feature selection text important concept talked topic mining analysis thats introduced probabilistic topic spend lot time explain basic topic model plsa basis understanding lda theoretically appealing time depth introducing practice plsa effective lda simpler introduce general concepts useful generating model general method modeling text data modeling kinds talked maximum_likelihood estimator em_algorithm solving problem computing maximum_likelihood general techniques tends useful talked text clustering text important building blocks text mining application text clustering talked solve problem slightly different mixture_model probabilistic topic briefly reviewed similarity based_approaches text categorization talked kinds generative classifiers rely base rule infer conditional probability category given text particular introduced naive_bayes practical useful technique lot text categorization briefly introduce discriminative_classifiers particularly logistical_regression k nearest neighbor important popular theyre useful text parts discussed evaluate results evaluation important measures use dont reflect utility method misleading important evaluation right talk evaluation categorisation detail lot specific talked sentiment_analysis opinion_mining thats introduced sentiment classification special case text categorization talked extend improve text categorisation method sophisticated features needed sentiment_analysis review commonly complex features text analysis talked capture order categories sentiment classification particular introduced ordinal logistical_regression talk latent_aspect rating unsupervised way generated model understand review data particular allows understand decomposed ratings reviewer different_aspects given text reviews overall ratings method allow infer ratings different_aspects allows infer reviewers latent weights aspects aspects important reviewer reviewed enables lot interesting finally discussion text based prediction mainly talked joint mining text non text data important particularly talked text data help non text data vice case non text data help text data analysis talked contextual_text introduce contextual plsa generalization generalized model plsa allow incorporate context variables time location general way allow review lot interesting topical patterns text introduced net case use social network network general text data help analyzing finally talked time series data context potentially causal_topics text way text help help interpreting patterns discovered non text data discuss detail provide reference stress thats actually important direction know want build practical text mining systems understanding interpreting patterns summary key takeaway_messages hope useful building text mining applications study algorithms provide good basis read frontier research_papers know advanced_algorithms invent new know topic suggest look areas short period time course touch basic concepts basic principles text mining emphasize coverage practical useful algorithms cost covering advanced_algorithms briefly cases omitted discussion lot advanced_algorithms learn subject definitely learn natural_language processing foundation text based nlp better representation texts deeper knowledge second area look statistical machine_learning techniques backbone techniques text analysis applications lot nlp_techniques nowadays actually based supervised_machine important key understanding advanced nlp_techniques naturally provide tools text analysis particularly interesting area called deep learning attracted lot attention shown promise application areas especially speech vision applied text example recently work deep learning sentiment_analysis achieve better accuracy thats example advanced techniques werent able thats area emerged statistical learning word embedding technique learn vector representation words vector representations allow compute similarity provides directly way discover potentially paradigmatically relations words results people got far thats promising technique time course new techniques lead practical use techniques work better current technologies open question evaluation example examining practical value word embedding word similarity based advanced techniques surely impact text mining important statistical learning key predictive modeling crucial big data talk predictive modeling component regression categorization techniques reason statistical learning suggested learn data mining thats simply general data mining algorithms applied text data regarded special case general applications data mining techniques particular example pattern discovery useful generate interesting features text recently information network mining techniques analyze text information good know order develop effective text analysis finally recommend learn text retrieval information retrieval search especially important youre interested building practical text data application search_engine essential system component text based applications thats text data created humans humans best position understand text important human loop big text data particular help text mining systems effectively reduce data size large collection small collection relevant text data matter particular provide way annotate explain patterns knowledge discover knowledge figure discovery reliable need original text verified thats search_engine techniques information retrieval example bm_25 vector_space language models useful text data mention know text retrieval youll techniques technique thats useful indexing technique enables quick response search_engine users query techniques useful building efficient text mining finally want remind big_picture harnessing big text data showed beginning general build big text data application system need kinds techniques text retrieval text text retrieval explained help convert big text data small relevant data particular problem help providing knowledge prominence help interpreting patterns text mining analyzing relevant data discover actionable_knowledge directly useful decision_making course covered text mining theres companion course called text retrieval search engines covers text havent taken course useful especially interested building text application system taking courses complete set practical skills building end like thank taking hope learned useful knowledge skills text mining discussions lot application opportunities kind techniques lot open challenges hope use learned build lot useful applications benefit society join research community discover new techniques text mining
